<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[实用工具 | 也许，这是最强大的一款浏览器插件]]></title>
    <url>%2F2019%2F07%2F14%2Ftampermonkey%2F</url>
    <content type="text"><![CDATA[前言 浏览器是我们日常工作中接触最多的工具之一，甚至在很多人的排行榜里毫无争议的夺得第一的位置。目前市面上浏览器可谓是五花八门，谷歌浏览器、IE浏览器、火狐浏览器、QQ浏览器、搜狗浏览器、360浏览器等等，但是归根结底，使用的内核主要分为两类：Chromium内核和Trident内核(又称IE内核)。由于浏览器在工作中扮演者至关重要的作用，使用比重也非常之大，因此，简单的官网默认浏览器很难满足我们各种各样的需求，所以，浏览器插件也就应用而生。甚至，对于很多浏览器来说，它的最大特色和吸引人的地方就是丰富而实用的插件。 如果让选出几款不错的插件推荐给大家，不同的使用者应该会推荐不同的插件，毕竟每个人的使用偏好和工作内容不同。但是我相信，对于大多数推荐者都不会忽略一个插件，也就是本文的主角：Tampermonkey。可以毫不谦虚的说，Tampermonkey是目前最为流行的用户脚本管理器，它适用于 Chrome, Microsoft Edge, Safari, Opera Next, 和 Firefox。用户脚本是一个什么东西？简而言之，不同脚本可以实现不同的功能，Tampermonkey可以对这些功能进行管理，让你的浏览器如虎添翼。 由于我个人日常使用谷歌浏览器较多，因此在这里就以谷歌浏览器为例为大家推荐几款不错的插件，每一款都让人赞不绝口。 概述Tampermonkey有很多可选的脚本，但是如果让推荐的话，我认为以下5款是必不可少的： AC-baidu Yet Another Weibo Filter 百度网盘直链下载助手 豆瓣资源下载大师 破解VIP会员视频集合 下面就逐个详细介绍一下上述5款插件，耐心往后面看，一个比一个强大。 AC-baidu 提及百度搜索，应该很多人想到的就是广告、混乱，的确，经常使用谷歌搜索，每当回到百度搜索时都会克制不住的质疑：“为什么会存在百度搜索这样的东西？” 的确，广告、相关推荐、垃圾信息，样样都有，就是没有我们想要的东西。 有了AC-baidu这个脚本，上述困扰就迎刃而解了。 它能够让你的搜索重定向到原始网页，拦截百家号等无用推广，让搜索网页回到最原始、最本质的样子。同时，每个搜索条后面都会有一个block字样，如果觉得对某些网站或者搜索条不满意，可以点击一些block就可以在以后的搜索中屏蔽这些搜索条。 Yet Another Weibo Filter 微博，是我们日常接触到较多的社交工具，甚至很多人每天都会反复多次刷微博。如果你喜欢用电脑浏览器刷微博应该清楚，它的页面信息十分混乱，多而杂，热门视频、特别关注、微博电影榜等等。我们唯一想看的就是微博，但是在浏览过程中却不得不被这些混乱的信息所干扰。有了Yet Another Weibo Filter就不用为此烦恼了，让你看真正想看的微博。 安装Yet Another Weibo Filter脚本之后打开微博会发现，右上角会出现一个漏斗状的一个图标，点击图标会打开上述界面，我们可以对微博进行内容、账号、话题、来源等进行过滤和设置，而且可以对版面进行清理，功能进行改造，而且还可以通过外观样式来修改字体、字号等内容，看看下面这幅图，经过版面清理之后是不是很整洁？ 百度网盘直链下载助手百度网盘是资源共享使用较多的一个工具，因此很多同学会通过各种网盘搜索工具寻找百度网盘的资源。但是资源找到了，会发现一个令人头疼的问题，文件太大无法直接下载，必须保存到个人网盘、打开PC客户端才可以下载。而打开客户端下载又被百度限速，非常痛苦，百度网盘直链下载助手就能够轻松解决这个问题。 安装百度网盘直链下载助手这个脚本之后会发现，浏览器打开百度网盘时上端会出现一个下载助手的选项卡，点击后会弹出两个选项：API下载、外链下载。这样的话可以直接点击调用IDM等下载工具进行下载，也可以复制下载链接，粘贴到一些下载工具后下载。 豆瓣资源下载大师 喜欢影视、音乐、图书的同学对豆瓣应该都不陌生，有大量的影视评论、书评。很多人会想，豆瓣上书籍、影视、音乐倒是不少，但是只能看看评论、评分，又有什么意义呢？豆瓣资源下载大师就让这个网站变的有了意义，把一个单纯的论坛和资源紧密的联系了一起。 安装豆瓣资源下载大师脚本之后，打开要找的电影、电视剧、图书等，会在右端状态栏很多匹配的资源列表，当然也包括下载的链接，下面就通过一个动画来演示下载《流畅的Python》这本书籍。 点击匹配的对应资源即可找到下载链接。 破解VIP会员视频集合 看电影、追剧，是很多同学闲暇之余最大的乐趣之一。但是发现我们要看的影视分布在优酷、腾讯、爱奇艺等平台，如果要买吧，太耗钱，不买吧，又要忍受冗长的广告。狠下心买了之后发现，很多电影需要观影券，这时候都会愤恨的说一句”与其这样，我还买你们会员干什么？“ 既然买了会员还不行，那么只有通过暴力方法来解决这个问题。关于视频破解工具，网上可谓是层出不穷，但是经过我的试用发现，真的不敢恭维，绝大多数都是不稳定或者压根不能用，而剩余个别能用的在打开时又非常缓慢，卡顿，直到遇到破解VIP会员视频集合这个脚本，发现真的令人惊讶，怎么可以有这么强大的神器？ 安装脚本之后会发现，打开视频后会在左边缘出现一个黄色箭头，点击这个箭头之后会弹出多个资源选项，点击其中一个会对我们看的视频进行解析，能够跳过广告、破解会员、观影券限制，更重要的是，它还很快，下面就来演示一下。 重点！！！亲测优酷、爱奇艺、腾讯视频均可用！ 脚本安装方法安装方式有两种： Chrome网上应用店 离线安装 Chrome网上应用店 如果能够访问Chrome网上应用店，我建议通过应用商店安装，便捷、安全。只需打开应用商店，搜索Tampermonkey，添加至Chrome即可。 离线安装 如果无法访问应用商店，则只能通过离线下载crx格式插件，然后点击右上角—更多工具—扩展程序，把crx格式插件拖动到空白处即可， tampermonkey安装之后点击图标，选择获取新脚本， 然后点击GreasyFork， 然后搜索、点击对应的的脚本安装即可， 插件下载如果无法访问Chrome网上应用店，则只能通过离线下载安装的方式，网上有很多Tampermonkey的资源，但是大多数很混乱，为了避免寻找的麻烦，我把插件进行共享了，需要的可以关注公众号，回复关键字”tmk“获取。]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习资源 | 如何学习优化算法？]]></title>
    <url>%2F2019%2F07%2F13%2Flearn-optimization%2F</url>
    <content type="text"><![CDATA[前言 在学习机器学习的一段时间之后，如果善于总结都会发现，无论是传统机器学习中比较经典的支持向量机，还是深度学习，无论是目前应用较广的计算机视觉，还是让AlphaGo大发神威的强化学习，最终都会涉及一个优化问题，或者是微积分系列的凸优化算法，或者是粒子群、蚁群等群体智能优化算法，或者是近几年比较热门的黑盒优化算法。尤其是近两年在工业控制方面契合度较高的强化学习，仔细分析它的模型，其实就是一个数学优化模型。最优化问题在当今的军事、工程、管理等领域有着极其广泛的应用。因此，优化算法的重要性可见一斑。理解优化算法，能够有助于理解深度学习的运作过程，对于模型的优化和改进也大有益处。本文就概括一下常用的优化算法并介绍一些学习资源。 优化算法概括 我个人对优化算法划分主要为3类，分别是： 凸优化 智能优化 黑盒优化 其中目前用的比较广泛的，尤其是在机器学习领域就是凸优化，例如梯度优化算法系列的梯度下降法、随即梯度下降、小批量梯度下降法、动量法momentum、Adagrad、RMSProp、Adadelta、Adam等，它们都是以梯度下降法为基础，在梯度下降法的基础上进行改进和优化。除了常用的这些还有牛顿法系列，以及无约束优化算法中的模式搜索法、Rosenbrock方法、单纯形搜索法、Powell方法。 凸优化虽然很成熟，但是很多工程问题并非是严格的符合凸优化的要求，换句话说，它是一个非凸优化问题，这样直接利用前面提到的这些算法很容易陷入局部最小值。因此，为了满足工程需求，研究者会根据问题的需求提出一些新颖的优化算法，其中就包括目前在工程应用领域比较热门的群体智能优化算法系列，例如，粒子群优化、模拟退火法、遗传算法，它们以独特而适应性强的有点在工程应用领域倍受欢迎，尤其是在复杂数学模型求解问题中能够更快速的求解同时避免陷入局部最优。 黑盒优化算法我最初是在谷歌开放的内部调参系统Google Vizier介绍论文Google Vizier: A Service for Black-Box Optimization提到的。在前面的优化算法中，优化问题都是建立在一个完整的数学模型基础之上，但是现实世界中很多场景是很难用数学模型来描述，或者没有数学模型，例如我们经常接触到的交通系统。在这种问题求解过程中，上述严格依赖数学模型的优化算法就显得有些捉襟见肘。谷歌在2017年在开放内部调参系统的介绍论文中详细介绍了它们用于调参的几种优化算法，其中包括如下几种算法： 贝叶斯优化 进化策略 SMAC 随机搜索 并在文中详细的对比了几种黑盒优化算法的效果。 下面分别针对这3类优化算法介绍一些学习资料。 凸优化算法 凸优化算法在目前机器学习中用的较多，其中分别有： 梯度下降法 动量法 Adam RMSProp Adagrad … 感兴趣的可以看我的另一篇文章，里面对机器学习中常用的优化算法推导过程及不同算法之间的关系进行了详细的阐述：一文了解人工智能中常用的优化算法 由于凸优化发展时间较长，而且理论体系比较完善，因此在微积分、数值计算等课程中都会涉及一部分，但是分布比较零散，不同于目前机器学习系列的课程，针对性较强，而且内容专一。虽然课程方面没有针对纯粹优化算法的，但是书籍方面却有很多，在这里我推荐两本不错的凸优化算法的书籍， 《最优化理论与方法》—袁亚湘，孙文瑜 作者袁亚湘为中国科学院院士、数学家，在计算数学、运筹学、应用数学领域有较深入的研究。曾有幸听过袁亚湘院士到学校开的优化算法专题讲座，真可谓是”听君一席话，胜读十年书”，于是就购买了袁亚湘院士的这本书籍。语言生动而易懂，系统地介绍了无约束量优化，约束优化和非光滑量优化的理论和计算方法，内容全面而丰富。 《最优化理论与算法（第2版）》—陈宝林 本书是陈宝林教授在多年的授课基础之上编著而成，与袁亚湘院士的书籍目录划分结构不同，但是我认为这种内容分层更有助于初学者的学习，他分别把优化算法划分成单纯形方法、对偶理论、灵敏度分析、运输问题、内点算法、非线性规划KT条件、无约束优化方法、约束优化方法、整数规划和动态规划等内容。 智能优化算法 智能优化算法的发展历史相对而言要短一些，但是由于都是在工程应用领域遇到瓶颈是应运而生，因此它的实用价值和效果更加让它们受欢迎，目前比较经典的智能优化算法有， 遗传算法 禁忌搜索 模拟退火法 蚁群算法 粒子群优化算法 由于智能优化算法更多是应工程应用需求而生，因此在数学模型方面并没有太多改进，因此在通识教育的数学课程中也很少涉及，同时，相关的书籍较少，在这里我就推荐一本智能优化算法的书籍。 《智能优化方法》—汪定伟 之所以推荐这本书，更多的是因为它的全面，它几乎囊括了目前所有主流的智能优化算法，其中当然就有遗传算法、蚁群算法、粒子群算法等。书中讨论这些算法的产生和发展、算法的基本思想和理论、基本构成、计算步骤和主要的变形以及数值例子和实际应用，对于学习者非常友好。 黑盒优化算法 就如同前文所讲，黑盒优化算法我最初实在2017年谷歌开放内部调参系统的介绍论文中看到的，它详细的介绍了内部调参系统Google Vizier使用的几种主流黑盒优化算法。之所以称之为黑盒，就是因为在这类优化问题中我们没有数学模型，我们不清楚优化的目标函数到底什么样。这种场景和我们日常所接触的现实场景更加贴近，因此它的实用价值自然不言而喻。 在谷歌的这篇文章中，不仅介绍了系统内部使用的黑盒优化算法，还在不同维度求解问题下对比了以下几种优化算法的效果： 随机搜索 贝叶斯 SMAC 进化策略 概率搜索 虽然谷歌的文章发表于2017年，但是里面提及的算法并不算新颖，其中的算法都是经过几年甚至几十年的不断改进而形成现如今的样子，所以要想详细学习需要看一下Google Vizier: A Service for Black-Box Optimization这篇提及的参考文献，比较零散。虽然这些成熟算法的理论体系比较零散，但是它们共同用到的理论知识却是成体系的，它们都用到了概率论\随机过程相关的知识，尤其是其中表现较好的贝叶斯优化和进化策略，都是建立在高斯过程的基础之上，因此，本文就推荐1本随机过程方面的书籍，对这些概率论\随机过程的基础知识有所了解更加有助于对这些成形算法的理解。 《随机过程（原书第2版）》—Sheldon M.Ross 本书由世界著名的应用概率专家和统计学家Sheldon M. Ross编著，本书介绍了从概率论基础概念，到各种常见的分布模型。详细的介绍随机过程中经典的知识，包括Poisson过程、Markov链、鞅、Brown运动、随机序关系、Poisson逼近，并详细的介绍了这些理论的应用，更加有助于理解和学习。]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>优化算法</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[two_windows_tools]]></title>
    <url>%2F2019%2F07%2F13%2Ftwo-windows-tools%2F</url>
    <content type="text"><![CDATA[前言好的工具能让做事效率事半功倍，学习和工作都是这样。不同专业方向都会有一些很知名、耳熟能详的工具，例如开发方面的visual studio、pycharm，办公方面的office、xmind。这些软件的确很强大，但是再强大的工具都很难做到面面俱到，把效率考虑的十分周全。而有一些高手就及时发现里面的不足之处并开发出一些强大高效的工具，能够让日常工作效率大大提升，本文要介绍的两款工具就是这样的：冷门而强大，它们分别是：DropletIt和Quicker，下面就来看一下这两款工具究竟强大在哪里。 DropIt 工作中，日积月累会积攒很多各种各样的文件，有word、Excel、powerpoint、pdf等文档，有png、jpg等图片，有zip、tgz、7z等压缩包，尤其是很多同学都有个习惯，为了方便会放在桌面上，当想要找自己需要的东西时如同大海捞针一样，不知道从何下手。我想这是困扰很多人的问题，删除—积累，不断的重复，但是始终没有找到一个高效的解决文件分类方法。我想说，有了DropIt，再也不用担心文件分类与管理了，真正的实现了文件一建整理，下面来介绍一下DropIt的使用。 下载安装 下载安装之后桌面会有这样一个图标， 添加协议 为了满足我们整理文件的偏好和需求，需要对DropIt设置一下协议，让它按照我们预先设定的协议整理，添加协议主要包括4个部分： 名称：添加协议的名称，按照自己的爱好随便命名即可。 规则：匹配文件的规则，按照我们需要整理的文件设置匹配规则，例如\.png*匹配以png结尾的文件，如果包含多个规则可以用;隔开。 操作：对我们规则匹配到的文件采用的操作，其中包括移动、删除、压缩等。 目标文件夹：对文件处理的目标文件夹，例如，移动规则匹配到的文件到目标文件夹。 例如，上述我个人设置的两个协议，分别对图片(bmp、gif、jpg)和压缩包(zip、7z)进行处理，将图片和压缩包分别移动到指定的文件夹内。 设置好协议之后只需要选中文件，拖动到DropIt图标上方即可，下面来看看效果， 这样，选中的文件会按照我们预先设定的协议分别移动到对应的文件夹内，就不用我们逐个选中文件然后剪切、粘贴到指定文件夹。 Quicker 之前介绍过两款高效的办公工具：Listary和Wox。如果说Listary和Wox是键盘增强工具，那么Quicker就是一款强大的鼠标增强工具，能够让对鼠标比较依赖的同学发现，原来鼠标可以做这么多事情。 我们都知道，大多数鼠标包含3个按键，分别是：左键、右键、中键。其中左键和右键日常工作中使用较为频繁，但是中键除了上下翻页之外很少使用。Quicker就合理的利用了这一点，为鼠标中键添加上一个强大的快捷面板。软件默认的快捷面板包含我们常用的记事本、计算器、截图、我的电脑、Excel等工具，能够避免再去开始菜单寻找这些小工具，能够大大提高效率。 如果觉得软件自带的动作不足以满足自己的使用需求，那么还可以添加其他的动作，添加方式包括两种： 添加他人分享的动作 自己设计动作 添加他人分享的动作 首先打开官网，https://getquicker.net/Share 会发现官网动作库包含很多别人分享的动作，其中不乏查询搜索、翻译、文本处理、编程相关，可以根据自己的需求搜索对应的动作，然后复制动作，中键打开快捷面板，点击鼠标右键，选择粘贴分享的动作，然后安装即可，下面来演示一下安装过程， 如果在分享的动作库找不到自己需要的，或者感觉别人分享的无法满足自己的需求，没问题，还可以选择自己设计动作，Quicker提供两种动作创建方式： 基础动作 组合动作 基础动作 基础动作主要包含打开网址、发送文本、模拟按键等，创建方法很简单：点击鼠标中键打开快捷面板，点击+号，创建基础动作，选择动作类型，录制即可，当然也可以选择快捷的方式录入打开网址等动作。 组合动作 如果觉得基础动作太单一，还不够便捷，没问题，我认为Quicker最强大的地方就是支持组合动作。创建组合动作相对而言也要复杂一些，我认为它像是一种高阶的编程语言，可以用条件语句、添加变量名来实现一连串的动作，这个相对复杂而且不够大众化，因此在这里不多阐述，如果喜欢折腾的可以查看官网教程，创建一些高级的动作来提高自己的效率。 https://www.yuque.com/quicker/help/xaction-editor]]></content>
  </entry>
  <entry>
    <title><![CDATA[【动手学计算机视觉】第八讲：传统目标检测之SIFT特征]]></title>
    <url>%2F2019%2F07%2F10%2Fcv-hog%2F</url>
    <content type="text"><![CDATA[前言 如果自称为计算机视觉工程师，没有听说过前文提到的尺度不变特征变换(SIFT)，可以理解，但是如果没有听说过方向梯度直方图(Histogram of oriented gradient，HOG)，就有一些令人诧异了。这项技术是有发过国家计算机技术和控制研究所(INRIA)的两位研究院Navneet Dalal和Bill Triggs在2005年CVPR上首先发表提出(那时的CVPR含金量还是很高的)。原文Histograms of oriented gradients for human detection截止2019年7月10日引用率已经达到26856。 HOG通过计算局部图像提取的方向信息统计值来统计图像的梯度特征，它跟EOH、SIFT及shape contexts有诸多相似之处，但是它有明显的不同之处：HOG特征描述子是在一个网格秘籍、大小统一的细胞单元上进行计算，而且为了提高性能，它还采用了局部对比度归一化思想。它的出现，使得目标检测技术在静态图像的人物检测、车辆检测等方向得到大量应用。 在传统目标检测中，HOG可以称得上是经典中的经典，它的HOG+SVM+归一化思想对后面的研究产生深远的影响，包括后面要讲到的神作DPM，可以说，HOG的出现，奠定了2005之后的传统目标检测的基调和方向，下面就来了解一下这个经典之作。 方向梯度直方图 HOG特征的算法可以用一下几个部分概括， 梯度计算 单元划分 区块选择 区间归一化 SVM分类器 下面分别来详细阐述一下。 梯度计算由于后面要进行归一化处理，因此在HOG中不需要像其他算法那样需要进行预处理，因此，第一步就成了梯度计算。为什么选择梯度特征？因为在目标边缘处灰度变化较大，因此，在边缘处灰度的梯度就较为明显，所以，梯度能够更好的表征目标的特征。 我们都知道在数学中计算梯度需要进行微分求导，但是数字图像是离散的，因此无法直接求导，可以利用一阶差分代替微分求离散图像的梯度大小和梯度方向，计算得到水平方向和垂直方向的梯度分别是， G_{h}(x, y)=f(x+1, y)-f(x-1, y),\forall x, yG_{v}(x, y)=f(x, y+1)-f(x, y-1) ,\forall x, y其中$f(x,y)$表示图像在$(x,y)$的像素值1。 可以得到梯度值(梯度强度)和梯度方向分别为, M(x, y)=\sqrt{G_{h}(x, y)^{2}+G_{v}(x, y)^{2}}\theta(x, y)=\arctan \left(G_{h}(x, y) / G_{v}(x, y)\right.单元划分 计算得到梯度的幅值和梯度方向之后，紧接着就是要建立分块直方图，得到图像的梯度大小和梯度方向后根据梯度方向对图像进行投影统计，首先将图像划分成若干个块(Block)，每个块又由若干个细胞单元(cell)组成，细胞单元由更小的单位像素(Pixel)组成，然后在每个细胞单元中对内部的所有像素的梯度方向进行统计。Dalal和Triggs通过测试验证得出，把方向分为9个通道效果最好，因此将180度划分成9个区间，每个区间为20度，如果像素落在某个区间，就将该像素的直方图累加在该区间对应的直方图上面，例如，如果像素的梯度方向在0~20度之间，则在0~20对应的直方图上累加该像素对应的梯度幅值。这样最终每个细胞单元就会得到一个9维的特征向量，特征向量每一维对应的值是累加的梯度幅值。 区块选择为了应对光照和形变，梯度需要在局部进行归一化。这个局部的区块该怎么选择？常用的有两种，分别是矩形区块(R-HOG)和圆形区块(C-HOG)，前面提供的例子就是矩形区块，一个矩形区块由三个参数表示：每个区块由多少放歌、每个方格有多少像素、每个像素有多少通道。前面已经提到，经过作者验证，每个像素选择9个通道效果最佳。同样，作者对每个方格采用的像素数也进行验证，经过验证每个方格采用3*3或者6*6个像素效果较好。 区间归一化每个方格内对像素梯度方向进行统计可以得出一个特征向量，一个区块内有多个方格，也就有多个特征向量，例如前面的示例区块Block内就有4个9维向量。这一步要做的就是对这4个向量进行归一化，Dalal和Triggs采用了四种不同的方式对区块进行归一化，分别是L2-norm、L2-hys、L1-norm、L1-sqrt，用$v$表示未被归一化的向量，以L2-norm为例，归一化后的特征向量为， v=\frac{v}{\sqrt{\|v\|_{2}^{2}+\varepsilon^{2}}}作者通过对比发现，L2-norm、L2-hys、L1-sqrt三种方式所取得的效果是一样的，L1-norm表现相对差一些。 SVM分类器最后一步，也是比较关键的一步，就是训练分类器，用SVM对前面提取的图像特征向量进行训练，寻找一个最优超平面作为决策函数，得到目标的训练模型。 编程实践完整代码请查看： https://github.com/Jackpopc/aiLearnNotes/blob/master/computer_vision/HOG.py HOG是一个优秀的特征提取算法，因此本文就仅介绍并实现特征提取算法部分，后面的训练分类器和目标检测偏重于机器学习内容，在这里就不多赘述。 HOG算法非常经典，因此，很多成熟的第三方库都已经集成了这个算法，例如比较知名的计算机视觉库OpenCV，对于HOG特征提取比较简单的方式就是直接调用OpenCV库，具体代码如下， 1234import cv2hog = cv2.HOGDescriptor()img = cv2.imread("../data/2007_000129.jpg", cv2.IMREAD_GRAYSCALE)des = hog.compute(img) 为了更好的理解HOG算法，本文就跟随文章的思路来重新实现一遍算法。 第一步：计算梯度方向和梯度幅值 这里用Sobel算子来计算水平和垂直方向的差分，然后用对梯度大小加权求和的方式来计算统计时使用的梯度幅值， 123456def compute_image_gradient(img): x_values = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5) y_values = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5) magnitude = cv2.addWeighted(x_values, 0.5, y_values, 0.5, 0) angle = cv2.phase(x_values, y_values, angleInDegrees=True) return magnitude, angle 第二步：统计细胞单元的梯度方向 指定细胞单元尺寸和角度单元，然后对用直方图统计一个细胞单元内的梯度方向，如果梯度角度落在一个区间内，则把该像素的幅值加权到和角度较近的一个角度区间内， 123456789101112def compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit): centers = [0] * bin_size # 遍历细胞单元，统计梯度方向 for i in range(cell_magnitude.shape[0]): for j in range(cell_magnitude.shape[1]): strength = cell_magnitude[i][j] gradient_angle = cell_angle[i][j] min_angle, max_angle, mod = choose_bins(gradient_angle, unit, bin_size) # 根据角度的相近程度分别对邻近的两个区间进行加权 centers[min_angle] += (strength * (1 - (mod / unit))) centers[max_angle] += (strength * (mod / unit)) return centers 第三步：块内归一化 根据HOG原文的思想可以知道，图像内分块，块内分细胞单元，然后对细胞单元进行统计。一个块由多个细胞单元组成，统计了每个细胞单元的梯度特征之后需要对这几个向量进行归一化， 1234567891011121314151617def normalized(cell_gradient_vector): hog_vector = [] for i in range(cell_gradient_vector.shape[0] - 1): for j in range(cell_gradient_vector.shape[1] - 1): block_vector = [] block_vector.extend(cell_gradient_vector[i][j]) block_vector.extend(cell_gradient_vector[i][j + 1]) block_vector.extend(cell_gradient_vector[i + 1][j]) block_vector.extend(cell_gradient_vector[i + 1][j + 1]) mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector)) magnitude = mag(block_vector) if magnitude != 0: # 归一化 normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector] block_vector = normalize(block_vector, magnitude) hog_vector.append(block_vector) return hog_vector 第四步：可视化 为了直观的看出特征提取的效果，对下图进行特征提取并且可视化， 可视化的方法是在每个像素上用线段画出梯度的方向和大小，用线段的长度来表示梯度大小， 12345678910111213141516171819def visual(cell_gradient, height, width, cell_size, unit): feature_image = np.zeros([height, width]) cell_width = cell_size / 2 max_mag = np.array(cell_gradient).max() for x in range(cell_gradient.shape[0]): for y in range(cell_gradient.shape[1]): cell_grad = cell_gradient[x][y] cell_grad /= max_mag angle = 0 angle_gap = unit for magnitude in cell_grad: angle_radian = math.radians(angle) x1 = int(x * cell_size + magnitude * cell_width * math.cos(angle_radian)) y1 = int(y * cell_size + magnitude * cell_width * math.sin(angle_radian)) x2 = int(x * cell_size - magnitude * cell_width * math.cos(angle_radian)) y2 = int(y * cell_size - magnitude * cell_width * math.sin(angle_radian)) cv2.line(feature_image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude))) angle += angle_gap return feature_image 提取的特征图为，图中白色的线段即为提取的特征， 完整代码如下， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import cv2import numpy as npimport mathimport matplotlib.pyplot as pltimg = cv2.imread("../data/2007_000129.jpg", cv2.IMREAD_GRAYSCALE)def compute_image_gradient(img): x_values = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5) y_values = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5) magnitude = abs(cv2.addWeighted(x_values, 0.5, y_values, 0.5, 0)) angle = cv2.phase(x_values, y_values, angleInDegrees=True) return magnitude, angledef choose_bins(gradient_angle, unit, bin_size): idx = int(gradient_angle / unit) mod = gradient_angle % unit return idx, (idx + 1) % bin_size, moddef compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit): centers = [0] * bin_size for i in range(cell_magnitude.shape[0]): for j in range(cell_magnitude.shape[1]): strength = cell_magnitude[i][j] gradient_angle = cell_angle[i][j] min_angle, max_angle, mod = choose_bins(gradient_angle, unit, bin_size) print(gradient_angle, unit, min_angle, max_angle) centers[min_angle] += (strength * (1 - (mod / unit))) centers[max_angle] += (strength * (mod / unit)) return centersdef normalized(cell_gradient_vector): hog_vector = [] for i in range(cell_gradient_vector.shape[0] - 1): for j in range(cell_gradient_vector.shape[1] - 1): block_vector = [] block_vector.extend(cell_gradient_vector[i][j]) block_vector.extend(cell_gradient_vector[i][j + 1]) block_vector.extend(cell_gradient_vector[i + 1][j]) block_vector.extend(cell_gradient_vector[i + 1][j + 1]) mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector)) magnitude = mag(block_vector) if magnitude != 0: normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector] block_vector = normalize(block_vector, magnitude) hog_vector.append(block_vector) return hog_vectordef visual(cell_gradient, height, width, cell_size, unit): feature_image = np.zeros([height, width]) cell_width = cell_size / 2 max_mag = np.array(cell_gradient).max() for x in range(cell_gradient.shape[0]): for y in range(cell_gradient.shape[1]): cell_grad = cell_gradient[x][y] cell_grad /= max_mag angle = 0 angle_gap = unit for magnitude in cell_grad: angle_radian = math.radians(angle) x1 = int(x * cell_size + magnitude * cell_width * math.cos(angle_radian)) y1 = int(y * cell_size + magnitude * cell_width * math.sin(angle_radian)) x2 = int(x * cell_size - magnitude * cell_width * math.cos(angle_radian)) y2 = int(y * cell_size - magnitude * cell_width * math.sin(angle_radian)) cv2.line(feature_image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude))) angle += angle_gap return feature_imagedef main(img): cell_size = 16 bin_size = 9 unit = 360 // bin_size height, width = img.shape magnitude, angle = compute_image_gradient(img) cell_gradient_vector = np.zeros((height // cell_size, width // cell_size, bin_size)) for i in range(cell_gradient_vector.shape[0]): for j in range(cell_gradient_vector.shape[1]): cell_magnitude = magnitude[i * cell_size:(i + 1) * cell_size, j * cell_size:(j + 1) * cell_size] cell_angle = angle[i * cell_size:(i + 1) * cell_size, j * cell_size:(j + 1) * cell_size] cell_gradient_vector[i][j] = compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit) hog_vector = normalized(cell_gradient_vector) hog_image = visual(cell_gradient_vector, height, width, cell_size, unit) plt.imshow(hog_image, cmap=plt.cm.gray) plt.show()if __name__ == '__main__': img = cv2.imread('../data/2007_002293.jpg', cv2.IMREAD_GRAYSCALE) cv2.imshow("origin", img) cv2.waitKey() main(img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[效率工具 | Windows下一款强大的启动搜索工具]]></title>
    <url>%2F2019%2F07%2F02%2Ftools-wox%2F</url>
    <content type="text"><![CDATA[前言对于大多数人来说，日常生活和工作中接触较多的软件和工具就是浏览器、专业软件、翻译软件、笔记、办公等。其实有很多软件在名气上虽然不如这些商业软件，但是功能却丝毫不输这些知名软件。在工作中能够大大提高办公效率，而且内存占用小、免费开源。大家都知道windows自带的文件浏览器查找文件是一件非常令人痛苦的事情，不仅速度缓慢，而且准确度出奇的低，让人感觉很鸡肋。但是当我们要找一个文档时却忘记放在哪里，挨个硬盘去翻更加令人感到折磨。所以不得不去借助一些高效的搜索工具，其中用的较多、名气较大的就是everything。我个人也一直在用这款工具，的确非常强大，快速、支持正则表达式匹配。它作为一个文件搜索工具的确很称职，但是当我们想要更多扩展功能，例如用于程序启动工具时everything就显得有些不足了。之前我介绍过一款工具叫做Listary，能够完美的与everything结合，既能涵盖everything强大的搜索功能，还能融合Listary实用的启动功能。本文再给大家介绍一款与Listary类似的工具—Wox，有相同之处，也有很大的差异之处，各位可以根据自己的喜好进行选择。 Wox Wox是一款启动器。这就是它与Listary的最大的不同之处—定位不同。Listary本身兼顾搜索与启动，但是在搜索方面不如everything，如果想使用更加丰富的搜索功能需要在设置里配置一下everything，如果满足于Listary提供的快速搜索功能则无需配置。而Wox的定位就是一个简单、纯净的启动器。它可以快速的启动本机安装的各种程序、文件、网页等。当然，它也可以用于文件搜索，它指定的后端搜索工具是everything，所以在打开Wox之前需要先启动everything，这样才能够使用强大的搜索功能。它不仅可以用于搜索程序和文件，还可以配置各种丰富的插件满足更多场景的需求，例如计算器、天气、翻译、网页搜索等。 Wox与Listary前面提到了，Wox与Listary有很多类似之处： 搜索 启动器 配合everything使用 但是Wox也有很多特别之处是Listary无法比拟的，Wox的特别之处主要有如下几点： 支持丰富的插件 支持自己定义插件 支持多种主题切换 支持自定义快捷键 支持丰富插件Wox的插件主要分类两种： 系统插件 第三方插件 系统插件不需要关键字唤醒，直接用Alt + Space调出Wox的工具栏输入相应的命令即可，系统插件主要包含如下几类： 程序插件 颜色插件 控制面板插件 计算器插件 网址插件 Web搜索插件 命令行插件 文件夹插件 拿其中几个举个例子， 程序插件 Alt+空格键激活Wox，然后输入要启动的程序即可， 计算器插件 计算器对于很多人来说虽然不是主要的工作工具，但是偶尔会用到，当我们需要用计算器的时候就需要点击windows图标，搜索“计算器”，这样比较麻烦，Wox集成了计算器插件，激活Wox后输入要计算的公式即可， 网址插件 当我们要浏览某个网站时往往需要打开浏览器-&gt;在地址栏输入网址，Wox的浏览器插件大大简化这个过程，只需要激活Wox，输入相应网址即可， 其他还有很多实用的系统插件，可以查看网站进行了解， http://doc.wox.one/zh/basic/ 除了Wox自带的系统插件，Wox还提供了多大230款第三方插件，其中就包含有道翻译、天气查询、Steam、Putty、二维码、维基百科、书签搜索、待办事项、进制转换、哔哩哔哩、Skype、FileZilla、Stack Overflow、沪江日语等等。只需要下载安装一下即可，而且Wox提供了多选、简单的安装方式， 安装第三方插件 命令安装 这是最简单的一种安装方式，使用wpm进行插件的安装、卸载管理， 123456789# 安装插件wpm install &lt;插件名称&gt;# 卸载插件wpm uninstall &lt;插件名称&gt;# 列出已安装插件wpm list 手动安装 如果由于网络、代理等原因无法命令安装，可以打开插件主页[http://www.wox.one/plugin]下载到本地(以.wox结尾),拖动到Wox搜索框进行安装， 支持自己定义插件除了官网提供的系统插件和第三方插件之外，Wox还支持自定义插件，它支持以下3种方式来定义插件， plugin.json C# Python Wox与插件之间的通信原理： 支持多种主题切换 Wox安装后会发现自带BlurBlack、BlurWhite、Dark、Gray、Light、Metro Server、Pink七种主题，除了上述提到的7种主题之外，还可以在官网自定义主题，配置之后下载主题(.xaml文件)，放置到C:\Users\YourUserName\AppData\Local\Wox\app-1.3.524\Themes路径下，重启Wox即可。 支持自定义快捷键这一点也是Wox吸引人的一点，它支持自定义快捷键。如果觉得Alt+空格启动程序、文件夹还不够快捷，可以把常用的命令保存到快捷键，这样当使用快捷键时能够快速达到目的。 例如，我想百度搜索“哈尔滨工业大学”，使用Wox的方式是这样的， Alt + 空格激活Wox 输入”bd 哈尔滨工业大学” 这样比起”打开浏览器-&gt;打开百度-&gt;搜索”已经便捷了很多，但是还有更便捷的，就是Wox支持的快捷键。 可以把常用的命令添加到快捷键，例如把”bd 哈尔滨工业大学”添加为快捷键”Ctrl+Alt+H”,能够同时激活Wox并输入相应的命令，然后按Enter键即可搜索。]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
        <tag>工具</tag>
        <tag>使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐一份热门机器学习资源]]></title>
    <url>%2F2019%2F07%2F01%2Fhomemade-machine-learning%2F</url>
    <content type="text"><![CDATA[前言最近几年人工智能异常火热，随之而来的就是各种针对入门者的学习资源，其中不乏很多经典的教程例如吴恩达的《机器学习》、《深度学习工程师》，但是也有很多千篇一律、照本宣科的学习资源。在学习进阶过程中很多人会到GitHub寻找一些可以动手实践的机器学习项目，会发现GitHub上会有和机器学习相关的各种awesome，恨不得把所有和机器学习、深度学习的资源都囊括进去。这样虽然全面，但是我认为它的价值并不高。我们之所以希望有经验者推荐学习资源，就是因为时间、精力有限，希望能够在鱼龙混杂的学习资源里筛选出真正有价值，或者与众不同的，能够让我们利用有限的精力和时间内真正学会一些东西。近期GitHub有一个关于机器学习的热门开源项目，homemade-machine-learning，目前已经11k+个star，近一周达到1.1k+，经过一段时间的学习发现这的确一个不错的学习项目，下面就详细介绍一下这个项目。 Homemade Machine Learning 开门见山，这个开源项目主要有以下几个优点： 少而精 不依赖python第三方库 详细解释它们背后的数学原理 交互式Jupyter notebook演示程序 丰富易懂的示例 这个项目用Python实现了目前热门、使用的一些机器学习算法，而不是像很多开源项目那样，从头至尾把每个机器学习算法都实现一遍。换句话说，这个开源项目追求“少而精”，它分别从监督学习、非监督学习、神经网络、异常检测、回归、分类这些类别中选择一种算法进行详细阐述算法背后的数学原理，然后使用jupyter notebook交互式的演示，随后会用多个示例进行实现，动手操作，不依赖集成的python第三方库，更容易理解机器学习算法的原理。 项目概括该项目主要包括如下几个方面的机器学习算法： 监督学习 无监督学习 异常检测 神经网络 其中监督学习又分为回归和分类，回归算法选取的是比较常用的线性回归，分类算法选取的是比较实用的逻辑回归。无监督学习中主要针对聚类进行讲解，项目中选取的是热门的k-means。异常检测是指通过大多数数据来检测出有显著差异的事件、观测结果，在数据处理、图像处理都有应用。神经网络中选择的是多层感知机。 安装首先要保证电脑上正确的安装了Python，然后安装一些项目依赖， 1pip install -r requirements.txt requirements: 1234567jupyter==1.0.0matplotlib==3.0.1numpy==1.15.3pandas==0.23.4plotly==3.4.1pylint==2.1.1scipy==1.1.0 如果要使用jupyter notebook，需要在命令行输入下面命令， 1jupyter notebook 然后会在浏览器中打开如下窗口， 详细介绍数学原理 我认为这是这个项目吸引人的地方，也是它与众不同的地方，它和很多项目不同，浮于表面，把很多环节都认为是既定的去阐述，有一些初学者会看的云里雾里，不明白“为什么是这样？”这个项目则不同，它详细、深入的阐述每个算法背后的数学原理，循序渐进，配合可视化很容易让人理解。 详细编码过程 该项目不过多依赖tensorflow、pytorch、keras这些高度集成的机器学习平台，它从梯度下降到损失函数、从训练到预测都是一步一步实现，尽量减少对高度集成第三方库的依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@staticmethoddef gradient_descent(data, labels, initial_theta, lambda_param, max_iteration): """Gradient descent function. Iteratively optimizes theta model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param initial_theta: initial model parameters. :param lambda_param: regularization parameter. :param max_iteration: maximum number of gradient descent steps. """ # Initialize cost history list. cost_history = [] # Calculate the number of features. num_features = data.shape[1] # Launch gradient descent. minification_result = minimize( # Function that we're going to minimize. lambda current_theta: LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Initial values of model parameter. initial_theta, # We will use conjugate gradient algorithm. method='CG', # Function that will help to calculate gradient direction on each step. jac=lambda current_theta: LogisticRegression.gradient_step( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Record gradient descent progress for debugging. callback=lambda current_theta: cost_history.append(LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param )), options=&#123;'maxiter': max_iteration&#125; ) # Throw an error in case if gradient descent ended up with error. if not minification_result.success: raise ArithmeticError('Can not minimize cost function: ' + minification_result.message) # Reshape the final version of model parameters. optimized_theta = minification_result.x.reshape((num_features, 1)) return optimized_theta, cost_history@staticmethoddef gradient_step(data, labels, theta, lambda_param): """GRADIENT STEP function. It performs one step of gradient descent for theta parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Initialize number of training examples. num_examples = labels.shape[0] # Calculate hypothesis predictions and difference with labels. predictions = LogisticRegression.hypothesis(data, theta) label_diff = predictions - labels # Calculate regularization parameter. regularization_param = (lambda_param / num_examples) * theta # Calculate gradient steps. gradients = (1 / num_examples) * (data.T @ label_diff) regularized_gradients = gradients + regularization_param # We should NOT regularize the parameter theta_zero. regularized_gradients[0] = (1 / num_examples) * (data[:, [0]].T @ label_diff) return regularized_gradients.T.flatten()@staticmethoddef cost_function(data, labels, theta, lambda_param): """Cost function. It shows how accurate our model is based on current model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Calculate the number of training examples and features. num_examples = data.shape[0] # Calculate hypothesis. predictions = LogisticRegression.hypothesis(data, theta) # Calculate regularization parameter # Remember that we should not regularize the parameter theta_zero. theta_cut = theta[1:, [0]] reg_param = (lambda_param / (2 * num_examples)) * (theta_cut.T @ theta_cut) # Calculate current predictions cost. y_is_set_cost = labels[labels == 1].T @ np.log(predictions[labels == 1]) y_is_not_set_cost = (1 - labels[labels == 0]).T @ np.log(1 - predictions[labels == 0]) cost = (-1 / num_examples) * (y_is_set_cost + y_is_not_set_cost) + reg_param # Let's extract cost value from the one and only cost numpy matrix cell. return cost[0][0] 丰富示例 理解了算法背后的数学原理，跟着作者一步一步实现了算法，要想更加深入的理解就需要把算法应用到不同方面，本项目提供了丰富的示例，其中不乏MNIST这类经典的演示样例。 其中每个项目后面都包含至少一个示例，可以获取对应的数据进行实现，这样对算法的理解和应用会有更加清晰而深入的认识。]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Github</tag>
        <tag>资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文熟练掌握Docker使用]]></title>
    <url>%2F2019%2F06%2F30%2Flearning-docker%2F</url>
    <content type="text"><![CDATA[Docker是由dotCloud公司发起并与2013年开源的一个项目，一径开源就备受欢迎，其主要项目至今在github已经54k个star。它是使用Go语言开发实现，基于Linux内核cgroup、namespace以及AUFS类等技术对进程进行封装隔离，属于一种操作系统层面的虚拟化技术。此后，进一步开发开始使用runC和containerd，进一步封装，从文件系统到网路互联，再到进行都进行隔离，极大的简化了容器的创建和维护，使得Docker比虚拟机更为轻便、快捷。 为什么要用docker？Docker与传统虚拟机一样，同属于虚拟化技术，但是它拥有众多虚拟机无法比拟的优势： 持续交付和部署 更快的迁移 更高效的利用系统资源 更快的启动时间 一致的运行环境 更轻松的维护和扩展 容器与虚拟机对比详情： 对于大多数开发人员感受最为就是前两点：持续交付和部署、更快的迁移。 我想这对于很多开发人员都是一个很头疼的问题，在开发过程中会遇到这种抱怨：“在我电脑上可以运行啊？为什么换一台电脑就不行了？” 虽然诸如maven、nodejs的package.json、Python的requirement.txt的出现使得迁移变得简单，但是它们更多的是使得在第三方工具包的迁移方面变得简单方面，但是在系统和开发环境方面却没有什么作用。docker确保了直行环境的一致性，可以在多平台上运行，使得应用迁移更加容易。此外，docker使用分层存储以及镜像技术，使得应用重复部分的复用更加容易，可以基于基础镜像做更多的扩展，使得系统的维护变得更加简单。 基本概念使用docker接触最多的就是以下3个概念， 镜像：image 容器：container 仓库：repository 了解这三个概念，对容器的整个生命周期便有了认识。在这里，我用简单的语言对上述3个概念进行描述 镜像：进行就相当于一个精简化的文件系统，例如官方提供的Ubuntu镜像，就只包含了最小化的root文件系统。 容器：容器是一个拥有自己root文件系统、自己网络配置、自己命名空间的进程。镜像和容器就像是编程中的类和实例，镜像时静态的定义，而镜像运行时的实体是容器。什么是类和实例？举一个编程的例子阐述一下， 1234567891011121314# 类class HelloWorld: def __init__(self, x, y): self.x = x self.y = y def add(self): return self.x + self.y# 实例hello_world = HelloWorld(2, 3)print(hello_world.add())&gt;&gt;&gt; 5 其中HelloWorld是类，hello_world是实例，类比一下，就能够理解容器和镜像之间的关系。 仓库：docker镜像仓库就如同github代码仓库一样，当一个人构建一个项目，想在其他其他电脑上运行这个项目，那么就去从代码仓库把这个项目克隆下来。docker镜像仓库也是这样，当构建一个镜像之后，想在其他服务器上使用这个镜像，就需要一个集中的存储、分发服务，仓库就是这样的服务。官方的镜像仓库是DockerHub，它存储了丰富的镜像，但是国内拉取镜像速度缓慢，因此可以使用国内镜像仓库进行替代，例如阿里云镜像仓库、网易云镜像仓库、DaoCloud镜像市场等。 安装docker目前支持Linux、Windows 10、macOS，下面就一个Linux安装为例， APT方式安装 首先安装HTTPS软件包和CV证书， 123456$ sudo apt-get update$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 添加软件源GPG密钥， 1$ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add 添加docker软件源， 1234$ sudo add-apt-repository \ "deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable" 安装docker ce, 12$ sudo apt-get update$ sudo apt-get install docker-ce 添加用户组 docker命令会使用Unix socket与docker引擎通讯，因此每次使用时会需要root权限，也就是需要在命令前加sudo比较麻烦，为了避免这个麻烦可以把建立docker组并把当前用户加入docker用户组， 12$ sudo groupadd docker$ sudo usermod -aG docker $USER 启动、退出、重启docker 123$ systemctl start docker$ systemctl stop docker$ systemctl restart docker 也可以使用， 123$ service docker start$ service docker stop$ service docker restart Dockerfile理解docker中一些基本概念，并完成docker安装下一步就是学习docker的使用。对于大多数开发人员来说，docker使用过程中最为核心的部分就是Dockerfile。 Dockerfile是一个文本文件，它包含了一些指令，docker镜像的构建就是通过Dockerfile中的这一条一条的指令完成的。也就是说，要构建一个镜像，就需要一个Dockerfile，然后根据自己的需求配置一些指令集合，下面就看一下Dockerfile中使用的一些指令。 FROM：指定基础镜像 定制我们的镜像，是需要以一个镜像为基础的，就是基础镜像，例如Ubuntu、 nginx、postgres、mysql等，例如，FROM Ubuntu:16.04，如果本地有Ubuntu基础镜像则使用本地基础镜像，如果没有则会到官方镜像仓库拉取，16.04是镜像版本号，如果不指定则会拉取lastest。 RUN：执行命令 RUN指定我们在构建镜像时需要执行的命令，比如apt-get install安装某个软件，pip install安装Python依赖包，配置软件源，配置时区等， 例如，RUN apt-get install python3。 ADD和COPY：文件操作 ADD和COPY是两个功能类似的指令，一般优先使用COPY，它比ADD更透明，它的功能是将本地文件拷贝到容器中，例如，COPY ./ /home/jackpop/test。 WORKDIR：指定工作路径 指定镜像的运行时的工作路径，例如，WORKDIR /home/jackpop/test 。 ENTRYPOINT：设置镜像主命令 指定镜像运行是运行的命令，例如, ENTRYPOINT [“python”, “-m”, “main”]。 LABEL：添加标签 可以为镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。 CMD：执行目标镜像中包含的软件 如果创建镜像的目的是为了部署某个服务，可能会执行某种形式的命令，可以包含参数。 EXPOSE：指定监听端口 给外部访问指定访问端口。 ENV：环境变量 为了方面程序运行，有时需要更新环境变量。 VOLUME：暴露数据库存储文件 USER：指定当前用户 其中常用的命令就是FROM、COPY、WORKDIR、RUN、ENTRYPOINT。 常用命令了解了Dockerfile的常用指令，我们该怎么对镜像和容器进行操作呢？下面就来学习一下docker常用的一些命令， 备注：由于我已经把当前用户加入到docker用户组，所以下面命令没有加sudo，如果没有加用户组需要使用sudo docker。 查看本地镜像 123$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 ****** 10 days ago 119MB 查看容器 123$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES*** *** *** *** *** *** *** *** 启动、停止、重启容器 123$ docker start $container_id$ docker stop $container_id$ docker restart $container_id 退出和进入镜像 12$ exit$ docker exec $container_id /bin/bash 启动镜像 1$ docker run $image_id 可以用—p和—dns指定端口和dns来配置网络。 container_id是容器ID，image_id是镜像ID。 拉取镜像 1$ docker image pull ubuntu 从Dockerfile创建镜像 1$ docker build 从一个修改的容器创建镜像 1$ docker commit 容器与本地之间复制文件 1$ docker cp 推送镜像 1$ docker push 为镜像打标签 1$ docker tag 重命名容器 1$ docker rename 删除容器 1$ docker rm 删除镜像 1$ docker rmi 搜索镜像 1$ docker search docker常用命令概括： 实践创建项目 123Test/├── Dockerfile└── main.py 写一个简单的测试程序 1234567891011121314151617181920# main.pyimport loggingfrom time import sleepimport numpy as nplogging.basicConfig(level=logging.DEBUG, format="'%(asctime)s - " "%(filename)s[line:%(lineno)d] - " "%(levelname)s: %(message)s")def main(): for i in range(10): logging.debug(np.random.randint(0, 5)) sleep(0.1)if __name__ == '__main__': main() Dockerfile 这是构建镜像中的重点部分， 1234567891011FROM ubuntu:16.04COPY ./ /home/Test_dockerWORKDIR /home/Test_dockerRUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip \&amp;&amp; ln -s pip3 /usr/bin/pip \&amp;&amp; ln -sf /usr/bin/python3 /usr/bin/python \&amp;&amp; rm -rf ls /var/cache/apt/* \ENTRYPOINT ["python3", "-m", "main"] 进入项目根目录 1$ cd Test 开始创建 1$ docker build test:v1.0 . test是指定构建镜像的名称，v1.0指定镜像标签，如果不指定，镜像名称和标签会显示为。 运行镜像 1234567891011$ docker run $image_id'2019-06-29 12:26:38,298 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,399 - main.py[line:13] - DEBUG: 2'2019-06-29 12:26:38,499 - main.py[line:13] - DEBUG: 1'2019-06-29 12:26:38,599 - main.py[line:13] - DEBUG: 3'2019-06-29 12:26:38,699 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,799 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:38,900 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,000 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,100 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,200 - main.py[line:13] - DEBUG: 2 当然也可以在基础镜像的基础上进行修改来创建我们的镜像，例如，我们拉取一个Ubuntu基础镜像，可以启动镜像后安装我们需要的软件和环境，然后利用docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]来创建一个新镜像。 延伸阅读除了基础的docker之外，还有一些高级的docker开源工具，比较知名的有如下3项， docker compose docker machine docker swarm 其中docker compose是官方编排项目之一，用于快速在集群中部署分布式应用。docker machine同样是官方编排项目之一，负责在多种平台上快速安装docker环境。docker swarm提供docker容器集群服务，是docker官方对容器云生态进行支持的核心方案。 除此之外，还有一些比较知名的集群管理系统，例如， Mesos Kubernetes 其中Mesos是来自UC Berkeley的集群资源管理开源项目，它可以让用户很容易实现分布式应用的自动化调度。Kubernetes是由Google团队发起并维护的给予docker的开源容器集群管理系统，应用比较广泛，它不仅支持场景的云平台，而且支持内部数据中心。 学习资源上述所讲的常用命令、指令含义等对于日常开发使用已经够用了，如果对Docker更深入的内容，例如，数据管理、安全、底层实现、容器与云计算等感兴趣可以选取其他的学习资料。在这里我推荐一份我认为不错的学习资料。就是yeasy大神在github开源的一份详细的docker教程—docker_practice，目前docker_practice项目在github已经13.7k个star，想深入学习的可以查看github项目， 也可以查看gitbooks， 或者关注公众号【平凡而诗意】回复关键字”dk”获取pdf和epub版教程， 更多内容请关注公众号【平凡而诗意】]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVPR2019最佳论文解读]]></title>
    <url>%2F2019%2F06%2F28%2FCVPR2019%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[前言 CVPR，全称IEEE Conference on Computer Vision and Pattern Recognition，与ECCV(Europeon Conference on Computer Vision)，ICCV( IEEE International Conference on Computer Vision)并称为计算机视觉领域三大会议，均为计算机视觉领域的顶级会议。由于近几年计算机视觉的异常火热，CVPR也就成为很多计算机视觉领域研究者趋之若鹜的盛宴，它的受关注程度更是今非昔比。CVPR2019于2019年6月16日在美国召开，此次会议共收到来自全球14104位研究者提交的5160篇文章，同比2018年增长56%，一举打破记录，受欢迎程度可见一斑。 CVPR2019最终共接收1294篇文章，尽管CVPR被计算机视觉领域视为顶尖，我个人认为，其中不乏质量平平的水文，真正令人印象深刻，几年之后依然被人所熟知且实用，并在算法思想方面取得跨越的却寥寥无几。闲话说完，回到本文的重点CVPR2019最佳论文，该荣誉最终由卡耐基梅隆大学、多伦多大学、伦敦大学学院的多位研究者斩获，论文名称为A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction，接下来，我详细解读一下这篇文章。 数学符号含义$s$ 光源上的点$v$ 可见场景内的点$x$ 不可见场景内的点$d$ 检测器上的点$\tau_{\mathcal{F}}$ 费马路径长度$I(\tau ; \boldsymbol{v})$ 瞬态 概念解释瞬态(transients):一种测量值，用于重建隐藏形状信息的大多数方法采用快速调制光源已经传感器来记录光子强度和旅行时间的测量值。费马路径(Fermat paths):首先返回的光子路径的超集合。费马路径长度(Fermat pathlengths):顾名思义，就是通过光速等计算出来的离散路径长度。 算法详解 目前大多数计算机视觉领域的研究都是围绕着视觉可见范围内的研究，但是理解视野范围之外的场景在很多领域却有着非常重要的应用，因此，这使得这项研究更加具有价值。被动方式通过分析隐藏场景所投射的阴影来粗略估计物体的运动和结构，或者利用光的相干性来定位隐藏对象。这些方法没有足够的信息来精确计算位置隐藏场景的三维形状。主动方式提取隐藏场景的附加信息时可能的。大多数重建隐藏形状信息的方法都是用调制光源和时间分辨传感器、超快光电二极管等，这些传感器不仅记录入射光子的强度，还在时间分辨率范围内记录它们到达的时间，这种测量称为瞬态。 大多数主动技术都是通过测量一个已知可见场景的不同位置的瞬态，然后根据已经获取的辐射成像逆向来进行三维重建，例如椭圆反投影、正则化线性系统、光锥变换等。这些方法主要有两个缺点： 它们依赖于辐射测量信息 为了简化反演问题，所有现有的重建技术都依赖于非视线场景的Lambertian 反射假设 在这篇文章中，作者提出一种使用视线以外场景的瞬态测量得到的几何信息的方法，克服了上述的限制。简言之，它主要使用视线内和视线外场景之间的一种称之为费马路径的几何路径星系，通过观察发现这些路径遵循镜面或者物体边界特点的反射定理。作者证明，费马路径对应于瞬态测量中的不连续性，不连续点的时间位置仅是视线外场景对象的形状而不是其反射率。利用上述理论，推导出一种精确重建视线外物体形状的算法，称之为费马流(Fermat Flow)。作者证明，费马路径长度的空间导数提供了一个简单的约束，它唯一地决定了隐藏场景点的深度和法线。这个导数是通过将光滑的路径函数拟合到一组稀疏的测量值上而得到，然后结合深度和法线信息来计算平滑网网格。概括一下，本文在隐藏物体重建方面主要包含以下3个步骤： 瞬态测量 求解费马流方程 表面拟合 测量瞬态 假设已经校准了从光源到可见点，和从可见点到检测器的距离 \mathcal{\tau\mathcal{V}}(\boldsymbol{v}) \triangleq\|s-v\|+\|d-v\|，那么可以通过光速等计算在非可见场景的路径长度， I(\tau ; \boldsymbol{v})=\int_{\mathcal{X}} f(\boldsymbol{x} ; \boldsymbol{v}) \delta(\tau-\tau(\boldsymbol{x} ; \boldsymbol{v})) \mathrm{d} A(p, q)其中 $\tau(\boldsymbol{x} ; \boldsymbol{v}) \triangleq 2 \cdot|\boldsymbol{x}-\boldsymbol{v}|,(p, q) \in[0,1]^{2} $是非可见物体表面的参数化表示。 费马流方程 给定测量的瞬态$I(\tau ; \boldsymbol{v})$ ，可以把它的离散性定义为对费马路径长度的贡献，每个路径长度约束了球面上的点的法线和曲率。这是本文的核心所在，给定一组费马路径长度，就可以得到隐藏物体表面点集的位置和法线。首先定义费马路径函数， \tau_{\mathcal{F}}(\boldsymbol{v})=\{\tau : I(\tau ; \boldsymbol{v}) \text { is discontinuous }\}在每个瞬态可以有多个不连续的路径长度，因此费马路径函数是一个多值函数 \boldsymbol{x}_{\mathcal{F}}=\boldsymbol{v}-\left(\tau_{\mathcal{F}}(\boldsymbol{v}) / 4\right) \nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})其中 $\boldsymbol{x}_{\mathcal{F}} $是隐藏物体球面上的点，因此，物体可以唯一的被可见点\boldsymbol{v}、路径长度、梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 重建，得到隐藏物体表面的点，然后通过一些简单的集合操作即可。但是就算路径长度的导数是一件非常难的事情，它和选取的可视面的形状、位置有密切的关系，为了简化，文中采用选取平面作为可视区域，得到的导数为， \begin{array}{l}{\nabla_{\boldsymbol{v}^{\tau} \mathcal{F}}(\boldsymbol{v})=} \\ {\left.\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}, \frac{\partial \tau_{\mathcal{F}}}{\partial y}, \sqrt{4-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}\right)^{2}-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial y}\right)^{2}}\right)\right|_{\boldsymbol{v}}}\end{array}表面拟合上述的步骤生成了一系列的有向点云，它的密度相当于在可视区域 \mathcal{V} 上的测量密度，然后，可以使用算法，利用正常信息，以更高的精度将曲面表示(如三角形网格)匹配到点云，给定这样一个初始的表面重建，在补充中，我们描述了一个基于高光路径扰动理论的优化过程，该过程对拟合表面进行了细化，以考虑由于梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 估计不准确而可能产生的误差。 实验结果 如图中所示，分别从两个视图中重建了一个有方向的点云，点按它们的法线着色。最后，我们将一个表面与点云相匹配，显示在右边的两个视图下。 扫描的对象跨越各种形状(凸，凹)和反射(半透明，光泽，镜面)。对于每一个物体，我们展示了环境光下的照片，以及它表面重建的两个视图。 更多我的作品Jackpop：【动手学计算机视觉】第一讲：图像预处理之图像去噪 Jackpop：【动手学计算机视觉】第二讲：图像预处理之图像增强 Jackpop：【动手学计算机视觉】第三讲：图像预处理之图像分割 Jackpop：【动手学计算机视觉】第四讲：图像预处理之图像增广 Jackpop：【动手学计算机视觉】第五讲：传统目标检测之特征工程 Jackpop：【动手学计算机视觉】第六讲：传统目标检测之Harris角点检测 Jackpop：【动手学计算机视觉】第七讲：传统目标检测之SIFT特征]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
