<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【动手学计算机视觉】第十一讲：卷积层、池化层与填充]]></title>
    <url>%2F2019%2F08%2F16%2Fcv-cnn-pool%2F</url>
    <content type="text"><![CDATA[前言从2012年AlexNet成名之后，CNN如同雨后春笋一样，出现了各种各样的Net，其中也有很多知名的，例如VGG、GoogleNet、Faster R-CNN等，每个算法都在前面研究工作的基础上做出了很大的改进，但是这些CNN模型中主要使用的组件却有很多重叠之处，这个组件主要有： 卷积层 池化层 激活函数 优化函数 全连接层 Dropout 批量正则化 填充padding …… 其实一个CNN网络的模型搭建过程非常容易，现在有很多优秀的机器学习框架，例如tensorflow、pytorch、mxnet、caffe、keras等，借助这些机器学习框架搭建一个CNN网络模型只需要几十行代码即可完成，而且使用到的函数屈指可数，难度并不大。而上述提到的这些组件却是CNN中非常核心的概念，了解它们是什么？有什么价值？在哪里起作用？掌握这些之后再回头看这些CNN模型就会发现轻而易举，因此，这几节会先把上述这些技术介绍一下，然后逐个讲解如何一步一步搭建那些成熟优秀的CNN模型。 由于上述每个技术都涉及很多知识点，本文为了效率就用简单的语言介绍它是什么？有什么价值？具体详细的内容可以阅读文章或者外网资料详细了解，本文主要介绍3点： 卷积层 池化层 填充padding 卷积层介绍 卷积神经网络(convolutional neural network)，从它的名称就可以看出，卷积是其中最为关键的部分。在前面讲解图像去噪和图像分割中提到了一些用于分割和去噪的算法，例如sobel算子、中值滤波，其实卷积的概念和这些有相同之处。 把输入图像看作是一个n维矩阵，然后拿一个mm维(m&lt;n)的卷积核(或者称为滤波器)，从图像的左上角开始沿着从左至右、*从上之下进行”扫描”，每当移动到一个窗口后和对应的窗口做卷积运算(严格的说是互相关运算)，用直白的话来说就是对应元素相乘之后加和。 移动过程中涉及一个重要的概念—步长(stride)，它的意思就是”扫描”过程中每次移动几个像素，如果步长stride=1，那么从左至右、从上之下逐个像素的移动。 以上图二维卷积运算为例，输入图像为一个5*5的矩阵，卷积核为3*3，以步长stride=1进行卷积运算，在左上角这个窗口每个对应元素先相乘再加和，即， 0*0+1*1+2*2+1*5+2*6+0*7+2*0+1*1+0*2=23以这种方式逐个窗口进行计算，就得到图中等号右边的输出结果。 tensorflow使用 在tensorflow中关于卷积层的函数为， 1tensorflow.nn. conv2d(input, filter, strides, padding) 其中参数分别为： input：输入数据或者上一层网络输出的结果 filter：卷积核，它的是一个1*4维的参数，例如filter=[5, 5, 3, 96]，这4个数字的概念分别是卷积核高度、卷积核宽度、输入数据通道数、输出数据通道数 strides：这是前面所讲的步伐，同卷积核一样，它也是一个1*4维的参数，例如strides=[1, 2, 2, 1]，这4个数字分别是batch方向移动的步长、水平方向移动的步长、垂直方向移动的步长、通道方向移动的步长，由于在运算过程中是不跳过batch和通道的，所以通常情况下第1个和第4个数字都是1 padding：是填充方式，主要有两种方式，SAME, VALID，后面会讲什么是填充 池化层介绍 池化层和卷积层一样，是CNN模型必不可少的一个部分，在很多卷积层后会紧跟一个池化层，而且在统计卷积神经网络时，池化层是不单独称为网络层的，它与卷积层、激活函数、正则化同时使用时共同称为1个卷积层。 池化层又成为下采样或者欠采样，它的主要功能是对于特征进行降维，压缩数据和参数量，避免过拟合，常用的池化方式有两种： 最大池化 平均池化 以最大池化为例介绍一下它是怎么实现的， 和卷积层类似，池化层也有窗口和步长的概念，其中步长在里面的作用也是完全相同的，就是窗口每次移动的像素个数，所以不再赘述。 池化层的窗口概念和卷积层中是截然不同的，在卷积层中每移动到一个窗口，对应的卷积核和输入图像做卷积运算。而在池化层中，窗口每移动到一个位置，就选择出这个窗口中的最大值输出，如果是平均池化就输出这个窗口内的平均值。 tensorflow使用 tensorflow中池化运算的函数为， 1tensorflow.nn.max_pool(value, ksize, strides, padding) 从函数的参数即可看出来，它和卷积层非常相似，它的参数概念分别是， value：输入数据或者上一层网络输出的结果 ksize：卷积核，它的是一个1*4维的参数，例如ksize=[1, 3, 3, 1]，这4个数字的概念分别是batch维度池化窗口、池化窗口高度、池化窗口宽度、通道维度窗口尺寸，由于在batch和通道维度不进行池化，所以通常情况下第1和第4个元素为1 strides：这和卷积层中相同 padding：这和卷积层中的也相同 填充在前面讲解卷积层和池化层时都提到了一个概念—填充，可见它是非常重要的。什么是填充？SAME, VALID这两种填充方式又有什么区别？下面来介绍一下。 从前面卷积层和池化层可以看出，卷积层和池化层的输出尺寸大小和选取的窗口大小有着密切关系，以卷积层为例，上述输入为5*5，但是输出为3*3，输出尺寸变小了，而且在输入图像的四周的元素只被卷积了一次，中间的元素却被利用多次，也就是说，如果是一副图像，图像四周的信息未被充分提取，这就体现了填充的价值， 保持边界信息 使得输入输出图像尺寸一致 那怎么样达到上述这2个目的？就是通过填充，一般情况下是在图像周围填充0，如下， 如上图所示，在输入图像周围填充0，然后通过卷积运算，输入和输出的尺寸都为5*5。当然，这是针对卷积核为3*3情况下，外层填充1层，具体填充几层，要根据卷积核大小而定。 然后回到前面所提到的，tensorflow中填充padding参数有两个选项：SAME, VALID，它们有什么区别呢 ？ VALID：不进行填充 SAME：填充0，使得输出和输入的尺寸相同，就如同上面这个例子。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[效率工具 | 推荐一款提高Python编程效率的神器]]></title>
    <url>%2F2019%2F08%2F13%2Fkite%2F</url>
    <content type="text"><![CDATA[前言“AI自动补全工具”，这个其实很久之前就有所耳闻，但是我却始终没有去尝试，因为，在我看来这两年人工智能泡沫太严重，各行各业都在蹭AI的热度，我想，也许”AI自动补全工具”也只不过是一个噱头吧。 在工作中，对于Python开发我一直都是以pycharm为主力。它也是Python开发中非常知名的一款IDE，支持DEBUG、格式提示、快速补全等等，有着非常吸引人的优点。尽管它非常臃肿、启动速度非常缓慢，但是对于追求补全速度的我来说，我还是选择忍受它的种种不足。 直到前不久在开发过程中发生的几次问题让我忍无可忍，我决心换掉这款工具，主要有如下几个原因： 内存占用大：16G的内存，pycharm占据了1G以上，使得电脑卡顿 license服务器崩溃：购买的license总是莫名其妙的出问题 臃肿：pycharm很强大，但是它的强大是建立在开启了很多辅助工具的基础上，这使得它非常臃肿卡顿 于是，我开始尝试不同的工具，VIM、vscode、sublime等。其中VIM在补全速度方面还可以，但是在windows下无法使用，而我有时在服务器下开发、有时会在windows下开发。至于vscode和sublime，界面和启动速度等都没的说，但是补全功能太弱，虽然配置了几款所谓的强大插件，但是依然跟不上编码的速度，于是，我又回到了pycharm，直到我遇到这款神奇的工具—kite，让我有一种柳暗花明的感觉，实在太强大了。 甚至Python之父Guido van Rossum都说I really love the line-of-code completions in the new kite.com，可见这款工具多么强大。 有了这一款工具，再也不用繁琐的配置sublime、vscode中各种插件和设置项了。 kite安装 kite是一款安装包+插件的工具，首先需要到官网下载kite的安装包，安装作为引擎，安装之后打开相应的编辑器或IDE安装kite的插件，然后就可以使用了，不用像sublime、vscode那样需要安装一堆插件还要到设置中配置Python路径之类的。 安装包下载可以直接到官网进行下载： https://www.kite.com/download/ 我把安装包进行共享了，如果访问官网速度比较慢，无法下载的话，可以在公众号后台回复kite获取。 双击安装 为什么推荐这款工具？ 一款好的编程工具能够让编码效率事半功倍，它不仅避免我们逐个敲击代码，还避免我们去记忆一些函数的名称。目前有很多有名气的IDE\编辑器，pycharm、eclipse、spyder、Atom、sublime、vscode等，每个人都有自己的习惯和偏好，所以每个人心中都有自己最认可的工具。但是不可否认，pycharm在Python开发方面是使用最为广泛的一款，它最吸引我的一点就是补全速度。虽然sublime、vscode等也可以通过配置插件来实现Python自动补全，但是速度和效果等方面始终和pycharm有着巨大差距。 所以长久以来，尽管我也体会到它的种种缺点，我还是在坚持使用pycharm，直到最近我遇到这款kite之后。它是一款基于人工智能的代码补全和文档查询工具。我觉得完全可以脱离臃肿的pycharm，利用sublime、vscode这些轻量的编辑器与kite结合使用，即可以避免缓慢的开启速度，还可以实现不亚于pycharm的补全速度。 当然，kite的功能不仅限于补全，它主要包括： 代码自动补全 文档查询 代码自动补全 直接来看一下它的补全速度，非常快。 目前的代码自动补全工具大多数都是通过上下文匹配、扫描第三方库的方式实现补全，这样都是通过你输入一个单词，它去扫描，可想而知，速度自然会很慢。但是kite则不同，它是通过人工智能的方式进行补全，当你属于一个单词，它能够像谷歌搜索那样，预测你接下来会输入什么，并按相关性进行排序。 它不仅支持Python内置函数补全，还支持第三方工具包的补全。此外，它还支持一些模块的补全，例如if…main…，能够极大的节省编码的时间，提升编码效率，经过统计，Kite的人工智能可以帮助减少47%的击键次数。 文档查询 当我们使用一个第三方库时，例如numpy、tensorflow、scipy等，我们对其中很多函数怎么使用？需要传入哪些参数并不清楚。当然你可以上网搜索一下，但是我认为现在网上的学习资料鱼龙混杂，最好的方法还是看文档，这样比较权威、严谨。 但是问题是去哪看文档？而且，找文档也很耗时间啊。 kite不仅可以自动补全的问题，它还可以解决文档查询的问题。 打开kite，输入你想搜索的模块，即可找到你想要看的文档。而且它非常简洁， 怎么使用 传入参数 返回值 以最简单明了的几句话概括这个模块的使用方法。 支持平台 kite是一块完全免费的工具，它目前支持以下两个平台： windows linux 支持工具 kite支持以下几种IDE\编辑器： pycharm Atom vscode sublime vim 因此，你有多种可选项，可以根据自己的喜好进行配置。即便你对目前所使用的编辑工具补全速度已经很满意了，我认为也不妨使用一下kite，用它作为一款文档查询工具，能够使得阅读文档效率大大提升。 支持语言 官方把它定义为一款Python自动补全工具，但是我在使用vscode开发javascript时发现kite同样能够实现补全，而且效果也不错，至于C++、Java等其他语言，我没有尝试，暂不清楚，感兴趣的可以试一下。]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>实用</tag>
        <tag>插件</tag>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【进阶Python】第二讲：装饰器]]></title>
    <url>%2F2019%2F08%2F10%2F1-decorators%2F</url>
    <content type="text"><![CDATA[完整代码请查看github项目: advance-python 前言前段时间我发了一篇讲解Python调试工具PySnooper的文章，在那篇文章开始一部分我简单的介绍了一下装饰器，文章发出之后有几位同学说”终于了解装饰器的用法了”，可见有不少同学对装饰器感兴趣。但是那篇文章主要的目的是在介绍PySnooper，所以没有太深入的展开讲解装饰器，于是在这里就详细的介绍一些装饰器的使用。 装饰器是Python中非常重要的一个概念，如果你会Python的基本语法，你可以写出能够跑通的代码，但是如果你想写出高效、简洁的代码，我认为离不开这些高级用法，当然也包括本文要讲解的装饰器，就如同前面提到的代码调试神器PySnooper一样，它就是主要通过装饰器调用的方式对Python代码进行调试。 什么是Python装饰器？ 顾名思义，从字面意思就可以理解，它是用来"装饰"Python的工具，使得代码更具有Python简洁的风格。换句话说，它是一种函数的函数，因为装饰器传入的参数就是一个函数，然后通过实现各种功能来对这个函数的功能进行增强。 为什么用装饰器？ 前面提到了，装饰器是通过某种方式来增强函数的功能。当然，我们可以通过很多方式来增强函数的功能，只是装饰器有一个无法替代的优势--简洁。 你只需要在每个函数上方加一个@就可以对这个函数进行增强。 在哪里用装饰器？ 装饰器最大的优势是用于解决重复性的操作，其主要使用的场景有如下几个： - 计算函数运行时间 - 给函数打日志 - 类型检查 当然，如果遇到其他重复操作的场景也可以类比使用装饰器。 简单示例 前面都是文字描述，不管说的怎么天花烂坠，可能都无法体会到它的价值，下面就以一个简单的例子来看一下它的作用。 如果你要对多个函数进行统计运行时间，不使用装饰器会是这样的， 12345678910111213141516171819202122from time import time, sleepdef fun_one(): start = time() sleep(1) end = time() cost_time = end - start print("func one run time &#123;&#125;".format(cost_time)) def fun_two(): start = time() sleep(1) end = time() cost_time = end - start print("func two run time &#123;&#125;".format(cost_time)) def fun_three(): start = time() sleep(1) end = time() cost_time = end - start print("func three run time &#123;&#125;".format(cost_time)) 在每个函数里都需要获取开始时间start、结束时间end、计算耗费时间cost_time、加上一个输出语句。 使用装饰器的方法是这样的， 1234567891011121314151617181920def run_time(func): def wrapper(): start = time() func() # 函数在这里运行 end = time() cost_time = end - start print("func three run time &#123;&#125;".format(cost_time)) return wrapper@run_timedef fun_one(): sleep(1) @run_timedef fun_two(): sleep(1) @run_timedef fun_three(): sleep(1) 通过编写一个统计时间的装饰器run_time，函数的作为装饰器的参数，然后返回一个统计时间的函数wrapper，这就是装饰器的写法，用专业属于来说这叫闭包，简单来说就是函数内嵌套函数。然后再每个函数上面加上@run_time来调用这个装饰器对不同的函数进行统计时间。 可见，统计时间这4行代码是重复的，一个函数需要4行，如果100个函数就需要400行，而使用装饰器，只需要几行代码实现一个装饰器，然后每个函数前面加一句命令即可，如果是100个函数，能少300行左右的代码量。 带参数的装饰器通过前面简单的例子应该已经明白装饰器的价值和它的简单用法：通过闭包来实现装饰器，函数作为外层函数的传入参数，然后在内层函数中运行、附加功能，随后把内层函数作为结果返回。 除了上述简单的用法还有一些更高级的用法，比如用装饰器进行类型检查、添加带参数的的装饰器等。它们的用法大同小异，关于高级用法，这里以带参数的装饰器为例进行介绍。 不要把问题想的太复杂，带参数的装饰器其实就是在上述基本的装饰器的基础上在外面套一层接收参数的函数，下面通过一个例子说明一下。 以上述例子为基础，前面的简单示例输出的信息是， 123func three run time 1.0003271102905273func three run time 1.0006263256072998func three run time 1.000312328338623 现在我认为这样的信息太单薄，需要它携带更多的信息，例如函数名称、日志等级等，这时候可以把函数名称和日志等级作为装饰器的参数，下面来时实现以下。 1234567891011121314151617181920212223242526def logger(msg=None): def run_time(func): def wrapper(*args, **kwargs): start = time() func() # 函数在这里运行 end = time() cost_time = end - start print("[&#123;&#125;] func three run time &#123;&#125;".format(msg, cost_time)) return wrapper return run_time@logger(msg="One")def fun_one(): sleep(1) @logger(msg="Two")def fun_two(): sleep(1) @logger(msg="Three")def fun_three(): sleep(1) fun_one()fun_two()fun_three() 可以看出，我在示例基本用法里编写的装饰器外层又嵌套了一层函数用来接收参数msg，这样的话在每个函数(func_one、func_two、func_three)前面调用时可以给装饰器传入参数，这样的输出结果是， 123[One] func three run time 1.0013229846954346[Two] func three run time 1.000720500946045[Three] func three run time 1.0001459121704102 自定义属性的装饰器上述介绍的几种用法中其实有一个问题，就是装饰器不够灵活，我们预先定义了装饰器run_time，它就会按照我们定义的流程去工作，只具备这固定的一种功能，当然，我们前面介绍的通过带参数的装饰器让它具备了一定的灵活性，但是依然不够灵活。其实，我们还可以对装饰器添加一些属性，就如同给一个类定义实现不同功能的方法那样。 以输出日志为例，初学Python的同学都习惯用print打印输出信息，其实这不是一个好习惯，当开发商业工程时，你很用意把一些信息暴露给用户。在开发过程中，我更加鼓励使用日志进行输出，通过定义WARNING、DEBUG、INFO等不同等级来控制信息的输出，比如INFO是可以给用户看到的，让用户直到当前程序跑到哪一个阶段了。DEBUG是用于开发人员调试和定位问题时使用。WARING是用于告警和提示。 那么问题来了，如果我们预先定义一个打印日志的装饰器， 123456def logger_info(func): logmsg = func.__name__ def wrapper(): func() log.log(logging.INFO, "&#123;&#125; if over.".format(logmsg)) return wrapper logging.INFO是打印日志的等级，如果我们仅仅写一个基本的日志装饰器logger_info，那么它的灵活度太差了，因为如果我们要输出DEBUG、WARING等级的日志，还需要重新写一个装饰器。 解决这个问题，有两个解决方法： 利用前面所讲的带参数装饰器，把日志等级传入装饰器 利用自定义属性来修改日志等级 由于第一种已经以统计函数运行时间的方式进行讲解，这里主要讲解第二种方法。 先看一下代码， 123456789101112131415161718192021222324252627282930313233343536import loggingfrom functools import partialdef wrapper_property(obj, func=None): if func is None: return partial(attach_wrapper, obj) setattr(obj, func.__name__, func) return funcdef logger_info(level, name=None, message=None): def decorate(func): logmsg = message if message else func.__name__ def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) @wrapper_property(wrapper) def set_level(newlevel): nonlocal level level = newlevel @wrapper_property(wrapper) def set_message(newmsg): nonlocal logmsg logmsg = newmsg return wrapper return decorate@logger_info(logging.WARNING)def main(x, y): return x + y 这里面最重要的是wrapper_property这个函数，它的功能是把一个函数func编程一个对象obj的属性，然后通过调用wrapper_property，给装饰器添加了两个属性set_message和set_level，分别用于改变输出日志的内容和改变输出日志的等级。 看一下输出结果， 12345main(3, 3)# 输出# WARNING:Test:main# 6 来改改变一下输出日志等级， 123456main.set_level(logging.ERROR)main(5, 5)# 输出# ERROR:Test:main# 10 输出日志等级改成了ERROR。 保留元信息的装饰器很多教程中都会介绍装饰器，但是大多数都是千篇一律的围绕基本用法在展开，少部分会讲一下带参数的装饰器，但是有一个细节很少有教程提及，那就是保留元信息的装饰器。 什么是函数的元信息？ 就是函数携带的一些基本信息，例如函数名、函数文档等，我们可以通过func.__name__获取函数名、可以通过func.__doc__获取函数的文档信息，用户也可以通过注解等方式为函数添加元信息。 例如下面代码， 1234567891011121314151617181920212223242526from time import timedef run_time(func): def wrapper(*args, **kwargs): start = time() func() # 函数在这里运行 end = time() cost_time = end - start print("func three run time &#123;&#125;".format(cost_time)) return wrapper@run_timedef fun_one(): ''' func one doc. ''' sleep(1) fun_one()print(fun_one.__name__)print(fun_one.__doc__)# 输出# wrapper# None 可以看出，通过使用装饰器，函数fun_one的元信息都丢失了，那怎么样才能保留装饰器的元信息呢？ 可以通过使用Python自带模块functools中的wraps来保留函数的元信息， 12345678910111213141516171819202122232425262728from time import timefrom functools import wrapsdef run_time(func): @wraps(func) # &lt;- 这里加 wraps(func) 即可 def wrapper(*args, **kwargs): start = time() func() # 函数在这里运行 end = time() cost_time = end - start print("func three run time &#123;&#125;".format(cost_time)) return wrapper@run_timedef fun_one(): ''' func one doc. ''' sleep(1) fun_one()print(fun_one.__name__)print(fun_one.__doc__)# 输出# fun_one # func one doc. 只需要在代码中加入箭头所指的一行即可保留函数的元信息。 文档获取本讲的Markdown格式文档我进行共享了，需要的可以关注公众号回复回复关键字”python“获取。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【进阶Python】第一讲：开篇]]></title>
    <url>%2F2019%2F08%2F04%2Fpython-one%2F</url>
    <content type="text"><![CDATA[前言 2015年，本科毕业的那个暑假我开始疯狂的投递简历，希望找一份数据分析与数据挖掘相关的实习工作。直到有一家公司的面试官问到我：“你会Python吗？”，我当时一脸疑惑，因为，大学期间只系统的学习过C语言，后期开发系统中用到过少量的C#。于是我问面试官：“你能给我拼写一下这么语言的名字吗”？多年之后回想起来还会觉得很尴尬，真的是孤陋寡闻。 从那以后，“Python”这么语言经常出现在我耳边。读研之后我开始之后我主要研究的方向是传统目标识别和图像处理，主要使用的语言就是C++和Matlab，所以Python在我读研第一年并不是主力工具。研二开始后我开始进入深度学习这个领域，开始用到很多第三方的工具包，例如caffe、tensorflow已经CNN，那以后开始以Python语言为主。 因为之前有一些编程基础，在加上当初面试实习时时间紧迫，所以我就抽了一天的时间把Python基础教程看了一遍，了解了基本用法之后就成功的面试上了一份实习工作。那时候我认为Python是简单的，因为它不像C++、Java那样有严格的语法规范、有变量类型的概念，你只需要记住缩进正确即可。而且在做自然语言和计算机视觉过程中很多部分的代码都是依托第三方工具包完成，真正自己开发的只是一些数据预处理、文本处理以及用一些条件循环语句对逻辑进行串联。 直到后来从事工作以后，做了更多有严格交付要求的项目之后才发现，Python并没有想象的那么简单，“会用Python容易，用好Python不易”，这是我使用几年Python之后的感触。 当你做一个项目要考虑到代码的复用性、易读性、运行效率、后期维护成本以及面对一些复杂的数据结构时，你会发现Python绝对不是简简单单利用那些基本知识能够实现的。 这也是我开始这个系列分享的原因，第一：把自己开发过程中的一些心得和经验总结下来。第二：如果能够帮助更多的Python学习者，那就更加荣幸了。 为什么要用Python？近几年唱衰Python的声音不拘于耳，有些人是的确发现并感受到了Python的缺点，但是更多的人是跟风式的唱衰Python。“Python效率低”，很多人都这样说，这显然有一些以偏概全的感觉，如果做游戏、软件，Python的确不占优势，但是如果作为算法工程师，进行算法验证，我想没有几个人会选择C/C++。口说无凭，先看几组数据对比。 PYPL 通过分析在谷歌上搜索语言教程的频率，创建了编程语言索引的PYPL流行度。 首先看一下PYPL最新编程语言流行程度， Python居于第一，力压Java、JS、PHP这些名气非常大的编程语言，而且前10名中2~9名都出现了负增长，而Python却4.5%的正向增长率。 如果觉得一个平台不够具有说服力，可以再看看另外一个知名的编程社区的排名。 TIOBE编程社区 TIOBE编程社区指数是编程语言受欢迎程度的一个指标。该指数每月更新一次。这些排名是基于全球熟练工程师、课程和第三方供应商的数量。流行的搜索引擎，如谷歌，必应，雅虎!美国、维基百科(Wikipedia)、亚马逊(Amazon)、YouTube和百度被用来计算收视率。值得注意的是，TIOBE索引不是关于最好的编程语言，也不是编写大多数代码行的语言。 来看一下TIOBE社区7月的编程语言排名， Python仅次于Java和C，排在第三名，而且对比去年同期，前10名中Python增长速度最快，达到2.9%。 从这里可以看出，Python一直被唱衰、一直很坚挺，尽管几年量关于Go、julia、Rust的呼声很高，但是依然无法撼动Python的地位，而且这些编程语言到底好不好用？有没有炒作的成分在里面？现在还是一个问号。 话说回来为什么Python如此受欢迎？ 我认为存在的即是合理的，如果它真的一无是处、漏洞百出，是经不住众人的考验的。它之所以如此受欢迎，自然有很多吸引人的方面： 简单易用、节省时间 丰富的第三方工具包 强大的社区 应用场景丰富 其他三个方面暂且不说，就说一些第一点，简单易用、节省时间，我觉得有这一个理由就足以吸引很多人。尤其是对于算法、测试等岗位，真正的耗费心思的并不在编程、开发这一块，编程语言是用来验证算法的可靠性的，但是没有这个编程语言，自然无法验证，这就体现出有一个简单易用的语言有多么重要了。 吴恩达在《机器学习》这么课程里提到“硅谷的工程师大多数都会选择一个简单的编程语言对自己的算法进行验证，当确认有效之后会用c/c++等语言重新实现一遍”，这足以体现Python语言简单易用的优点。 Python距离第一个版本发布以及有28年，唱衰的言论从未间断，但是依旧坚挺。 尤其是机器学习的大规模应用、国家把人工智能智能技术上升到战略层次，使得Python称为独树一帜的编程语言，虽然这两年Go、Julia号称性能更好、更加易用，但是一直无法撼动Python在机器学习领域的地位，很难望其项背，为什么？我认为最主要的原因就是拥有强大的用户基础。现在在大多数企业，从事算法相关岗位的清一色的使用Python，更别说计算机视觉、自然语言这些强依赖Python第三方库的方向。 Python该怎么学习？我认为大多数编程语言的学习都可以简化为3个过程： 入门 进阶 强化 入门阶段网上的教程已经很多了，关于入门我个人是不推荐参加培训班的，因为就如同前面所说的那样，Python基础语法非常简单，尤其是有一些C、Matlab、C++等编程基础的同学来说，Python中的很多概念虽然和恰语言不是完全相同，但是相似度还是非常高的，可以达到触类旁通。我个人更倾向于使用在线教程，这里推荐两个不错的入门教程， 菜鸟教程 https://www.runoob.com/python/python-tutorial.html 廖雪峰Python https://www.liaoxuefeng.com/wiki/1016959663602400 强化阶段我认为需要在实际的项目和工作中去得到提升，就如同计算机视觉、自然语言处理一样，你从文章和练手项目中所能获取的只有那么多，如果像进一步得到升华就需要在项目中去面对困难、解决困难，这时候就会想尽方法去解决各种难题，不知不觉中会得到很大的提升。 本系列的主要目的是介绍进阶阶段，讲解一些Python的高级用法，对于入门和强化阶段自己可以私下完成。 书籍推荐如果时间比较冲突，我觉得可以系统的看一些Python书籍，因为书籍的严谨性和条理性更加有保障，在这我推荐3本我个人认为不错的书籍， 1.《Python编程 从入门到实践》 如果时间有限，我认为入门阶段可以通过菜鸟教程、廖雪峰Python进行学习。如果时间充足，我认为可以看一下入门书籍，因为更加严谨一些。 《Python编程 从入门到实践》是一本比较适合入门的书籍，环境配置、变量、列表、if语句、函数等基础的概念都会详细的展开介绍，这对于没有编成基础的同学非常有帮助。 2.《流畅的Python》 这是一本经得起考验的Python书籍。 它和大多数书籍和在线教程蜻蜓点水式的讲解不同，它更加深入，深入而不冗余，在你看这本书的时候你会发现，它的每一段话都是有意义的，没有什么废话。 它分别从数据结构、字典集合、文本和字节序列、函数、设计、装饰器、闭包等讲起，然后对每一块知识进行展开，详细介绍里面最根本的原理，然后告诉你，该怎么用好它，高效的使用它。 举一个最简单的例子，在绝大多数教程都会讲到循环和条件语句，千篇一律的告诉你”if..else..”, “for…while”，这个有一点编程语言的同学都知道，但是在Python里面循环和条件语句有什么特殊的地方吗？该怎么用好它？ 《流畅的Python》这本书就教你怎么去使用它，告诉你列表推导该怎么用还有它的意义所在。 这就是这本书的优点：不仅告诉你怎么用Python，而是告诉你怎么用好Python。 3. 《Python CookBook》 学而不精的同学都会认为Python是一门很简单的编程语言，不错，Python相对于Java、C++要简单很多，没有严格的语法结构、没有变量类型，而且如果有一些编程基础去学Python的话可以一个周甚至一天即可学完。 但是我认为，Python入门简单，但是用好并不简单，当你接触到标准的商业项目时你就会意识到Python高级用法的重要性以及它的价值所在。 《Python CookBook》这本书就是这样的一本进阶教材，它不同于大多数教程，反复的介绍基本语法，它直接跳过基本语法开始讲解数据结构、算法、迭代器、生成器、类、对象、元编程等，我认为这些才是工作中真正有价值、拉开差距的地方，而那些基本语法是默认应该会的。 《Python CookBook》会在每个知识点开始提出一个应用场景，然后告诉你怎么去解决这种应用，同时会编程实现，这样对于提升Python是最为实际的，而且让你更加容易理解它这样用的价值所在。 这本书不仅有出版的书籍，也有免费的在线教程，需要可以看一下。 https://python3-cookbook.readthedocs.io/zh_CN/latest/preface.html 更多精彩内容，请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【动手学计算机视觉】第十讲：传统目标检测之卷积神经网络概述]]></title>
    <url>%2F2019%2F08%2F03%2Fcnn%2F</url>
    <content type="text"><![CDATA[前言 提起卷积神经网络(CNN)，应该很多人都有所耳闻。自从2012年AlexNet在ImageNet挑战赛一举夺魁，它再一次的回到的人们的视野。 为什么称之为”再一次”，因为CNN并不是近几年的产物，早在20世纪90年代Yann LeCun就提出了最基础的卷积神经网络模型(LeNet)，但是由于算力和数据的限制，它一直处于一种被冷遇的地位，传统目标识别方法，例如之前所讲到的SIFT、HOG、DPM占据着不可撼动的统治地位。 但是随着算力的提升和数据集的积累，这一切都变了，在AlexNet成功之后，CNN如同雨后春笋一样，每年各种各样的Net数不胜数，近其中知名的就有AlexNet、VGG、GoogleNet、UNet、R-CNN、FCN、SSD、YOLO等。 入门计算机视觉领域的绝大多数同学应该都学过或听说过斯坦福大学的公开课(CS231n: Convolutional Neural Networks for Visual Recognition)，主要就围绕CNN进行展开，甚至很多近几年入门计算机视觉的同学就斩钉截铁的认为，计算机视觉就是卷积神经网络，我认为这有一些”一叶障目，不见泰山的”感觉。 CNN只是计算机视觉的一个子集，而且是一个很小的子集，更确切的说，计算机视觉是一种应用性技术，CNN是一种工具。 但是，不可否认，CNN是目前阶段我们能力所达到的、在大多数CV方向应用最为成功的一项技术，尤其是R-CNN系列和YOLO系列，在商业中，例如交通监测、车站安检、人脸识别应用非常多，效果对比于传统目标识别算法也要好很多，所以，它是学习计算机视觉中非常重要的一环，本文就概述一下近年来比较成功的CNN模型。本文只是用简略的语言进行概述，后续会挑选一些比较经典的模型进行详解和编程实现。 卷积神经网络概述 按功能对卷积神经网络进行分类主要可以分为两类， 检测(detection) 分割(segmentation) 检测的目的是要判断一副图像中是否有特定的目标，以及它所在的位置，通过一些手段识别出它所在的包围合区域。 分割的目的要更加严格一些，它不仅要识别出目标的所在区域，还要分割出目标的边缘，尤其在CNN图像分割领域，和传统的图像分割不同，它不能简单的依靠梯度变化幅度把目标分割出来，还需要进行语义上的分割，识别到像素级的类别。 目前比较知名的用于识别的CNN模型有， AlexNet VGG R-CNN系列 Resnet MobileNet YOLO系列 在分割方面比较知名的CNN模型有， Mask R-CNN FCN U-Net SegNet CNN中主要用到的技术 系统学习以上上述所提到的知名CNN模型会发现，其中所使用到的技术手段大同小异，而那些知名度较小的CNN模型更是如此，创新点更是微乎其微，其中所使用到的技术主要有， 卷积 池化 基础块 Dropout 跳跃连接 锚点 优化算法 激活函数 批量正则化 回归 卷积和池化是非常基础的，在特征提取过程中至关重要。 基础块的思想最初出自于VGG，它在AlexNet的基础上进行了很大的改进，基础块思想的引入增加了网络的重用性，后续很多模型都死在这一举出上进行改进的，因此，在很多后续的网络模型都是以VGG为基础模型。 Dropout这个几乎成了CNN模型中必不可少的一个组件，它在应对过拟合问题中具有非常重要的价值。 跳跃连接最初出现在ResNet，在网络的不断改进中发现，其中的思想都是使网络越来越深，网络适当的加深的确能够带来识别精度的提到，但是真的越深越好吗？当然不是。随着网络的加深，很容易出现梯度消失和梯度爆炸现象，ResNet中提出的跳跃连接在后来的网络模型中扮演者非常重要的角色。 锚点这一概念最初是在2008年的DPM模型中看到，后来Faster R-CNN中主要的使用了这项技术，使得它名声大噪，后来的经典模型几乎都用到了锚点这个思想。 优化算法对于上述CNN模型的价值自然不言而喻，梯度下降、Adam、牛顿法等，可以说这是深度计算机视觉的核心所在，也是理论体系最完善、最能够用数学模型解释的一部分。 激活函数和Dropout一样，也是CNN模型中必不可少的一个组件，它的主要价值在于解决模型的线性不可分问题，把非线性的特性引入到网络模型中。 批量正则化也是CNN中常用的一个功能，它的主要作用是加速模型的收敛，避免深层神经网络的梯度消失和梯度爆炸。 回归中用到的较多的自然是softmax，它将经过各种网络层处理得到的特性向量进行回归，得到每一个类别对应的概率，在多分类问题中是一个必不可少的功能。 CNN模型架构 纵观上述所提及的经典CNN模型，它们的模型架构非常相似，主要包含如下几个部分： 输入层 特征提取层 全连接层 回归 输出层 输入层主要是用于读取图像，用于后面的网络层使用。 特征提取层主要通过卷积来获取图像局部的特征，得到图像的特征图。 全连接层用于对特征层进行后处理，然后用于回归层处理。 回归主要通过一些回归函数，例如softmax函数来对前面得到的特征向量进行处理，得到每个类别对应的概率。 输出层用于输出检测和分类的结果。 当然，在这个过程中某些环节会用到上述提到的激活函数、批量正则化、优化算法以及非极大值抑制。 搭建CNN目标识别系统有了上述强大的模型，在实际项目中该怎么搭建一个有价值的CNN目标识别系统呢？我认为主要分为如下几个步骤， 数据获取 数据预处理 模型搭建 数据后处理 在CNN，乃至整个深度学习领域都可以说数据获取是至关重要的一部分，甚至可以说占据了超过50%的地位。深度学习的发展主要就是得益于这么多年来数据的积累，很多项目和工程也是由于数据的限制和却是只能中途作废。因此，数据获取部分是搭建目标识别系统中最重要的一个环节，它直接决定着是否能够继续走下去。 目前有一些公开的数据集可以获取，例如MNIST、Pascal VOC、ImageNet、Kaggle等。如果自己所做的方向恰好巧合，这些公开数据集里有相应的数据，那么的确是幸运的，可以从这些数据中直接获取。 数据预处理对于CNN同样非常重要，各种视频、摄像头在数据采集的过程中很难保证数据是有价值的，或者干净的，这里就需要对数据进行去噪、去模糊、增强分辨率，如果数据集不充足，还需要对数据进行扩充。 模型搭建我认为是这几个环节中相对较为容易的一部分，首先目前这些经典的框架都有开源的项目，有的甚至不止一个版本，我们可以借鉴甚至直接拿来用这些模型。即便不愿意选择开源的项目，也可以使用tensorflow、pytorch进行搭建，其中需要的代码量是非常有限的。 输出检测的结果需要进行非极大值抑制、绘出包围合等后续工作，以及和一些系统进行对接，这样它才是一个可用的完整系统。 更多精彩内容，请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐5款值得安装的Windows工具]]></title>
    <url>%2F2019%2F08%2F01%2Ffive-windows-tools%2F</url>
    <content type="text"><![CDATA[前言电脑，是我们日常学习和办公中主要依赖的工具之一。而windows作为最流行、使用最为广泛的桌面操作系统，与我们的生活有着密不可分的关系。尤其是近两年随着windows10的逐渐完善和丰富，使得windows操作系统更加受欢迎。我个人使用win10已经超过两年，不得不说，这的确是一个不错的操作系统，在此之前会想方设法安装Ubuntu、centos、redhat等操作系统来替代win7和win8，但是随着windows发布和晚上，加入了linux内核，丰富实用的小工具，让我认识到微软在操作系统和软件生态方面的强大。 在使用windows的过程中，仅仅依靠系统自带的功能是无法满足各种各样的工作、学习需求的，因此需要借助一些第三方工具，虽然有很多知名的软件，例如office、Matlab、Photoshop、CAD等，但是这些工具太过于臃肿，不仅占用很大硬盘空间，而且需要付出高额的费用。windows上其实有很多使用、免费，但不失强大的工具，因为是免费开源，所以没有那么过广告和宣传，所以知名度相对较低，本文就介绍5款值得安装的windows工具。 1. Click&amp;Clean 浏览器是我们使用最多的一款工具之一，甚至没有其中的之一。 每天我们花费大量的时间在浏览器上面，访问各种网址，也留下了很多访问的足迹，这就涉及一个问题，除了缓存垃圾之外就是隐私和信息安全。不知不觉中我们把自己的信息展露无疑。 我认为有着Click&amp;Clean这款超强的隐私保护工具就再也不用担心这个问题了。 当浏览器关闭时，这款应用程序删除你的浏览历史,防止他人跟踪你的网上活动，它支持以下诸多功能， 清空缓存 删除 Cookie 清除已保存的密码 浏览器关闭时运行外部应用程序 关闭所有窗口/标签前清理 Delete Web Local Storages Delete Extension Local Storages Delete Web SQL Databases Delete Extension SQL Databases Google Gears 认证数据删除 …… 2. 石墨文档 颠覆传统办公 就如同它的定位那样“颠覆传统办公”，我觉得它做到了。和以往臃肿的office、昂贵的xmind不同，它首先免费，其次它支持多平台同步，windows、mac、手机均支持。此外，它将常用的办公工具融合为一体。 虽然拿它和office做对比，但是它不仅仅是传统意义上的office工具，它还包含如下功能， 文档 表格 幻灯片 思维导图 协作空间 可以说，上述每一项功能都是目前一个完整的商业产品，需要付出高额的服用，而且非常臃肿，但是石墨文档把这些问题都给解决了，不仅使用简单，而且轻量化、见面简洁大方。 3. Squoosh 这是谷歌出品的一款强大的图片压缩工具，比之前较为知名的TinyPng还要强大一些。 我们都知道在我们传输图片，或者在一些平台上传图片时都会有图像大小的限制，例如微信公众号对上传图片就有限制，很多报名系统对上传图片也有限制。 但是我们又不想损失图片质量怎么办？可以尝试一下Squoosh，它采用谷歌强大的算法，在保障图像质量的前提下最大化压缩图片。 严格意义上说，它是一个网页工具，如果觉得用网页方便，可以直接保存网站https://squoosh.app/，到书签即可，如果不喜欢网页工具，没问题，它也支持安装， 打开网站后点击右上角会发现，菜单栏出现”安装Squoosh”的资源，点击安装即可，占用内存非常小。 前面铺垫了很多，效果到底真的那么强大吗？下面来看一下对比图， 把一副1.51MB的原图压缩到104KB，压缩率高达93%，但是视觉上并不是很明显，看上去依然很清晰。 此外，它还支持一些简单的在线编辑。 4. uTools 这可以称得上上“软件中的百宝箱”，内含丰富的插件，通过安装插件能够实现几十种功能，可以说，有了这款软件可以把很多软件卸载给你的系统节省一些空间了，此外，它还支持设置全局快捷键。 它的插件主要包括如下几类： 通用：例如二维码、翻译、待办事项、剪切板、颜色助手、本地搜索等实用的小工具。 图片：包括压缩图片、图床、图片转文字等功能。 开发：包括JSON、正则表达式、http抓包等功能。 这款工具可以适用于不同的人群，满足不同的需求，有了这款工具就不需要人群。 安装插件 插件安装非常简单，只需要点击对应软件-下载即可， 使用 安装之后打开对应的工具即可使用， 5. WGestures我之前其实并不看好鼠标手势，因为尝试过很多手势工具，大多数都是功能花哨，但是使用体验很差，我一度甚至认为鼠标手势就是一个鸡肋，直到我遇到WGestures这款工具，可以说是让人心里感觉豁然开朗，原来鼠标手势可以这么好用，下面简单举几个例子。 基本手势包括复制、剪切、粘贴、前进、后退、添加书签、刷新、Home、End、”摩擦”边缘、触发角等。 复制、粘贴 Web搜索 摩擦边缘 摩擦右边缘弹出任务管理器、摩擦左边缘弹出控制面板 自定义手势 如果WGestures自带的手势无法满足自己的需求，还可以根据自己的偏好添加手势，添加手势类型包括打开文件、窗口控制、命令行、音量控制、执行快捷键等，例如，我自定义一个打开文件的手势， 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
        <tag>工具</tag>
        <tag>实用</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习资源 | 推荐2份Github热门校招面试汇总资料]]></title>
    <url>%2F2019%2F07%2F28%2Finterview%2F</url>
    <content type="text"><![CDATA[前言 秋季招聘一般集中在每年的9月-10月份，有早一些的城市或者公司会在8月就开始进入校园，开启招聘，也有比较晚的少数公司会在11月-12月进行招聘。 一年一度的秋季招聘马上就要开始了，秋季招聘是校园招聘中最为集中、岗位最多的一次集体招聘会，虽然也有春招，但是对于很多公司而言主要是“查漏补缺”，岗位数量相对于秋招有很大的差距。因此，很多即将毕业的学生会把秋季招聘看的非常重要，毕竟第一份工作对一个人来说是至关重要的，每个同学都希望找到称心如意的工作。 但是，“天下没有免费的午餐”，在秋季招聘中这个道理同样适用，好的工作岗位和面试的难度是成正比的，无论是银行、金融，还是互联网、IT。因此，要想找到一份称心如意的工作，必然需要做好充分的准备，毕竟，机会都是留给有准备的人。 面试是否有规可循？答案是肯定的，以阿里、百度、华为这些知名的互联网、IT公司为例，每年招聘的人数有限，但是应聘人数却是招聘人数的几十倍，甚至上千倍。招聘对于毕业生来说是一次煎熬的过程，对于企业同样是一个非常耗时耗力的事情，因此他们会通过一些“落入俗套”的方式进行人才的筛选，虽然这样会错失一部分真正的人才，但是能够筛选掉更多不符合要求的平庸人员，这样的损失是企业愿意接受的。有哪些“落入俗套”的方式呢？无非就是学历、学科、笔试、面试。其实经过一轮简历上学历、学科的筛选已经筛选下去一大批，而通过笔试又会筛选去一大批没有做好充分准备的同学，真正进入最后面试的已经是经过层层筛选留下来的。 学历、学科这些是人为无法改变的，但是笔试、面试却可以，因为成熟、经典的知识体系已经经过多年的洗礼逐渐完善了起来，笔试、面试的内容无非是变着花样的考书本上、教材上的知识，例如数据结构、算法设计等。因此，我认为通过准备，学习掌握目标公司历年来的出题类型和面试方式，会让应聘过程变的顺畅很多。 近期在github上发现两个不错的面试笔记，总结了各大知名互联网、IT公司，例如阿里、百度、腾讯、华为、美团等公司面试中常见的笔试、面试题型，并且给出了详细的解答。我认为每个人都有薄弱的地方，所以，如果心中有目标的公司，可以根据自身的不足之处学习一下对应公司近两年面试、笔试中常见的题型，好好准备，这样能够有效的帮助你在校招中找到称心如意的公司，废话不多说，下面介绍一下这两个开源学习项目。 0voice / interview_internal_reference https://github.com/0voice/interview_internal_reference 这是一个按公司和知识体系分类的的学习资源，目前已经13w+star。 如果心中有明确的目标公司，可以针对性的看一下对应公司的面试总结。它包含阿里、华为、百度、腾讯、美团、头条、滴滴、京东等。此外，还针对企业中比较常用的工程技术进行知识类型的总结，例如MySQL、Redis、MongoDB、Zookeeper、Nginx、算法、内存、磁盘、网络通信、安全、并发等，可以说是涵盖的非常全面。 和往常见到主要针对算法实现的笔试题目不同，这个项目更加偏向面试。我觉得对于有一些编程和数据结构知识的同学通过笔试都不是特别困难的事情，而真正能够在面试官心中留下深刻印象的往往在笔试中，而这些面试官往往是工作多年，深耕业务和产品的工作人员，因此，他们更多的关注的是现实中遇到的问题，所以，如果在这些问题上回答的不错更容易抓住面试官的心。 interview_internal_reference这个项目主要的针对这些问题，从系统稳定性到缓存机制，从并行计算内存优化，非常全面，知识体系也非常分散，我认为这远远要比反复的刷leetcode要有价值的多，尤其是对于腾讯、阿里这些偏工程的公司，在面试过程中会问很多非常分散的工程技术问题。 imhuay/Algorithm_Interview_Notes-Chinese https://github.com/imhuay/Algorithm_Interview_Notes-Chinese 如果说interview_internal_reference偏向于工程技术，那么Algorithm_Interview_Notes-Chinese更多的是围绕着算法进行展开，目前已经25w+star。 在面试过程中，偏开发和偏算法的面试差别非常大，偏开发，例如前端、后端、云服务等工程技术的会询问很多分散技术的问题，但是偏算法的往往会集中在算法和项目方面，例如，做过哪些相关的项目？使用了什么算法？这个算法具体细节是什么？等等。大多数是围绕着应聘岗位进行面试，如果发散一些，会问一些经典的数据结构和数学方面的知识。 这几年随着人工智能火热，计算机视觉、深度学习、自然语言处理方面的工作岗位也多了起来，应聘者也多了起来。这个学习资源主要围绕人工智能领域的技术进行总结，同时涵盖数学、编程、数据结构等方面的基础知识。 如图所示，在深度学习方面，它包含了深度学习的基础知识，例如过拟合、欠拟合、激活函数、反向传播、正则化、加速训练，同时还包含深度学习领域核心的优化算法，例如，梯度下降法、动量法、牛顿法等。 此外，在计算机视觉、自然语言处理方面也包含了诸如VGG、词向量等基础的知识。我认为，它不仅适用于即将应聘的同学，同时对于已经参加工作的同学也非常有用。 除了应用层面的算法之外，它还有数学基础，例如微积分、概率论方面的知识，从求导到极限、从微分到积分，泰勒级数等，样样都有。 123456789101112131415161718192021222324252627class Solution &#123;public: int widthOfBinaryTree(TreeNode* root) &#123; if (root == nullptr) return 0; queue&lt;TreeNode*&gt; Q; Q.push(root); int ans = 1; while(!Q.empty()) &#123; int cur_w = Q.size(); // 当前层的宽度 ans = max(ans, cur_w); for (int i=0; i&lt;cur_w; i++) &#123; auto p = Q.front(); Q.pop(); if (p-&gt;left) Q.push(p-&gt;left); if (p-&gt;right) Q.push(p-&gt;right); &#125; &#125; return ans; &#125;&#125;; 除了这些偏理论的知识，它还有面试中常出现的数据结构和算法方面的总结，同时给出了编程实现，例如，动态规划、双指针、排列组合、二叉树、链表、堆、栈等，此外，Algorithm_Interview_Notes-Chinese吸引人的地方是在这些算法方面不是单纯的给出编程实现，还是列出实现的步骤和思路，非常有助于理解。 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Github</tag>
        <tag>资源</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【动手学计算机视觉】第九讲：传统目标检测之DPM模型]]></title>
    <url>%2F2019%2F07%2F28%2Fcv-dpm%2F</url>
    <content type="text"><![CDATA[前言 DPM(Deformable Part Model)模型，又称为可变型部件模型，是Felzenszwalb于2008年提出的一个模型。这可以说是传统目标识别算法中最为经典的算法之一，我认为对计算机视觉有一些深入了解的同学应该对DPM模型都有所耳闻。 首先说一下DPM模型这篇文章有多牛。DPM模型的坐着Felzenszwalb凭借这个模型一举获得2010年voc挑战赛的终身成就奖，感觉还是不够牛？不知道Felzenszwalb是何许人也？Felzenszwalb正是Ross B. Girshick(也就是DPM模型的第二作者)硕士和博士期间的导师。我想，如果连Ross B. Girshick都不知道的话就真的称不上是一个计算机视觉领域的学习者了。它正是R-CNN系列、YOLO系列等现如今被封为经典的计算机视觉模型的提出者或共同提出者，可以说是这几年计算机视觉领域比较有作为的一位研究者。 说完DPM的作者很牛，那和DPM有什么关系？前面提到，它的作者是近几年计算机视觉领域非常知名的研究者，因此，自然而然，这几年比较成功的计算机视觉模型都会受到这个标杆性算法的影响。多尺度、锚点、可变型部件，都对后面深度学习计算机视觉带了巨大的影响。 介绍完DPM模型的背景，再回到这个算法本身。DPM模型和前文讲到的HOG整体流程非常类似，HOG采用HOG特征加linear SVM，而DPM采用多尺度特征加latent SVM，此外，DPM在特征提取方面也是在HOG特征的基础上进行稍加改进。虽然从文中看上去两者差别并不大，但是其实DPM无论是在特征提取层面还是在机器学习层面都做了巨大的改进。 首先是特征提取思想，HOG模型仅仅考虑根模型的特征，不考虑部件模型的特征，而DPM模型采用根模型加部件模型的思路，同时考虑外观和细节部分的特征。 其次是SVM方面，Latent SVM加入了潜在信息的训练。 下面就分别从特征提取到模型训练介绍一下这个模型。 特征提取 文章中讲的有点让新学者难以理解，这里我就对照着HOG特征讲解一下，更有助于理解。 两者相同的是第一步都要先计算梯度方向，然后对梯度方向进行统计。 不同之处是，HOG特征含有块(block)的概念，它首先把一副图像划分成若干个块，然后再把块划分成若干个单元，然后对单元内部的像素进行梯度统计，然后对同一个块内的特征向量进行归一化，HOG采用的是0~180度之间的梯度方向，20度一个区间，这样每个细胞单元就统计得到一个9维特征向量，一个块内就得到n * 9维特征向量。 由于HOG采用的梯度方向为0~180度方向不敏感特征，这样会丢失很多特征信息，DPM模型对HOG做了很大的改进。首先DPM模型没有快的概念，它是去一个细胞单元四角对应的领进单元的特征进行归一化，此外，更重要的是DPM不仅提取结合0~180度方向不敏感特征和0~360度方向敏感特征两种特征，它首先提取0~180度之间的特征，得到上图所示4*9维的特征，拼接起来得到13维特征向量，然后再提取0~360度之间的特征，得到18维特征向量，二者相加得到31维特征向量。 模型训练前面介绍了一下DPM模型特征提取的方法，虽然思想与HOG有很大不同之处，但是在最基本的梯度方向统计方面是相同的。 知道了如何从一副图像中提取我们想要的特征，要进一步深入理解一个算法，我认为从模型训练、模型预测方面是最简单明了的方法，无论是传统目标识别还是深度计算机视觉。知道它是如何训练、如何预测的就知道这个模型的运作情况，输入是什么？中间经历了什么过程？输出是什么？下面就来看一下DPM模型的训练过程。 本算法采用的训练说句来自于Pascal VOC，用过这个数据集的都知道，它只标记了图片中目标的包围合，并没有标记图像的部件，例如它只标记了一个人，并没有标记人的胳膊、腿、头部等，而DPM被称为可变型部件模型，那么部件体现在哪里？怎么知道它的部件在哪？下面来了解一下它的训练过程，能够帮助理解这个算法。 DPM的在训练之前先进性了初始化，主要包括3个阶段： 初始化根滤波器 为了训练一个有m个组件的混合模型，首先将正样本按照长宽比划分成m组，然后针对每一组训练一个根滤波器F1、F2、…、Fm，在训练根模型过程中使用的是标准的SVM， 不含有潜在信息，例如上图(a)、(b)就是初始化的两个根模型。 合并组件 把初始化的根滤波器合并到一个没有部件的混合模型中并且重新训练参数，在这个过程中，组件的标签和根的位置是潜在变量(组件和部件不是同一个概念)。 初始化部件滤波器 前面提到，数据集中并没有标记部件的位置，因此文中在初始化部件滤波器是用了一个简单的假设，将每个组件的部件数量固定在6个，并使用一个矩形部件形状的小池，文中贪婪地放置部件，以覆盖根过滤器得分较高的区域。 另外需要清楚的是，部件滤波器是在根据滤波器2倍分辨率的图像上进行初始化，因为分辨率越高，细节越清晰，越能提取部件的特征。 经过初始化之后就可以训练模型参数。 下面是详细的训练过程， 模型检测前面介绍了DPM模型的特征提取和训练过程，下面就来看一下模型检测过程。 上述就是就是DPM模型检测的详细过程： 对输入图像进行特征提取，得到特征图和2倍分辨率的特征图 分别在特征图和2倍分辨率上计算根滤波器和部件滤波器的得分 合并根位置的得分，得到总得分 用数学语言表示，图像的总得分为， \begin{array}{l}{\operatorname{score}\left(x_{0}, y_{0}, l_{0}\right)=} {\quad R_{0, l_{0}}\left(x_{0}, y_{0}\right)+\sum_{i=1}^{n} D_{i, l_{0}-\lambda}\left(2\left(x_{0}, y_{0}\right)+v_{i}\right)+b}\end{array}模型检测过程就是获取局部最大响应(得分)的过程，前面已经训练得到了模型参数，然后利用模型参数在图像特征图上滑动求点积，计算得分。DPM的得分包括两个方面：$R_{0, l_{0}}\left(x_{0}, y_{0}\right)$是根滤波器的得分， $\sum_{i=1}^{n} D_{i, l_{0}-\lambda}\left(2\left(x_{0}, y_{0}\right)+v_{i}\right)$是部件滤波器的得分，$b$是偏移量。 Latent SVM在经典的SVM中，认为训练样本的标记是严格符合类别标签的，标记的正样本就是正样本、标记负样本就是负样本，但是由于标记过程中有很多人为因素，因此，虽然能保证负样本一定是负的，但是却不能保证正样本一定属于正的。因此在训练过程中有很多潜在的未知信息，作者发现，将根位置作为一个潜在变量，可以有效地补偿正样本中存在噪声的边界框标签。 Latent SVM训练的目标函数为， L_{D}(\beta)=\frac{1}{2}\|\beta\|^{2}+C \sum_{i=1}^{n} \max \left(0,1-y_{i} f_{\beta}\left(x_{i}\right)\right)其中， f_{\beta}(x)=\max _{z \in Z(x)} \beta \cdot \Phi(x, z), $z$是潜在信息。 源码解析由于DPM模型工程量较大，而且作者已经开源代码并且经过多个版本的迭代，目前非常成熟，因此不在这里逐步实现，在这里主要讲解一下怎么使用源码去检测目标和训练模型。 目前源码版本为 voc-release5，可以直接访问官网下载， http://www.rossgirshick.info/latent/ 也可以关注公众号回复voc获取。 DPM的源码是由Matlab和C++进行混编而成，Matlab主要用于做一些简单的图像处理，由于在模型训练和特征提取过程中非常缓慢，因此，为了提高效率，作者用C++实现了特征提取和模型训练部分，另外，由于C++部分使用了一些多线程的库，所以在windows下无法直接运行，需要做一些修改，在linux和mac下可以直接运行。 目标检测 用训练好的模型检测目标，主要有如下几个步骤， 解压缩代码。 运行Matlab。 运行’compile’函数来编译helper函数。 加载模型和图像。 检测目标。 示例， 1234&gt;&gt; load VOC2007/car_final.mat; &gt;&gt; im = imread('000034.jpg'); &gt;&gt; bbox = process(im, model, -0.5); &gt;&gt; showboxes(im, bbox); 训练模型 可以自己按照voc的格式准备数据，训练自己的模型，去检测相应的目标，详细过程如下， 下载数据集和VOC devkit工具包。 根据自己的数据配置voc_config.m。 运行’compile’函数来编译helper函数。 利用pascal.m脚本训练模型 示例， 1&gt;&gt; pascal('bicycle', 3); 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实用工具 | 推荐10款浏览器插件]]></title>
    <url>%2F2019%2F07%2F24%2Fchrome-plugin%2F</url>
    <content type="text"><![CDATA[前言前一篇文章花大篇幅详细的介绍了一款强大的浏览器插件—tampermonkey，评论里很多同学对这款插件给予很高的评价。可以看出，浏览器插件在日常工作和生活中的确占据着很重要的地位，因此，本文整理推荐10款浏览器插件，每一款都是经过长时间使用并且最终保留下来的，插件主要是一些效率工具，希望能够对各位提供有效的帮助。 Infinity 这款插件自称是一款新标签页工具，但是我觉得，如果仅仅把它视为新标签页工具，那就把它想的太简单了。 它提供极简的标签页设计，而且含有丰富的标签页壁纸，轻轻点击即可切换新标签壁纸，但是它的功能远不止于此，它还包含如下丰富功能： 待办事项 实用笔记 精美天气 轻松切换搜索引擎 …… Forest 保持专注，用心生活，这是这款工具的宗旨。 这是一款习惯养成插件，就如同前面所说，浏览器是我们工作和学习中常用的一款工具，但是如果把过多的时间花费在浏览器上，那么就是一种巨大的时间浪费。Forest利用一种轻松有趣的方式让你远离网络成瘾。 在每次开始工作时，可以种下一颗树苗，它会慢慢长大。如果你频繁的打开浏览器，它会用各种方式提醒你应该专注工作。此外，你还可以把一些网站加入黑名单，如果在专注时间内访问这些网址则会被禁止，如果强制访问，那么辛辛苦苦种下的小树苗则会枯萎，利用这种游戏的方式让你更加专注于学习与工作。 LastPass 这是一款强大的密码管理工具。 互联网的时代，让我们困扰的就是频繁的注册、数不清的账号和密码，我们不断的在重复着设置密码、重置密码。怎么样才能解决这种困扰？可以尝试一下LastPass，它采用256位AES密匙的强大加密算法，首先保证了在本机上不获取得到您的信息，其次，每当访问对应的网站时，它能够快速提示你对应的密码并填充，这样就避免了重复记忆密码的困扰。 当然，它不仅仅包含密码管理，还包含安全笔记这个实用的功能。 OneTab 在浏览网站时我们会发现，不知不觉中打开了很多网页，这时候标签栏变的非常密集而混乱。 这时候该怎么办？逐个关闭不仅麻烦，而且如果后续用到的话又找不到了。如果不关闭吧，又影响了浏览器的使用体验。 有了OneTab这款工具，只需单击一下，就可以把所有标签页转化成一个列表，如果再次需要某个网页的时候，可以单个或者全部恢复标签页。此外，它还节省高达95%的内存占用。 Pocket 一款轻松捕获视频、文章等内容的快捷插件。 当我们看到一个视频或者文章时，由于种种原因无法当时去看，希望以后某个时段有了时间再去看，有了Pocket就使得这件事情变得简单起来，只需要点击一下Pocket图标或者鼠标右键保存即可轻松把内容保存到Pocket里面，而且Pocket还支持多平台、多终端，在浏览器上保存后再手机上也可以查看。 Grammar and Spell Checker 从名字就可以知道这款工具的功能—语法和拼写检查工具。 它能够在网站上任何位置对你输入的段落进行拼写和语法检查，它的强大之处主要有如下2点： 支持超过25种语言 适用于几乎所有的网站 FireShot 这是一款截图工具。 截图，是我们常用的一个功能，windows自带的截图功能自然不用多说，真的挺差的，借助QQ、微信等截图又比较麻烦，当然，可以借助Snipaste等强大的截图工具。支持截图的工具有很多，但是大多数只能截取可见部分，支持截取完整页面的却很少，FireShot就可以做到这一点，此外，它还支持： 截图保存到磁盘为PDF，PNG和JPEG 截图复制到剪贴板 打印截图 crxMouse 鼠标手势依赖者的福音。 它可以跨windows、linux、mac多平台支持自定义鼠标手势，同时支持超级拖拽、平滑滚动、摇杆手势。此外，还支持导入和导出配置文件。 它默认携带手势包括前进、后退、向上滚动、关闭标签页、到底部、刷新等，如果不满足于这些手势，还可以自定义添加。 Dark Reader 这是一款主题插件，现在有些手机和软件都实现了夜间模式，因为黑色的主题对于保护眼睛更有好处，能够减少明亮色彩带来的眼睛疲劳，Dark Reader就可以实现浏览器的夜间模式，同时它具有更强的定制性，能够调整亮度，对比度，应用棕褐色滤镜，黑暗模式，设置字体和忽略的网站列表。 SwitchyOmega 这是一款可以称得上“神器”的插件，轻松快捷的管理代理，同时支持自动切换多个代理模式。 在很多场景下，尤其是在有些公司内部对于信息安全的限制，需要设置代理才能访问不同类型的网站。如果通过IE代理设置，这样需要每次打开IE、连接设置…一系列流程，非常繁琐。而且针对不同的网络下只能使用同一种代理模式。SwitchyOmega能够让你轻松的切换不同的代理模式，而且支持自动代理切换，当访问不同网络时能够选取最快的代理方式，这样就不会出现有的网址可以访问，有的网址访问速度缓慢甚至打不开的现象。 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
        <tag>工具</tag>
        <tag>实用</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实用工具 | 也许，这是最强大的一款浏览器插件]]></title>
    <url>%2F2019%2F07%2F14%2Ftampermonkey%2F</url>
    <content type="text"><![CDATA[前言 浏览器是我们日常工作中接触最多的工具之一，甚至在很多人的排行榜里毫无争议的夺得第一的位置。目前市面上浏览器可谓是五花八门，谷歌浏览器、IE浏览器、火狐浏览器、QQ浏览器、搜狗浏览器、360浏览器等等，但是归根结底，使用的内核主要分为两类：Chromium内核和Trident内核(又称IE内核)。由于浏览器在工作中扮演者至关重要的作用，使用比重也非常之大，因此，简单的官网默认浏览器很难满足我们各种各样的需求，所以，浏览器插件也就应用而生。甚至，对于很多浏览器来说，它的最大特色和吸引人的地方就是丰富而实用的插件。 如果让选出几款不错的插件推荐给大家，不同的使用者应该会推荐不同的插件，毕竟每个人的使用偏好和工作内容不同。但是我相信，对于大多数推荐者都不会忽略一个插件，也就是本文的主角：Tampermonkey。可以毫不谦虚的说，Tampermonkey是目前最为流行的用户脚本管理器，它适用于 Chrome, Microsoft Edge, Safari, Opera Next, 和 Firefox。用户脚本是一个什么东西？简而言之，不同脚本可以实现不同的功能，Tampermonkey可以对这些功能进行管理，让你的浏览器如虎添翼。 由于我个人日常使用谷歌浏览器较多，因此在这里就以谷歌浏览器为例为大家推荐几款不错的插件，每一款都让人赞不绝口。 概述Tampermonkey有很多可选的脚本，但是如果让推荐的话，我认为以下5款是必不可少的： AC-baidu Yet Another Weibo Filter 百度网盘直链下载助手 豆瓣资源下载大师 破解VIP会员视频集合 下面就逐个详细介绍一下上述5款插件，耐心往后面看，一个比一个强大。 AC-baidu 提及百度搜索，应该很多人想到的就是广告、混乱，的确，经常使用谷歌搜索，每当回到百度搜索时都会克制不住的质疑：“为什么会存在百度搜索这样的东西？” 的确，广告、相关推荐、垃圾信息，样样都有，就是没有我们想要的东西。 有了AC-baidu这个脚本，上述困扰就迎刃而解了。 它能够让你的搜索重定向到原始网页，拦截百家号等无用推广，让搜索网页回到最原始、最本质的样子。同时，每个搜索条后面都会有一个block字样，如果觉得对某些网站或者搜索条不满意，可以点击一些block就可以在以后的搜索中屏蔽这些搜索条。 Yet Another Weibo Filter 微博，是我们日常接触到较多的社交工具，甚至很多人每天都会反复多次刷微博。如果你喜欢用电脑浏览器刷微博应该清楚，它的页面信息十分混乱，多而杂，热门视频、特别关注、微博电影榜等等。我们唯一想看的就是微博，但是在浏览过程中却不得不被这些混乱的信息所干扰。有了Yet Another Weibo Filter就不用为此烦恼了，让你看真正想看的微博。 安装Yet Another Weibo Filter脚本之后打开微博会发现，右上角会出现一个漏斗状的一个图标，点击图标会打开上述界面，我们可以对微博进行内容、账号、话题、来源等进行过滤和设置，而且可以对版面进行清理，功能进行改造，而且还可以通过外观样式来修改字体、字号等内容，看看下面这幅图，经过版面清理之后是不是很整洁？ 百度网盘直链下载助手百度网盘是资源共享使用较多的一个工具，因此很多同学会通过各种网盘搜索工具寻找百度网盘的资源。但是资源找到了，会发现一个令人头疼的问题，文件太大无法直接下载，必须保存到个人网盘、打开PC客户端才可以下载。而打开客户端下载又被百度限速，非常痛苦，百度网盘直链下载助手就能够轻松解决这个问题。 安装百度网盘直链下载助手这个脚本之后会发现，浏览器打开百度网盘时上端会出现一个下载助手的选项卡，点击后会弹出两个选项：API下载、外链下载。这样的话可以直接点击调用IDM等下载工具进行下载，也可以复制下载链接，粘贴到一些下载工具后下载。 豆瓣资源下载大师 喜欢影视、音乐、图书的同学对豆瓣应该都不陌生，有大量的影视评论、书评。很多人会想，豆瓣上书籍、影视、音乐倒是不少，但是只能看看评论、评分，又有什么意义呢？豆瓣资源下载大师就让这个网站变的有了意义，把一个单纯的论坛和资源紧密的联系了一起。 安装豆瓣资源下载大师脚本之后，打开要找的电影、电视剧、图书等，会在右端状态栏很多匹配的资源列表，当然也包括下载的链接，下面就通过一个动画来演示下载《流畅的Python》这本书籍。 点击匹配的对应资源即可找到下载链接。 破解VIP会员视频集合 看电影、追剧，是很多同学闲暇之余最大的乐趣之一。但是发现我们要看的影视分布在优酷、腾讯、爱奇艺等平台，如果要买吧，太耗钱，不买吧，又要忍受冗长的广告。狠下心买了之后发现，很多电影需要观影券，这时候都会愤恨的说一句”与其这样，我还买你们会员干什么？“ 既然买了会员还不行，那么只有通过暴力方法来解决这个问题。关于视频破解工具，网上可谓是层出不穷，但是经过我的试用发现，真的不敢恭维，绝大多数都是不稳定或者压根不能用，而剩余个别能用的在打开时又非常缓慢，卡顿，直到遇到破解VIP会员视频集合这个脚本，发现真的令人惊讶，怎么可以有这么强大的神器？ 安装脚本之后会发现，打开视频后会在左边缘出现一个黄色箭头，点击这个箭头之后会弹出多个资源选项，点击其中一个会对我们看的视频进行解析，能够跳过广告、破解会员、观影券限制，更重要的是，它还很快，下面就来演示一下。 重点！！！亲测优酷、爱奇艺、腾讯视频均可用！ 脚本安装方法安装方式有两种： Chrome网上应用店 离线安装 Chrome网上应用店 如果能够访问Chrome网上应用店，我建议通过应用商店安装，便捷、安全。只需打开应用商店，搜索Tampermonkey，添加至Chrome即可。 离线安装 如果无法访问应用商店，则只能通过离线下载crx格式插件，然后点击右上角—更多工具—扩展程序，把crx格式插件拖动到空白处即可， tampermonkey安装之后点击图标，选择获取新脚本， 然后点击GreasyFork， 然后搜索、点击对应的的脚本安装即可， 插件下载如果无法访问Chrome网上应用店，则只能通过离线下载安装的方式，网上有很多Tampermonkey的资源，但是大多数很混乱，为了避免寻找的麻烦，我把插件进行共享了，需要的可以关注公众号，回复关键字”tmk“获取。]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习资源 | 如何学习优化算法？]]></title>
    <url>%2F2019%2F07%2F13%2Flearn-optimization%2F</url>
    <content type="text"><![CDATA[前言 在学习机器学习的一段时间之后，如果善于总结都会发现，无论是传统机器学习中比较经典的支持向量机，还是深度学习，无论是目前应用较广的计算机视觉，还是让AlphaGo大发神威的强化学习，最终都会涉及一个优化问题，或者是微积分系列的凸优化算法，或者是粒子群、蚁群等群体智能优化算法，或者是近几年比较热门的黑盒优化算法。尤其是近两年在工业控制方面契合度较高的强化学习，仔细分析它的模型，其实就是一个数学优化模型。最优化问题在当今的军事、工程、管理等领域有着极其广泛的应用。因此，优化算法的重要性可见一斑。理解优化算法，能够有助于理解深度学习的运作过程，对于模型的优化和改进也大有益处。本文就概括一下常用的优化算法并介绍一些学习资源。 优化算法概括 我个人对优化算法划分主要为3类，分别是： 凸优化 智能优化 黑盒优化 其中目前用的比较广泛的，尤其是在机器学习领域就是凸优化，例如梯度优化算法系列的梯度下降法、随即梯度下降、小批量梯度下降法、动量法momentum、Adagrad、RMSProp、Adadelta、Adam等，它们都是以梯度下降法为基础，在梯度下降法的基础上进行改进和优化。除了常用的这些还有牛顿法系列，以及无约束优化算法中的模式搜索法、Rosenbrock方法、单纯形搜索法、Powell方法。 凸优化虽然很成熟，但是很多工程问题并非是严格的符合凸优化的要求，换句话说，它是一个非凸优化问题，这样直接利用前面提到的这些算法很容易陷入局部最小值。因此，为了满足工程需求，研究者会根据问题的需求提出一些新颖的优化算法，其中就包括目前在工程应用领域比较热门的群体智能优化算法系列，例如，粒子群优化、模拟退火法、遗传算法，它们以独特而适应性强的有点在工程应用领域倍受欢迎，尤其是在复杂数学模型求解问题中能够更快速的求解同时避免陷入局部最优。 黑盒优化算法我最初是在谷歌开放的内部调参系统Google Vizier介绍论文Google Vizier: A Service for Black-Box Optimization提到的。在前面的优化算法中，优化问题都是建立在一个完整的数学模型基础之上，但是现实世界中很多场景是很难用数学模型来描述，或者没有数学模型，例如我们经常接触到的交通系统。在这种问题求解过程中，上述严格依赖数学模型的优化算法就显得有些捉襟见肘。谷歌在2017年在开放内部调参系统的介绍论文中详细介绍了它们用于调参的几种优化算法，其中包括如下几种算法： 贝叶斯优化 进化策略 SMAC 随机搜索 并在文中详细的对比了几种黑盒优化算法的效果。 下面分别针对这3类优化算法介绍一些学习资料。 凸优化算法 凸优化算法在目前机器学习中用的较多，其中分别有： 梯度下降法 动量法 Adam RMSProp Adagrad … 感兴趣的可以看我的另一篇文章，里面对机器学习中常用的优化算法推导过程及不同算法之间的关系进行了详细的阐述：一文了解人工智能中常用的优化算法 由于凸优化发展时间较长，而且理论体系比较完善，因此在微积分、数值计算等课程中都会涉及一部分，但是分布比较零散，不同于目前机器学习系列的课程，针对性较强，而且内容专一。虽然课程方面没有针对纯粹优化算法的，但是书籍方面却有很多，在这里我推荐两本不错的凸优化算法的书籍， 《最优化理论与方法》—袁亚湘，孙文瑜 作者袁亚湘为中国科学院院士、数学家，在计算数学、运筹学、应用数学领域有较深入的研究。曾有幸听过袁亚湘院士到学校开的优化算法专题讲座，真可谓是”听君一席话，胜读十年书”，于是就购买了袁亚湘院士的这本书籍。语言生动而易懂，系统地介绍了无约束量优化，约束优化和非光滑量优化的理论和计算方法，内容全面而丰富。 《最优化理论与算法（第2版）》—陈宝林 本书是陈宝林教授在多年的授课基础之上编著而成，与袁亚湘院士的书籍目录划分结构不同，但是我认为这种内容分层更有助于初学者的学习，他分别把优化算法划分成单纯形方法、对偶理论、灵敏度分析、运输问题、内点算法、非线性规划KT条件、无约束优化方法、约束优化方法、整数规划和动态规划等内容。 智能优化算法 智能优化算法的发展历史相对而言要短一些，但是由于都是在工程应用领域遇到瓶颈是应运而生，因此它的实用价值和效果更加让它们受欢迎，目前比较经典的智能优化算法有， 遗传算法 禁忌搜索 模拟退火法 蚁群算法 粒子群优化算法 由于智能优化算法更多是应工程应用需求而生，因此在数学模型方面并没有太多改进，因此在通识教育的数学课程中也很少涉及，同时，相关的书籍较少，在这里我就推荐一本智能优化算法的书籍。 《智能优化方法》—汪定伟 之所以推荐这本书，更多的是因为它的全面，它几乎囊括了目前所有主流的智能优化算法，其中当然就有遗传算法、蚁群算法、粒子群算法等。书中讨论这些算法的产生和发展、算法的基本思想和理论、基本构成、计算步骤和主要的变形以及数值例子和实际应用，对于学习者非常友好。 黑盒优化算法 就如同前文所讲，黑盒优化算法我最初实在2017年谷歌开放内部调参系统的介绍论文中看到的，它详细的介绍了内部调参系统Google Vizier使用的几种主流黑盒优化算法。之所以称之为黑盒，就是因为在这类优化问题中我们没有数学模型，我们不清楚优化的目标函数到底什么样。这种场景和我们日常所接触的现实场景更加贴近，因此它的实用价值自然不言而喻。 在谷歌的这篇文章中，不仅介绍了系统内部使用的黑盒优化算法，还在不同维度求解问题下对比了以下几种优化算法的效果： 随机搜索 贝叶斯 SMAC 进化策略 概率搜索 虽然谷歌的文章发表于2017年，但是里面提及的算法并不算新颖，其中的算法都是经过几年甚至几十年的不断改进而形成现如今的样子，所以要想详细学习需要看一下Google Vizier: A Service for Black-Box Optimization这篇提及的参考文献，比较零散。虽然这些成熟算法的理论体系比较零散，但是它们共同用到的理论知识却是成体系的，它们都用到了概率论\随机过程相关的知识，尤其是其中表现较好的贝叶斯优化和进化策略，都是建立在高斯过程的基础之上，因此，本文就推荐1本随机过程方面的书籍，对这些概率论\随机过程的基础知识有所了解更加有助于对这些成形算法的理解。 《随机过程（原书第2版）》—Sheldon M.Ross 本书由世界著名的应用概率专家和统计学家Sheldon M. Ross编著，本书介绍了从概率论基础概念，到各种常见的分布模型。详细的介绍随机过程中经典的知识，包括Poisson过程、Markov链、鞅、Brown运动、随机序关系、Poisson逼近，并详细的介绍了这些理论的应用，更加有助于理解和学习。]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>优化算法</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[效率工具 | 推荐两款提高windows下工作效率的工具]]></title>
    <url>%2F2019%2F07%2F13%2Ftwo-windows-tools%2F</url>
    <content type="text"><![CDATA[前言好的工具能让做事效率事半功倍，学习和工作都是这样。不同专业方向都会有一些很知名、耳熟能详的工具，例如开发方面的visual studio、pycharm，办公方面的office、xmind。这些软件的确很强大，但是再强大的工具都很难做到面面俱到，把效率考虑的十分周全。而有一些高手就及时发现里面的不足之处并开发出一些强大高效的工具，能够让日常工作效率大大提升，本文要介绍的两款工具就是这样的：冷门而强大，它们分别是：DropletIt和Quicker，下面就来看一下这两款工具究竟强大在哪里。 DropIt 工作中，日积月累会积攒很多各种各样的文件，有word、Excel、powerpoint、pdf等文档，有png、jpg等图片，有zip、tgz、7z等压缩包，尤其是很多同学都有个习惯，为了方便会放在桌面上，当想要找自己需要的东西时如同大海捞针一样，不知道从何下手。我想这是困扰很多人的问题，删除—积累，不断的重复，但是始终没有找到一个高效的解决文件分类方法。我想说，有了DropIt，再也不用担心文件分类与管理了，真正的实现了文件一建整理，下面来介绍一下DropIt的使用。 下载安装 下载安装之后桌面会有这样一个图标， 添加协议 为了满足我们整理文件的偏好和需求，需要对DropIt设置一下协议，让它按照我们预先设定的协议整理，添加协议主要包括4个部分： 名称：添加协议的名称，按照自己的爱好随便命名即可。 规则：匹配文件的规则，按照我们需要整理的文件设置匹配规则，例如\.png*匹配以png结尾的文件，如果包含多个规则可以用;隔开。 操作：对我们规则匹配到的文件采用的操作，其中包括移动、删除、压缩等。 目标文件夹：对文件处理的目标文件夹，例如，移动规则匹配到的文件到目标文件夹。 例如，上述我个人设置的两个协议，分别对图片(bmp、gif、jpg)和压缩包(zip、7z)进行处理，将图片和压缩包分别移动到指定的文件夹内。 设置好协议之后只需要选中文件，拖动到DropIt图标上方即可，下面来看看效果， 这样，选中的文件会按照我们预先设定的协议分别移动到对应的文件夹内，就不用我们逐个选中文件然后剪切、粘贴到指定文件夹。 Quicker 之前介绍过两款高效的办公工具：Listary和Wox。如果说Listary和Wox是键盘增强工具，那么Quicker就是一款强大的鼠标增强工具，能够让对鼠标比较依赖的同学发现，原来鼠标可以做这么多事情。 我们都知道，大多数鼠标包含3个按键，分别是：左键、右键、中键。其中左键和右键日常工作中使用较为频繁，但是中键除了上下翻页之外很少使用。Quicker就合理的利用了这一点，为鼠标中键添加上一个强大的快捷面板。软件默认的快捷面板包含我们常用的记事本、计算器、截图、我的电脑、Excel等工具，能够避免再去开始菜单寻找这些小工具，能够大大提高效率。 如果觉得软件自带的动作不足以满足自己的使用需求，那么还可以添加其他的动作，添加方式包括两种： 添加他人分享的动作 自己设计动作 添加他人分享的动作 首先打开官网，https://getquicker.net/Share 会发现官网动作库包含很多别人分享的动作，其中不乏查询搜索、翻译、文本处理、编程相关，可以根据自己的需求搜索对应的动作，然后复制动作，中键打开快捷面板，点击鼠标右键，选择粘贴分享的动作，然后安装即可，下面来演示一下安装过程， 如果在分享的动作库找不到自己需要的，或者感觉别人分享的无法满足自己的需求，没问题，还可以选择自己设计动作，Quicker提供两种动作创建方式： 基础动作 组合动作 基础动作 基础动作主要包含打开网址、发送文本、模拟按键等，创建方法很简单：点击鼠标中键打开快捷面板，点击+号，创建基础动作，选择动作类型，录制即可，当然也可以选择快捷的方式录入打开网址等动作。 组合动作 如果觉得基础动作太单一，还不够便捷，没问题，我认为Quicker最强大的地方就是支持组合动作。创建组合动作相对而言也要复杂一些，我认为它像是一种高阶的编程语言，可以用条件语句、添加变量名来实现一连串的动作，这个相对复杂而且不够大众化，因此在这里不多阐述，如果喜欢折腾的可以查看官网教程，创建一些高级的动作来提高自己的效率。 https://www.yuque.com/quicker/help/xaction-editor]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【动手学计算机视觉】第八讲：传统目标检测之HOG特征]]></title>
    <url>%2F2019%2F07%2F10%2Fcv-hog%2F</url>
    <content type="text"><![CDATA[前言 如果自称为计算机视觉工程师，没有听说过前文提到的尺度不变特征变换(SIFT)，可以理解，但是如果没有听说过方向梯度直方图(Histogram of oriented gradient，HOG)，就有一些令人诧异了。这项技术是有发过国家计算机技术和控制研究所(INRIA)的两位研究院Navneet Dalal和Bill Triggs在2005年CVPR上首先发表提出(那时的CVPR含金量还是很高的)。原文Histograms of oriented gradients for human detection截止2019年7月10日引用率已经达到26856。 HOG通过计算局部图像提取的方向信息统计值来统计图像的梯度特征，它跟EOH、SIFT及shape contexts有诸多相似之处，但是它有明显的不同之处：HOG特征描述子是在一个网格秘籍、大小统一的细胞单元上进行计算，而且为了提高性能，它还采用了局部对比度归一化思想。它的出现，使得目标检测技术在静态图像的人物检测、车辆检测等方向得到大量应用。 在传统目标检测中，HOG可以称得上是经典中的经典，它的HOG+SVM+归一化思想对后面的研究产生深远的影响，包括后面要讲到的神作DPM，可以说，HOG的出现，奠定了2005之后的传统目标检测的基调和方向，下面就来了解一下这个经典之作。 方向梯度直方图 HOG特征的算法可以用一下几个部分概括， 梯度计算 单元划分 区块选择 区间归一化 SVM分类器 下面分别来详细阐述一下。 梯度计算由于后面要进行归一化处理，因此在HOG中不需要像其他算法那样需要进行预处理，因此，第一步就成了梯度计算。为什么选择梯度特征？因为在目标边缘处灰度变化较大，因此，在边缘处灰度的梯度就较为明显，所以，梯度能够更好的表征目标的特征。 我们都知道在数学中计算梯度需要进行微分求导，但是数字图像是离散的，因此无法直接求导，可以利用一阶差分代替微分求离散图像的梯度大小和梯度方向，计算得到水平方向和垂直方向的梯度分别是， G_{h}(x, y)=f(x+1, y)-f(x-1, y),\forall x, yG_{v}(x, y)=f(x, y+1)-f(x, y-1) ,\forall x, y其中$f(x,y)$表示图像在$(x,y)$的像素值1。 可以得到梯度值(梯度强度)和梯度方向分别为, M(x, y)=\sqrt{G_{h}(x, y)^{2}+G_{v}(x, y)^{2}}\theta(x, y)=\arctan \left(G_{h}(x, y) / G_{v}(x, y)\right.单元划分 计算得到梯度的幅值和梯度方向之后，紧接着就是要建立分块直方图，得到图像的梯度大小和梯度方向后根据梯度方向对图像进行投影统计，首先将图像划分成若干个块(Block)，每个块又由若干个细胞单元(cell)组成，细胞单元由更小的单位像素(Pixel)组成，然后在每个细胞单元中对内部的所有像素的梯度方向进行统计。Dalal和Triggs通过测试验证得出，把方向分为9个通道效果最好，因此将180度划分成9个区间，每个区间为20度，如果像素落在某个区间，就将该像素的直方图累加在该区间对应的直方图上面，例如，如果像素的梯度方向在0~20度之间，则在0~20对应的直方图上累加该像素对应的梯度幅值。这样最终每个细胞单元就会得到一个9维的特征向量，特征向量每一维对应的值是累加的梯度幅值。 区块选择为了应对光照和形变，梯度需要在局部进行归一化。这个局部的区块该怎么选择？常用的有两种，分别是矩形区块(R-HOG)和圆形区块(C-HOG)，前面提供的例子就是矩形区块，一个矩形区块由三个参数表示：每个区块由多少放歌、每个方格有多少像素、每个像素有多少通道。前面已经提到，经过作者验证，每个像素选择9个通道效果最佳。同样，作者对每个方格采用的像素数也进行验证，经过验证每个方格采用3*3或者6*6个像素效果较好。 区间归一化每个方格内对像素梯度方向进行统计可以得出一个特征向量，一个区块内有多个方格，也就有多个特征向量，例如前面的示例区块Block内就有4个9维向量。这一步要做的就是对这4个向量进行归一化，Dalal和Triggs采用了四种不同的方式对区块进行归一化，分别是L2-norm、L2-hys、L1-norm、L1-sqrt，用$v$表示未被归一化的向量，以L2-norm为例，归一化后的特征向量为， v=\frac{v}{\sqrt{\|v\|_{2}^{2}+\varepsilon^{2}}}作者通过对比发现，L2-norm、L2-hys、L1-sqrt三种方式所取得的效果是一样的，L1-norm表现相对差一些。 SVM分类器最后一步，也是比较关键的一步，就是训练分类器，用SVM对前面提取的图像特征向量进行训练，寻找一个最优超平面作为决策函数，得到目标的训练模型。 编程实践完整代码请查看： https://github.com/Jackpopc/aiLearnNotes/blob/master/computer_vision/HOG.py HOG是一个优秀的特征提取算法，因此本文就仅介绍并实现特征提取算法部分，后面的训练分类器和目标检测偏重于机器学习内容，在这里就不多赘述。 HOG算法非常经典，因此，很多成熟的第三方库都已经集成了这个算法，例如比较知名的计算机视觉库OpenCV，对于HOG特征提取比较简单的方式就是直接调用OpenCV库，具体代码如下， 1234import cv2hog = cv2.HOGDescriptor()img = cv2.imread("../data/2007_000129.jpg", cv2.IMREAD_GRAYSCALE)des = hog.compute(img) 为了更好的理解HOG算法，本文就跟随文章的思路来重新实现一遍算法。 第一步：计算梯度方向和梯度幅值 这里用Sobel算子来计算水平和垂直方向的差分，然后用对梯度大小加权求和的方式来计算统计时使用的梯度幅值， 123456def compute_image_gradient(img): x_values = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5) y_values = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5) magnitude = cv2.addWeighted(x_values, 0.5, y_values, 0.5, 0) angle = cv2.phase(x_values, y_values, angleInDegrees=True) return magnitude, angle 第二步：统计细胞单元的梯度方向 指定细胞单元尺寸和角度单元，然后对用直方图统计一个细胞单元内的梯度方向，如果梯度角度落在一个区间内，则把该像素的幅值加权到和角度较近的一个角度区间内， 123456789101112def compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit): centers = [0] * bin_size # 遍历细胞单元，统计梯度方向 for i in range(cell_magnitude.shape[0]): for j in range(cell_magnitude.shape[1]): strength = cell_magnitude[i][j] gradient_angle = cell_angle[i][j] min_angle, max_angle, mod = choose_bins(gradient_angle, unit, bin_size) # 根据角度的相近程度分别对邻近的两个区间进行加权 centers[min_angle] += (strength * (1 - (mod / unit))) centers[max_angle] += (strength * (mod / unit)) return centers 第三步：块内归一化 根据HOG原文的思想可以知道，图像内分块，块内分细胞单元，然后对细胞单元进行统计。一个块由多个细胞单元组成，统计了每个细胞单元的梯度特征之后需要对这几个向量进行归一化， 1234567891011121314151617def normalized(cell_gradient_vector): hog_vector = [] for i in range(cell_gradient_vector.shape[0] - 1): for j in range(cell_gradient_vector.shape[1] - 1): block_vector = [] block_vector.extend(cell_gradient_vector[i][j]) block_vector.extend(cell_gradient_vector[i][j + 1]) block_vector.extend(cell_gradient_vector[i + 1][j]) block_vector.extend(cell_gradient_vector[i + 1][j + 1]) mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector)) magnitude = mag(block_vector) if magnitude != 0: # 归一化 normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector] block_vector = normalize(block_vector, magnitude) hog_vector.append(block_vector) return hog_vector 第四步：可视化 为了直观的看出特征提取的效果，对下图进行特征提取并且可视化， 可视化的方法是在每个像素上用线段画出梯度的方向和大小，用线段的长度来表示梯度大小， 12345678910111213141516171819def visual(cell_gradient, height, width, cell_size, unit): feature_image = np.zeros([height, width]) cell_width = cell_size / 2 max_mag = np.array(cell_gradient).max() for x in range(cell_gradient.shape[0]): for y in range(cell_gradient.shape[1]): cell_grad = cell_gradient[x][y] cell_grad /= max_mag angle = 0 angle_gap = unit for magnitude in cell_grad: angle_radian = math.radians(angle) x1 = int(x * cell_size + magnitude * cell_width * math.cos(angle_radian)) y1 = int(y * cell_size + magnitude * cell_width * math.sin(angle_radian)) x2 = int(x * cell_size - magnitude * cell_width * math.cos(angle_radian)) y2 = int(y * cell_size - magnitude * cell_width * math.sin(angle_radian)) cv2.line(feature_image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude))) angle += angle_gap return feature_image 提取的特征图为，图中白色的线段即为提取的特征， 完整代码如下， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import cv2import numpy as npimport mathimport matplotlib.pyplot as pltimg = cv2.imread("../data/2007_000129.jpg", cv2.IMREAD_GRAYSCALE)def compute_image_gradient(img): x_values = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5) y_values = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5) magnitude = abs(cv2.addWeighted(x_values, 0.5, y_values, 0.5, 0)) angle = cv2.phase(x_values, y_values, angleInDegrees=True) return magnitude, angledef choose_bins(gradient_angle, unit, bin_size): idx = int(gradient_angle / unit) mod = gradient_angle % unit return idx, (idx + 1) % bin_size, moddef compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit): centers = [0] * bin_size for i in range(cell_magnitude.shape[0]): for j in range(cell_magnitude.shape[1]): strength = cell_magnitude[i][j] gradient_angle = cell_angle[i][j] min_angle, max_angle, mod = choose_bins(gradient_angle, unit, bin_size) print(gradient_angle, unit, min_angle, max_angle) centers[min_angle] += (strength * (1 - (mod / unit))) centers[max_angle] += (strength * (mod / unit)) return centersdef normalized(cell_gradient_vector): hog_vector = [] for i in range(cell_gradient_vector.shape[0] - 1): for j in range(cell_gradient_vector.shape[1] - 1): block_vector = [] block_vector.extend(cell_gradient_vector[i][j]) block_vector.extend(cell_gradient_vector[i][j + 1]) block_vector.extend(cell_gradient_vector[i + 1][j]) block_vector.extend(cell_gradient_vector[i + 1][j + 1]) mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector)) magnitude = mag(block_vector) if magnitude != 0: normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector] block_vector = normalize(block_vector, magnitude) hog_vector.append(block_vector) return hog_vectordef visual(cell_gradient, height, width, cell_size, unit): feature_image = np.zeros([height, width]) cell_width = cell_size / 2 max_mag = np.array(cell_gradient).max() for x in range(cell_gradient.shape[0]): for y in range(cell_gradient.shape[1]): cell_grad = cell_gradient[x][y] cell_grad /= max_mag angle = 0 angle_gap = unit for magnitude in cell_grad: angle_radian = math.radians(angle) x1 = int(x * cell_size + magnitude * cell_width * math.cos(angle_radian)) y1 = int(y * cell_size + magnitude * cell_width * math.sin(angle_radian)) x2 = int(x * cell_size - magnitude * cell_width * math.cos(angle_radian)) y2 = int(y * cell_size - magnitude * cell_width * math.sin(angle_radian)) cv2.line(feature_image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude))) angle += angle_gap return feature_imagedef main(img): cell_size = 16 bin_size = 9 unit = 360 // bin_size height, width = img.shape magnitude, angle = compute_image_gradient(img) cell_gradient_vector = np.zeros((height // cell_size, width // cell_size, bin_size)) for i in range(cell_gradient_vector.shape[0]): for j in range(cell_gradient_vector.shape[1]): cell_magnitude = magnitude[i * cell_size:(i + 1) * cell_size, j * cell_size:(j + 1) * cell_size] cell_angle = angle[i * cell_size:(i + 1) * cell_size, j * cell_size:(j + 1) * cell_size] cell_gradient_vector[i][j] = compute_cell_gradient(cell_magnitude, cell_angle, bin_size, unit) hog_vector = normalized(cell_gradient_vector) hog_image = visual(cell_gradient_vector, height, width, cell_size, unit) plt.imshow(hog_image, cmap=plt.cm.gray) plt.show()if __name__ == '__main__': img = cv2.imread('../data/2007_002293.jpg', cv2.IMREAD_GRAYSCALE) cv2.imshow("origin", img) cv2.waitKey() main(img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[效率工具 | Windows下一款强大的启动搜索工具]]></title>
    <url>%2F2019%2F07%2F02%2Ftools-wox%2F</url>
    <content type="text"><![CDATA[前言对于大多数人来说，日常生活和工作中接触较多的软件和工具就是浏览器、专业软件、翻译软件、笔记、办公等。其实有很多软件在名气上虽然不如这些商业软件，但是功能却丝毫不输这些知名软件。在工作中能够大大提高办公效率，而且内存占用小、免费开源。大家都知道windows自带的文件浏览器查找文件是一件非常令人痛苦的事情，不仅速度缓慢，而且准确度出奇的低，让人感觉很鸡肋。但是当我们要找一个文档时却忘记放在哪里，挨个硬盘去翻更加令人感到折磨。所以不得不去借助一些高效的搜索工具，其中用的较多、名气较大的就是everything。我个人也一直在用这款工具，的确非常强大，快速、支持正则表达式匹配。它作为一个文件搜索工具的确很称职，但是当我们想要更多扩展功能，例如用于程序启动工具时everything就显得有些不足了。之前我介绍过一款工具叫做Listary，能够完美的与everything结合，既能涵盖everything强大的搜索功能，还能融合Listary实用的启动功能。本文再给大家介绍一款与Listary类似的工具—Wox，有相同之处，也有很大的差异之处，各位可以根据自己的喜好进行选择。 Wox Wox是一款启动器。这就是它与Listary的最大的不同之处—定位不同。Listary本身兼顾搜索与启动，但是在搜索方面不如everything，如果想使用更加丰富的搜索功能需要在设置里配置一下everything，如果满足于Listary提供的快速搜索功能则无需配置。而Wox的定位就是一个简单、纯净的启动器。它可以快速的启动本机安装的各种程序、文件、网页等。当然，它也可以用于文件搜索，它指定的后端搜索工具是everything，所以在打开Wox之前需要先启动everything，这样才能够使用强大的搜索功能。它不仅可以用于搜索程序和文件，还可以配置各种丰富的插件满足更多场景的需求，例如计算器、天气、翻译、网页搜索等。 Wox与Listary前面提到了，Wox与Listary有很多类似之处： 搜索 启动器 配合everything使用 但是Wox也有很多特别之处是Listary无法比拟的，Wox的特别之处主要有如下几点： 支持丰富的插件 支持自己定义插件 支持多种主题切换 支持自定义快捷键 支持丰富插件Wox的插件主要分类两种： 系统插件 第三方插件 系统插件不需要关键字唤醒，直接用Alt + Space调出Wox的工具栏输入相应的命令即可，系统插件主要包含如下几类： 程序插件 颜色插件 控制面板插件 计算器插件 网址插件 Web搜索插件 命令行插件 文件夹插件 拿其中几个举个例子， 程序插件 Alt+空格键激活Wox，然后输入要启动的程序即可， 计算器插件 计算器对于很多人来说虽然不是主要的工作工具，但是偶尔会用到，当我们需要用计算器的时候就需要点击windows图标，搜索“计算器”，这样比较麻烦，Wox集成了计算器插件，激活Wox后输入要计算的公式即可， 网址插件 当我们要浏览某个网站时往往需要打开浏览器-&gt;在地址栏输入网址，Wox的浏览器插件大大简化这个过程，只需要激活Wox，输入相应网址即可， 其他还有很多实用的系统插件，可以查看网站进行了解， http://doc.wox.one/zh/basic/ 除了Wox自带的系统插件，Wox还提供了多大230款第三方插件，其中就包含有道翻译、天气查询、Steam、Putty、二维码、维基百科、书签搜索、待办事项、进制转换、哔哩哔哩、Skype、FileZilla、Stack Overflow、沪江日语等等。只需要下载安装一下即可，而且Wox提供了多选、简单的安装方式， 安装第三方插件 命令安装 这是最简单的一种安装方式，使用wpm进行插件的安装、卸载管理， 123456789# 安装插件wpm install &lt;插件名称&gt;# 卸载插件wpm uninstall &lt;插件名称&gt;# 列出已安装插件wpm list 手动安装 如果由于网络、代理等原因无法命令安装，可以打开插件主页[http://www.wox.one/plugin]下载到本地(以.wox结尾),拖动到Wox搜索框进行安装， 支持自己定义插件除了官网提供的系统插件和第三方插件之外，Wox还支持自定义插件，它支持以下3种方式来定义插件， plugin.json C# Python Wox与插件之间的通信原理： 支持多种主题切换 Wox安装后会发现自带BlurBlack、BlurWhite、Dark、Gray、Light、Metro Server、Pink七种主题，除了上述提到的7种主题之外，还可以在官网自定义主题，配置之后下载主题(.xaml文件)，放置到C:\Users\YourUserName\AppData\Local\Wox\app-1.3.524\Themes路径下，重启Wox即可。 支持自定义快捷键这一点也是Wox吸引人的一点，它支持自定义快捷键。如果觉得Alt+空格启动程序、文件夹还不够快捷，可以把常用的命令保存到快捷键，这样当使用快捷键时能够快速达到目的。 例如，我想百度搜索“哈尔滨工业大学”，使用Wox的方式是这样的， Alt + 空格激活Wox 输入”bd 哈尔滨工业大学” 这样比起”打开浏览器-&gt;打开百度-&gt;搜索”已经便捷了很多，但是还有更便捷的，就是Wox支持的快捷键。 可以把常用的命令添加到快捷键，例如把”bd 哈尔滨工业大学”添加为快捷键”Ctrl+Alt+H”,能够同时激活Wox并输入相应的命令，然后按Enter键即可搜索。 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
        <tag>工具</tag>
        <tag>实用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐一份热门机器学习资源]]></title>
    <url>%2F2019%2F07%2F01%2Fhomemade-machine-learning%2F</url>
    <content type="text"><![CDATA[前言最近几年人工智能异常火热，随之而来的就是各种针对入门者的学习资源，其中不乏很多经典的教程例如吴恩达的《机器学习》、《深度学习工程师》，但是也有很多千篇一律、照本宣科的学习资源。在学习进阶过程中很多人会到GitHub寻找一些可以动手实践的机器学习项目，会发现GitHub上会有和机器学习相关的各种awesome，恨不得把所有和机器学习、深度学习的资源都囊括进去。这样虽然全面，但是我认为它的价值并不高。我们之所以希望有经验者推荐学习资源，就是因为时间、精力有限，希望能够在鱼龙混杂的学习资源里筛选出真正有价值，或者与众不同的，能够让我们利用有限的精力和时间内真正学会一些东西。近期GitHub有一个关于机器学习的热门开源项目，homemade-machine-learning，目前已经11k+个star，近一周达到1.1k+，经过一段时间的学习发现这的确一个不错的学习项目，下面就详细介绍一下这个项目。 Homemade Machine Learning 开门见山，这个开源项目主要有以下几个优点： 少而精 不依赖python第三方库 详细解释它们背后的数学原理 交互式Jupyter notebook演示程序 丰富易懂的示例 这个项目用Python实现了目前热门、使用的一些机器学习算法，而不是像很多开源项目那样，从头至尾把每个机器学习算法都实现一遍。换句话说，这个开源项目追求“少而精”，它分别从监督学习、非监督学习、神经网络、异常检测、回归、分类这些类别中选择一种算法进行详细阐述算法背后的数学原理，然后使用jupyter notebook交互式的演示，随后会用多个示例进行实现，动手操作，不依赖集成的python第三方库，更容易理解机器学习算法的原理。 项目概括该项目主要包括如下几个方面的机器学习算法： 监督学习 无监督学习 异常检测 神经网络 其中监督学习又分为回归和分类，回归算法选取的是比较常用的线性回归，分类算法选取的是比较实用的逻辑回归。无监督学习中主要针对聚类进行讲解，项目中选取的是热门的k-means。异常检测是指通过大多数数据来检测出有显著差异的事件、观测结果，在数据处理、图像处理都有应用。神经网络中选择的是多层感知机。 安装首先要保证电脑上正确的安装了Python，然后安装一些项目依赖， 1pip install -r requirements.txt requirements: 1234567jupyter==1.0.0matplotlib==3.0.1numpy==1.15.3pandas==0.23.4plotly==3.4.1pylint==2.1.1scipy==1.1.0 如果要使用jupyter notebook，需要在命令行输入下面命令， 1jupyter notebook 然后会在浏览器中打开如下窗口， 详细介绍数学原理 我认为这是这个项目吸引人的地方，也是它与众不同的地方，它和很多项目不同，浮于表面，把很多环节都认为是既定的去阐述，有一些初学者会看的云里雾里，不明白“为什么是这样？”这个项目则不同，它详细、深入的阐述每个算法背后的数学原理，循序渐进，配合可视化很容易让人理解。 详细编码过程 该项目不过多依赖tensorflow、pytorch、keras这些高度集成的机器学习平台，它从梯度下降到损失函数、从训练到预测都是一步一步实现，尽量减少对高度集成第三方库的依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@staticmethoddef gradient_descent(data, labels, initial_theta, lambda_param, max_iteration): """Gradient descent function. Iteratively optimizes theta model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param initial_theta: initial model parameters. :param lambda_param: regularization parameter. :param max_iteration: maximum number of gradient descent steps. """ # Initialize cost history list. cost_history = [] # Calculate the number of features. num_features = data.shape[1] # Launch gradient descent. minification_result = minimize( # Function that we're going to minimize. lambda current_theta: LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Initial values of model parameter. initial_theta, # We will use conjugate gradient algorithm. method='CG', # Function that will help to calculate gradient direction on each step. jac=lambda current_theta: LogisticRegression.gradient_step( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Record gradient descent progress for debugging. callback=lambda current_theta: cost_history.append(LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param )), options=&#123;'maxiter': max_iteration&#125; ) # Throw an error in case if gradient descent ended up with error. if not minification_result.success: raise ArithmeticError('Can not minimize cost function: ' + minification_result.message) # Reshape the final version of model parameters. optimized_theta = minification_result.x.reshape((num_features, 1)) return optimized_theta, cost_history@staticmethoddef gradient_step(data, labels, theta, lambda_param): """GRADIENT STEP function. It performs one step of gradient descent for theta parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Initialize number of training examples. num_examples = labels.shape[0] # Calculate hypothesis predictions and difference with labels. predictions = LogisticRegression.hypothesis(data, theta) label_diff = predictions - labels # Calculate regularization parameter. regularization_param = (lambda_param / num_examples) * theta # Calculate gradient steps. gradients = (1 / num_examples) * (data.T @ label_diff) regularized_gradients = gradients + regularization_param # We should NOT regularize the parameter theta_zero. regularized_gradients[0] = (1 / num_examples) * (data[:, [0]].T @ label_diff) return regularized_gradients.T.flatten()@staticmethoddef cost_function(data, labels, theta, lambda_param): """Cost function. It shows how accurate our model is based on current model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Calculate the number of training examples and features. num_examples = data.shape[0] # Calculate hypothesis. predictions = LogisticRegression.hypothesis(data, theta) # Calculate regularization parameter # Remember that we should not regularize the parameter theta_zero. theta_cut = theta[1:, [0]] reg_param = (lambda_param / (2 * num_examples)) * (theta_cut.T @ theta_cut) # Calculate current predictions cost. y_is_set_cost = labels[labels == 1].T @ np.log(predictions[labels == 1]) y_is_not_set_cost = (1 - labels[labels == 0]).T @ np.log(1 - predictions[labels == 0]) cost = (-1 / num_examples) * (y_is_set_cost + y_is_not_set_cost) + reg_param # Let's extract cost value from the one and only cost numpy matrix cell. return cost[0][0] 丰富示例 理解了算法背后的数学原理，跟着作者一步一步实现了算法，要想更加深入的理解就需要把算法应用到不同方面，本项目提供了丰富的示例，其中不乏MNIST这类经典的演示样例。 其中每个项目后面都包含至少一个示例，可以获取对应的数据进行实现，这样对算法的理解和应用会有更加清晰而深入的认识。 更多精彩内容请关注公众号【平凡而诗意】~]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Github</tag>
        <tag>资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文熟练掌握Docker使用]]></title>
    <url>%2F2019%2F06%2F30%2Flearning-docker%2F</url>
    <content type="text"><![CDATA[Docker是由dotCloud公司发起并与2013年开源的一个项目，一径开源就备受欢迎，其主要项目至今在github已经54k个star。它是使用Go语言开发实现，基于Linux内核cgroup、namespace以及AUFS类等技术对进程进行封装隔离，属于一种操作系统层面的虚拟化技术。此后，进一步开发开始使用runC和containerd，进一步封装，从文件系统到网路互联，再到进行都进行隔离，极大的简化了容器的创建和维护，使得Docker比虚拟机更为轻便、快捷。 为什么要用docker？Docker与传统虚拟机一样，同属于虚拟化技术，但是它拥有众多虚拟机无法比拟的优势： 持续交付和部署 更快的迁移 更高效的利用系统资源 更快的启动时间 一致的运行环境 更轻松的维护和扩展 容器与虚拟机对比详情： 对于大多数开发人员感受最为就是前两点：持续交付和部署、更快的迁移。 我想这对于很多开发人员都是一个很头疼的问题，在开发过程中会遇到这种抱怨：“在我电脑上可以运行啊？为什么换一台电脑就不行了？” 虽然诸如maven、nodejs的package.json、Python的requirement.txt的出现使得迁移变得简单，但是它们更多的是使得在第三方工具包的迁移方面变得简单方面，但是在系统和开发环境方面却没有什么作用。docker确保了直行环境的一致性，可以在多平台上运行，使得应用迁移更加容易。此外，docker使用分层存储以及镜像技术，使得应用重复部分的复用更加容易，可以基于基础镜像做更多的扩展，使得系统的维护变得更加简单。 基本概念使用docker接触最多的就是以下3个概念， 镜像：image 容器：container 仓库：repository 了解这三个概念，对容器的整个生命周期便有了认识。在这里，我用简单的语言对上述3个概念进行描述 镜像：进行就相当于一个精简化的文件系统，例如官方提供的Ubuntu镜像，就只包含了最小化的root文件系统。 容器：容器是一个拥有自己root文件系统、自己网络配置、自己命名空间的进程。镜像和容器就像是编程中的类和实例，镜像时静态的定义，而镜像运行时的实体是容器。什么是类和实例？举一个编程的例子阐述一下， 1234567891011121314# 类class HelloWorld: def __init__(self, x, y): self.x = x self.y = y def add(self): return self.x + self.y# 实例hello_world = HelloWorld(2, 3)print(hello_world.add())&gt;&gt;&gt; 5 其中HelloWorld是类，hello_world是实例，类比一下，就能够理解容器和镜像之间的关系。 仓库：docker镜像仓库就如同github代码仓库一样，当一个人构建一个项目，想在其他其他电脑上运行这个项目，那么就去从代码仓库把这个项目克隆下来。docker镜像仓库也是这样，当构建一个镜像之后，想在其他服务器上使用这个镜像，就需要一个集中的存储、分发服务，仓库就是这样的服务。官方的镜像仓库是DockerHub，它存储了丰富的镜像，但是国内拉取镜像速度缓慢，因此可以使用国内镜像仓库进行替代，例如阿里云镜像仓库、网易云镜像仓库、DaoCloud镜像市场等。 安装docker目前支持Linux、Windows 10、macOS，下面就一个Linux安装为例， APT方式安装 首先安装HTTPS软件包和CV证书， 123456$ sudo apt-get update$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 添加软件源GPG密钥， 1$ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add 添加docker软件源， 1234$ sudo add-apt-repository \ "deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable" 安装docker ce, 12$ sudo apt-get update$ sudo apt-get install docker-ce 添加用户组 docker命令会使用Unix socket与docker引擎通讯，因此每次使用时会需要root权限，也就是需要在命令前加sudo比较麻烦，为了避免这个麻烦可以把建立docker组并把当前用户加入docker用户组， 12$ sudo groupadd docker$ sudo usermod -aG docker $USER 启动、退出、重启docker 123$ systemctl start docker$ systemctl stop docker$ systemctl restart docker 也可以使用， 123$ service docker start$ service docker stop$ service docker restart Dockerfile理解docker中一些基本概念，并完成docker安装下一步就是学习docker的使用。对于大多数开发人员来说，docker使用过程中最为核心的部分就是Dockerfile。 Dockerfile是一个文本文件，它包含了一些指令，docker镜像的构建就是通过Dockerfile中的这一条一条的指令完成的。也就是说，要构建一个镜像，就需要一个Dockerfile，然后根据自己的需求配置一些指令集合，下面就看一下Dockerfile中使用的一些指令。 FROM：指定基础镜像 定制我们的镜像，是需要以一个镜像为基础的，就是基础镜像，例如Ubuntu、 nginx、postgres、mysql等，例如，FROM Ubuntu:16.04，如果本地有Ubuntu基础镜像则使用本地基础镜像，如果没有则会到官方镜像仓库拉取，16.04是镜像版本号，如果不指定则会拉取lastest。 RUN：执行命令 RUN指定我们在构建镜像时需要执行的命令，比如apt-get install安装某个软件，pip install安装Python依赖包，配置软件源，配置时区等， 例如，RUN apt-get install python3。 ADD和COPY：文件操作 ADD和COPY是两个功能类似的指令，一般优先使用COPY，它比ADD更透明，它的功能是将本地文件拷贝到容器中，例如，COPY ./ /home/jackpop/test。 WORKDIR：指定工作路径 指定镜像的运行时的工作路径，例如，WORKDIR /home/jackpop/test 。 ENTRYPOINT：设置镜像主命令 指定镜像运行是运行的命令，例如, ENTRYPOINT [“python”, “-m”, “main”]。 LABEL：添加标签 可以为镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。 CMD：执行目标镜像中包含的软件 如果创建镜像的目的是为了部署某个服务，可能会执行某种形式的命令，可以包含参数。 EXPOSE：指定监听端口 给外部访问指定访问端口。 ENV：环境变量 为了方面程序运行，有时需要更新环境变量。 VOLUME：暴露数据库存储文件 USER：指定当前用户 其中常用的命令就是FROM、COPY、WORKDIR、RUN、ENTRYPOINT。 常用命令了解了Dockerfile的常用指令，我们该怎么对镜像和容器进行操作呢？下面就来学习一下docker常用的一些命令， 备注：由于我已经把当前用户加入到docker用户组，所以下面命令没有加sudo，如果没有加用户组需要使用sudo docker。 查看本地镜像 123$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 ****** 10 days ago 119MB 查看容器 123$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES*** *** *** *** *** *** *** *** 启动、停止、重启容器 123$ docker start $container_id$ docker stop $container_id$ docker restart $container_id 退出和进入镜像 12$ exit$ docker exec $container_id /bin/bash 启动镜像 1$ docker run $image_id 可以用—p和—dns指定端口和dns来配置网络。 container_id是容器ID，image_id是镜像ID。 拉取镜像 1$ docker image pull ubuntu 从Dockerfile创建镜像 1$ docker build 从一个修改的容器创建镜像 1$ docker commit 容器与本地之间复制文件 1$ docker cp 推送镜像 1$ docker push 为镜像打标签 1$ docker tag 重命名容器 1$ docker rename 删除容器 1$ docker rm 删除镜像 1$ docker rmi 搜索镜像 1$ docker search docker常用命令概括： 实践创建项目 123Test/├── Dockerfile└── main.py 写一个简单的测试程序 1234567891011121314151617181920# main.pyimport loggingfrom time import sleepimport numpy as nplogging.basicConfig(level=logging.DEBUG, format="'%(asctime)s - " "%(filename)s[line:%(lineno)d] - " "%(levelname)s: %(message)s")def main(): for i in range(10): logging.debug(np.random.randint(0, 5)) sleep(0.1)if __name__ == '__main__': main() Dockerfile 这是构建镜像中的重点部分， 1234567891011FROM ubuntu:16.04COPY ./ /home/Test_dockerWORKDIR /home/Test_dockerRUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip \&amp;&amp; ln -s pip3 /usr/bin/pip \&amp;&amp; ln -sf /usr/bin/python3 /usr/bin/python \&amp;&amp; rm -rf ls /var/cache/apt/* \ENTRYPOINT ["python3", "-m", "main"] 进入项目根目录 1$ cd Test 开始创建 1$ docker build test:v1.0 . test是指定构建镜像的名称，v1.0指定镜像标签，如果不指定，镜像名称和标签会显示为。 运行镜像 1234567891011$ docker run $image_id'2019-06-29 12:26:38,298 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,399 - main.py[line:13] - DEBUG: 2'2019-06-29 12:26:38,499 - main.py[line:13] - DEBUG: 1'2019-06-29 12:26:38,599 - main.py[line:13] - DEBUG: 3'2019-06-29 12:26:38,699 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,799 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:38,900 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,000 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,100 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,200 - main.py[line:13] - DEBUG: 2 当然也可以在基础镜像的基础上进行修改来创建我们的镜像，例如，我们拉取一个Ubuntu基础镜像，可以启动镜像后安装我们需要的软件和环境，然后利用docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]来创建一个新镜像。 延伸阅读除了基础的docker之外，还有一些高级的docker开源工具，比较知名的有如下3项， docker compose docker machine docker swarm 其中docker compose是官方编排项目之一，用于快速在集群中部署分布式应用。docker machine同样是官方编排项目之一，负责在多种平台上快速安装docker环境。docker swarm提供docker容器集群服务，是docker官方对容器云生态进行支持的核心方案。 除此之外，还有一些比较知名的集群管理系统，例如， Mesos Kubernetes 其中Mesos是来自UC Berkeley的集群资源管理开源项目，它可以让用户很容易实现分布式应用的自动化调度。Kubernetes是由Google团队发起并维护的给予docker的开源容器集群管理系统，应用比较广泛，它不仅支持场景的云平台，而且支持内部数据中心。 学习资源上述所讲的常用命令、指令含义等对于日常开发使用已经够用了，如果对Docker更深入的内容，例如，数据管理、安全、底层实现、容器与云计算等感兴趣可以选取其他的学习资料。在这里我推荐一份我认为不错的学习资料。就是yeasy大神在github开源的一份详细的docker教程—docker_practice，目前docker_practice项目在github已经13.7k个star，想深入学习的可以查看github项目， 也可以查看gitbooks， 或者关注公众号【平凡而诗意】回复关键字”dk”获取pdf和epub版教程， 更多内容请关注公众号【平凡而诗意】]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVPR2019最佳论文解读]]></title>
    <url>%2F2019%2F06%2F28%2FCVPR2019%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[前言 CVPR，全称IEEE Conference on Computer Vision and Pattern Recognition，与ECCV(Europeon Conference on Computer Vision)，ICCV( IEEE International Conference on Computer Vision)并称为计算机视觉领域三大会议，均为计算机视觉领域的顶级会议。由于近几年计算机视觉的异常火热，CVPR也就成为很多计算机视觉领域研究者趋之若鹜的盛宴，它的受关注程度更是今非昔比。CVPR2019于2019年6月16日在美国召开，此次会议共收到来自全球14104位研究者提交的5160篇文章，同比2018年增长56%，一举打破记录，受欢迎程度可见一斑。 CVPR2019最终共接收1294篇文章，尽管CVPR被计算机视觉领域视为顶尖，我个人认为，其中不乏质量平平的水文，真正令人印象深刻，几年之后依然被人所熟知且实用，并在算法思想方面取得跨越的却寥寥无几。闲话说完，回到本文的重点CVPR2019最佳论文，该荣誉最终由卡耐基梅隆大学、多伦多大学、伦敦大学学院的多位研究者斩获，论文名称为A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction，接下来，我详细解读一下这篇文章。 数学符号含义$s$ 光源上的点$v$ 可见场景内的点$x$ 不可见场景内的点$d$ 检测器上的点$\tau_{\mathcal{F}}$ 费马路径长度$I(\tau ; \boldsymbol{v})$ 瞬态 概念解释瞬态(transients):一种测量值，用于重建隐藏形状信息的大多数方法采用快速调制光源已经传感器来记录光子强度和旅行时间的测量值。费马路径(Fermat paths):首先返回的光子路径的超集合。费马路径长度(Fermat pathlengths):顾名思义，就是通过光速等计算出来的离散路径长度。 算法详解 目前大多数计算机视觉领域的研究都是围绕着视觉可见范围内的研究，但是理解视野范围之外的场景在很多领域却有着非常重要的应用，因此，这使得这项研究更加具有价值。被动方式通过分析隐藏场景所投射的阴影来粗略估计物体的运动和结构，或者利用光的相干性来定位隐藏对象。这些方法没有足够的信息来精确计算位置隐藏场景的三维形状。主动方式提取隐藏场景的附加信息时可能的。大多数重建隐藏形状信息的方法都是用调制光源和时间分辨传感器、超快光电二极管等，这些传感器不仅记录入射光子的强度，还在时间分辨率范围内记录它们到达的时间，这种测量称为瞬态。 大多数主动技术都是通过测量一个已知可见场景的不同位置的瞬态，然后根据已经获取的辐射成像逆向来进行三维重建，例如椭圆反投影、正则化线性系统、光锥变换等。这些方法主要有两个缺点： 它们依赖于辐射测量信息 为了简化反演问题，所有现有的重建技术都依赖于非视线场景的Lambertian 反射假设 在这篇文章中，作者提出一种使用视线以外场景的瞬态测量得到的几何信息的方法，克服了上述的限制。简言之，它主要使用视线内和视线外场景之间的一种称之为费马路径的几何路径星系，通过观察发现这些路径遵循镜面或者物体边界特点的反射定理。作者证明，费马路径对应于瞬态测量中的不连续性，不连续点的时间位置仅是视线外场景对象的形状而不是其反射率。利用上述理论，推导出一种精确重建视线外物体形状的算法，称之为费马流(Fermat Flow)。作者证明，费马路径长度的空间导数提供了一个简单的约束，它唯一地决定了隐藏场景点的深度和法线。这个导数是通过将光滑的路径函数拟合到一组稀疏的测量值上而得到，然后结合深度和法线信息来计算平滑网网格。概括一下，本文在隐藏物体重建方面主要包含以下3个步骤： 瞬态测量 求解费马流方程 表面拟合 测量瞬态 假设已经校准了从光源到可见点，和从可见点到检测器的距离 \mathcal{\tau\mathcal{V}}(\boldsymbol{v}) \triangleq\|s-v\|+\|d-v\|，那么可以通过光速等计算在非可见场景的路径长度， I(\tau ; \boldsymbol{v})=\int_{\mathcal{X}} f(\boldsymbol{x} ; \boldsymbol{v}) \delta(\tau-\tau(\boldsymbol{x} ; \boldsymbol{v})) \mathrm{d} A(p, q)其中 $\tau(\boldsymbol{x} ; \boldsymbol{v}) \triangleq 2 \cdot|\boldsymbol{x}-\boldsymbol{v}|,(p, q) \in[0,1]^{2} $是非可见物体表面的参数化表示。 费马流方程 给定测量的瞬态$I(\tau ; \boldsymbol{v})$ ，可以把它的离散性定义为对费马路径长度的贡献，每个路径长度约束了球面上的点的法线和曲率。这是本文的核心所在，给定一组费马路径长度，就可以得到隐藏物体表面点集的位置和法线。首先定义费马路径函数， \tau_{\mathcal{F}}(\boldsymbol{v})=\{\tau : I(\tau ; \boldsymbol{v}) \text { is discontinuous }\}在每个瞬态可以有多个不连续的路径长度，因此费马路径函数是一个多值函数 \boldsymbol{x}_{\mathcal{F}}=\boldsymbol{v}-\left(\tau_{\mathcal{F}}(\boldsymbol{v}) / 4\right) \nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})其中 $\boldsymbol{x}_{\mathcal{F}} $是隐藏物体球面上的点，因此，物体可以唯一的被可见点\boldsymbol{v}、路径长度、梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 重建，得到隐藏物体表面的点，然后通过一些简单的集合操作即可。但是就算路径长度的导数是一件非常难的事情，它和选取的可视面的形状、位置有密切的关系，为了简化，文中采用选取平面作为可视区域，得到的导数为， \begin{array}{l}{\nabla_{\boldsymbol{v}^{\tau} \mathcal{F}}(\boldsymbol{v})=} \\ {\left.\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}, \frac{\partial \tau_{\mathcal{F}}}{\partial y}, \sqrt{4-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}\right)^{2}-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial y}\right)^{2}}\right)\right|_{\boldsymbol{v}}}\end{array}表面拟合上述的步骤生成了一系列的有向点云，它的密度相当于在可视区域 \mathcal{V} 上的测量密度，然后，可以使用算法，利用正常信息，以更高的精度将曲面表示(如三角形网格)匹配到点云，给定这样一个初始的表面重建，在补充中，我们描述了一个基于高光路径扰动理论的优化过程，该过程对拟合表面进行了细化，以考虑由于梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 估计不准确而可能产生的误差。 实验结果 如图中所示，分别从两个视图中重建了一个有方向的点云，点按它们的法线着色。最后，我们将一个表面与点云相匹配，显示在右边的两个视图下。 扫描的对象跨越各种形状(凸，凹)和反射(半透明，光泽，镜面)。对于每一个物体，我们展示了环境光下的照片，以及它表面重建的两个视图。 更多我的作品Jackpop：【动手学计算机视觉】第一讲：图像预处理之图像去噪 Jackpop：【动手学计算机视觉】第二讲：图像预处理之图像增强 Jackpop：【动手学计算机视觉】第三讲：图像预处理之图像分割 Jackpop：【动手学计算机视觉】第四讲：图像预处理之图像增广 Jackpop：【动手学计算机视觉】第五讲：传统目标检测之特征工程 Jackpop：【动手学计算机视觉】第六讲：传统目标检测之Harris角点检测 Jackpop：【动手学计算机视觉】第七讲：传统目标检测之SIFT特征]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
