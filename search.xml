<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[cv_hog]]></title>
    <url>%2F2019%2F07%2F08%2Fcv-hog%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[learn_optimization]]></title>
    <url>%2F2019%2F07%2F07%2Flearn-optimization%2F</url>
    <content type="text"></content>
      <categories>
        <category>优化算法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[效率工具 | Windows下一款强大的启动搜索工具]]></title>
    <url>%2F2019%2F07%2F02%2Ftools-wox%2F</url>
    <content type="text"><![CDATA[前言对于大多数人来说，日常生活和工作中接触较多的软件和工具就是浏览器、专业软件、翻译软件、笔记、办公等。其实有很多软件在名气上虽然不如这些商业软件，但是功能却丝毫不输这些知名软件。在工作中能够大大提高办公效率，而且内存占用小、免费开源。大家都知道windows自带的文件浏览器查找文件是一件非常令人痛苦的事情，不仅速度缓慢，而且准确度出奇的低，让人感觉很鸡肋。但是当我们要找一个文档时却忘记放在哪里，挨个硬盘去翻更加令人感到折磨。所以不得不去借助一些高效的搜索工具，其中用的较多、名气较大的就是everything。我个人也一直在用这款工具，的确非常强大，快速、支持正则表达式匹配。它作为一个文件搜索工具的确很称职，但是当我们想要更多扩展功能，例如用于程序启动工具时everything就显得有些不足了。之前我介绍过一款工具叫做Listary，能够完美的与everything结合，既能涵盖everything强大的搜索功能，还能融合Listary实用的启动功能。本文再给大家介绍一款与Listary类似的工具—Wox，有相同之处，也有很大的差异之处，各位可以根据自己的喜好进行选择。 Wox Wox是一款启动器。这就是它与Listary的最大的不同之处—定位不同。Listary本身兼顾搜索与启动，但是在搜索方面不如everything，如果想使用更加丰富的搜索功能需要在设置里配置一下everything，如果满足于Listary提供的快速搜索功能则无需配置。而Wox的定位就是一个简单、纯净的启动器。它可以快速的启动本机安装的各种程序、文件、网页等。当然，它也可以用于文件搜索，它指定的后端搜索工具是everything，所以在打开Wox之前需要先启动everything，这样才能够使用强大的搜索功能。它不仅可以用于搜索程序和文件，还可以配置各种丰富的插件满足更多场景的需求，例如计算器、天气、翻译、网页搜索等。 Wox与Listary前面提到了，Wox与Listary有很多类似之处： 搜索 启动器 配合everything使用 但是Wox也有很多特别之处是Listary无法比拟的，Wox的特别之处主要有如下几点： 支持丰富的插件 支持自己定义插件 支持多种主题切换 支持自定义快捷键 支持丰富插件Wox的插件主要分类两种： 系统插件 第三方插件 系统插件不需要关键字唤醒，直接用Alt + Space调出Wox的工具栏输入相应的命令即可，系统插件主要包含如下几类： 程序插件 颜色插件 控制面板插件 计算器插件 网址插件 Web搜索插件 命令行插件 文件夹插件 拿其中几个举个例子， 程序插件 Alt+空格键激活Wox，然后输入要启动的程序即可， 计算器插件 计算器对于很多人来说虽然不是主要的工作工具，但是偶尔会用到，当我们需要用计算器的时候就需要点击windows图标，搜索“计算器”，这样比较麻烦，Wox集成了计算器插件，激活Wox后输入要计算的公式即可， 网址插件 当我们要浏览某个网站时往往需要打开浏览器-&gt;在地址栏输入网址，Wox的浏览器插件大大简化这个过程，只需要激活Wox，输入相应网址即可， 其他还有很多实用的系统插件，可以查看网站进行了解， http://doc.wox.one/zh/basic/ 除了Wox自带的系统插件，Wox还提供了多大230款第三方插件，其中就包含有道翻译、天气查询、Steam、Putty、二维码、维基百科、书签搜索、待办事项、进制转换、哔哩哔哩、Skype、FileZilla、Stack Overflow、沪江日语等等。只需要下载安装一下即可，而且Wox提供了多选、简单的安装方式， 安装第三方插件 命令安装 这是最简单的一种安装方式，使用wpm进行插件的安装、卸载管理， 123456789# 安装插件wpm install &lt;插件名称&gt;# 卸载插件wpm uninstall &lt;插件名称&gt;# 列出已安装插件wpm list 手动安装 如果由于网络、代理等原因无法命令安装，可以打开插件主页[http://www.wox.one/plugin]下载到本地(以.wox结尾),拖动到Wox搜索框进行安装， 支持自己定义插件除了官网提供的系统插件和第三方插件之外，Wox还支持自定义插件，它支持以下3种方式来定义插件， plugin.json C# Python Wox与插件之间的通信原理： 支持多种主题切换 Wox安装后会发现自带BlurBlack、BlurWhite、Dark、Gray、Light、Metro Server、Pink七种主题，除了上述提到的7种主题之外，还可以在官网自定义主题，配置之后下载主题(.xaml文件)，放置到C:\Users\YourUserName\AppData\Local\Wox\app-1.3.524\Themes路径下，重启Wox即可。 支持自定义快捷键这一点也是Wox吸引人的一点，它支持自定义快捷键。如果觉得Alt+空格启动程序、文件夹还不够快捷，可以把常用的命令保存到快捷键，这样当使用快捷键时能够快速达到目的。 例如，我想百度搜索“哈尔滨工业大学”，使用Wox的方式是这样的， Alt + 空格激活Wox 输入”bd 哈尔滨工业大学” 这样比起”打开浏览器-&gt;打开百度-&gt;搜索”已经便捷了很多，但是还有更便捷的，就是Wox支持的快捷键。 可以把常用的命令添加到快捷键，例如把”bd 哈尔滨工业大学”添加为快捷键”Ctrl+Alt+H”,能够同时激活Wox并输入相应的命令，然后按Enter键即可搜索。]]></content>
      <categories>
        <category>实用工具</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
        <tag>工具</tag>
        <tag>使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐一份热门机器学习资源]]></title>
    <url>%2F2019%2F07%2F01%2Fhomemade-machine-learning%2F</url>
    <content type="text"><![CDATA[前言最近几年人工智能异常火热，随之而来的就是各种针对入门者的学习资源，其中不乏很多经典的教程例如吴恩达的《机器学习》、《深度学习工程师》，但是也有很多千篇一律、照本宣科的学习资源。在学习进阶过程中很多人会到GitHub寻找一些可以动手实践的机器学习项目，会发现GitHub上会有和机器学习相关的各种awesome，恨不得把所有和机器学习、深度学习的资源都囊括进去。这样虽然全面，但是我认为它的价值并不高。我们之所以希望有经验者推荐学习资源，就是因为时间、精力有限，希望能够在鱼龙混杂的学习资源里筛选出真正有价值，或者与众不同的，能够让我们利用有限的精力和时间内真正学会一些东西。近期GitHub有一个关于机器学习的热门开源项目，homemade-machine-learning，目前已经11k+个star，近一周达到1.1k+，经过一段时间的学习发现这的确一个不错的学习项目，下面就详细介绍一下这个项目。 Homemade Machine Learning 开门见山，这个开源项目主要有以下几个优点： 少而精 不依赖python第三方库 详细解释它们背后的数学原理 交互式Jupyter notebook演示程序 丰富易懂的示例 这个项目用Python实现了目前热门、使用的一些机器学习算法，而不是像很多开源项目那样，从头至尾把每个机器学习算法都实现一遍。换句话说，这个开源项目追求“少而精”，它分别从监督学习、非监督学习、神经网络、异常检测、回归、分类这些类别中选择一种算法进行详细阐述算法背后的数学原理，然后使用jupyter notebook交互式的演示，随后会用多个示例进行实现，动手操作，不依赖集成的python第三方库，更容易理解机器学习算法的原理。 项目概括该项目主要包括如下几个方面的机器学习算法： 监督学习 无监督学习 异常检测 神经网络 其中监督学习又分为回归和分类，回归算法选取的是比较常用的线性回归，分类算法选取的是比较实用的逻辑回归。无监督学习中主要针对聚类进行讲解，项目中选取的是热门的k-means。异常检测是指通过大多数数据来检测出有显著差异的事件、观测结果，在数据处理、图像处理都有应用。神经网络中选择的是多层感知机。 安装首先要保证电脑上正确的安装了Python，然后安装一些项目依赖， 1pip install -r requirements.txt requirements: 1234567jupyter==1.0.0matplotlib==3.0.1numpy==1.15.3pandas==0.23.4plotly==3.4.1pylint==2.1.1scipy==1.1.0 如果要使用jupyter notebook，需要在命令行输入下面命令， 1jupyter notebook 然后会在浏览器中打开如下窗口， 详细介绍数学原理 我认为这是这个项目吸引人的地方，也是它与众不同的地方，它和很多项目不同，浮于表面，把很多环节都认为是既定的去阐述，有一些初学者会看的云里雾里，不明白“为什么是这样？”这个项目则不同，它详细、深入的阐述每个算法背后的数学原理，循序渐进，配合可视化很容易让人理解。 详细编码过程 该项目不过多依赖tensorflow、pytorch、keras这些高度集成的机器学习平台，它从梯度下降到损失函数、从训练到预测都是一步一步实现，尽量减少对高度集成第三方库的依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@staticmethoddef gradient_descent(data, labels, initial_theta, lambda_param, max_iteration): """Gradient descent function. Iteratively optimizes theta model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param initial_theta: initial model parameters. :param lambda_param: regularization parameter. :param max_iteration: maximum number of gradient descent steps. """ # Initialize cost history list. cost_history = [] # Calculate the number of features. num_features = data.shape[1] # Launch gradient descent. minification_result = minimize( # Function that we're going to minimize. lambda current_theta: LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Initial values of model parameter. initial_theta, # We will use conjugate gradient algorithm. method='CG', # Function that will help to calculate gradient direction on each step. jac=lambda current_theta: LogisticRegression.gradient_step( data, labels, current_theta.reshape((num_features, 1)), lambda_param ), # Record gradient descent progress for debugging. callback=lambda current_theta: cost_history.append(LogisticRegression.cost_function( data, labels, current_theta.reshape((num_features, 1)), lambda_param )), options=&#123;'maxiter': max_iteration&#125; ) # Throw an error in case if gradient descent ended up with error. if not minification_result.success: raise ArithmeticError('Can not minimize cost function: ' + minification_result.message) # Reshape the final version of model parameters. optimized_theta = minification_result.x.reshape((num_features, 1)) return optimized_theta, cost_history@staticmethoddef gradient_step(data, labels, theta, lambda_param): """GRADIENT STEP function. It performs one step of gradient descent for theta parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Initialize number of training examples. num_examples = labels.shape[0] # Calculate hypothesis predictions and difference with labels. predictions = LogisticRegression.hypothesis(data, theta) label_diff = predictions - labels # Calculate regularization parameter. regularization_param = (lambda_param / num_examples) * theta # Calculate gradient steps. gradients = (1 / num_examples) * (data.T @ label_diff) regularized_gradients = gradients + regularization_param # We should NOT regularize the parameter theta_zero. regularized_gradients[0] = (1 / num_examples) * (data[:, [0]].T @ label_diff) return regularized_gradients.T.flatten()@staticmethoddef cost_function(data, labels, theta, lambda_param): """Cost function. It shows how accurate our model is based on current model parameters. :param data: the set of training or test data. :param labels: training set outputs (0 or 1 that defines the class of an example). :param theta: model parameters. :param lambda_param: regularization parameter. """ # Calculate the number of training examples and features. num_examples = data.shape[0] # Calculate hypothesis. predictions = LogisticRegression.hypothesis(data, theta) # Calculate regularization parameter # Remember that we should not regularize the parameter theta_zero. theta_cut = theta[1:, [0]] reg_param = (lambda_param / (2 * num_examples)) * (theta_cut.T @ theta_cut) # Calculate current predictions cost. y_is_set_cost = labels[labels == 1].T @ np.log(predictions[labels == 1]) y_is_not_set_cost = (1 - labels[labels == 0]).T @ np.log(1 - predictions[labels == 0]) cost = (-1 / num_examples) * (y_is_set_cost + y_is_not_set_cost) + reg_param # Let's extract cost value from the one and only cost numpy matrix cell. return cost[0][0] 丰富示例 理解了算法背后的数学原理，跟着作者一步一步实现了算法，要想更加深入的理解就需要把算法应用到不同方面，本项目提供了丰富的示例，其中不乏MNIST这类经典的演示样例。 其中每个项目后面都包含至少一个示例，可以获取对应的数据进行实现，这样对算法的理解和应用会有更加清晰而深入的认识。]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Github</tag>
        <tag>资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文熟练掌握Docker使用]]></title>
    <url>%2F2019%2F06%2F30%2Flearning-docker%2F</url>
    <content type="text"><![CDATA[Docker是由dotCloud公司发起并与2013年开源的一个项目，一径开源就备受欢迎，其主要项目至今在github已经54k个star。它是使用Go语言开发实现，基于Linux内核cgroup、namespace以及AUFS类等技术对进程进行封装隔离，属于一种操作系统层面的虚拟化技术。此后，进一步开发开始使用runC和containerd，进一步封装，从文件系统到网路互联，再到进行都进行隔离，极大的简化了容器的创建和维护，使得Docker比虚拟机更为轻便、快捷。 为什么要用docker？Docker与传统虚拟机一样，同属于虚拟化技术，但是它拥有众多虚拟机无法比拟的优势： 持续交付和部署 更快的迁移 更高效的利用系统资源 更快的启动时间 一致的运行环境 更轻松的维护和扩展 容器与虚拟机对比详情： 对于大多数开发人员感受最为就是前两点：持续交付和部署、更快的迁移。 我想这对于很多开发人员都是一个很头疼的问题，在开发过程中会遇到这种抱怨：“在我电脑上可以运行啊？为什么换一台电脑就不行了？” 虽然诸如maven、nodejs的package.json、Python的requirement.txt的出现使得迁移变得简单，但是它们更多的是使得在第三方工具包的迁移方面变得简单方面，但是在系统和开发环境方面却没有什么作用。docker确保了直行环境的一致性，可以在多平台上运行，使得应用迁移更加容易。此外，docker使用分层存储以及镜像技术，使得应用重复部分的复用更加容易，可以基于基础镜像做更多的扩展，使得系统的维护变得更加简单。 基本概念使用docker接触最多的就是以下3个概念， 镜像：image 容器：container 仓库：repository 了解这三个概念，对容器的整个生命周期便有了认识。在这里，我用简单的语言对上述3个概念进行描述 镜像：进行就相当于一个精简化的文件系统，例如官方提供的Ubuntu镜像，就只包含了最小化的root文件系统。 容器：容器是一个拥有自己root文件系统、自己网络配置、自己命名空间的进程。镜像和容器就像是编程中的类和实例，镜像时静态的定义，而镜像运行时的实体是容器。什么是类和实例？举一个编程的例子阐述一下， 1234567891011121314# 类class HelloWorld: def __init__(self, x, y): self.x = x self.y = y def add(self): return self.x + self.y# 实例hello_world = HelloWorld(2, 3)print(hello_world.add())&gt;&gt;&gt; 5 其中HelloWorld是类，hello_world是实例，类比一下，就能够理解容器和镜像之间的关系。 仓库：docker镜像仓库就如同github代码仓库一样，当一个人构建一个项目，想在其他其他电脑上运行这个项目，那么就去从代码仓库把这个项目克隆下来。docker镜像仓库也是这样，当构建一个镜像之后，想在其他服务器上使用这个镜像，就需要一个集中的存储、分发服务，仓库就是这样的服务。官方的镜像仓库是DockerHub，它存储了丰富的镜像，但是国内拉取镜像速度缓慢，因此可以使用国内镜像仓库进行替代，例如阿里云镜像仓库、网易云镜像仓库、DaoCloud镜像市场等。 安装docker目前支持Linux、Windows 10、macOS，下面就一个Linux安装为例， APT方式安装 首先安装HTTPS软件包和CV证书， 123456$ sudo apt-get update$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 添加软件源GPG密钥， 1$ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add 添加docker软件源， 1234$ sudo add-apt-repository \ "deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable" 安装docker ce, 12$ sudo apt-get update$ sudo apt-get install docker-ce 添加用户组 docker命令会使用Unix socket与docker引擎通讯，因此每次使用时会需要root权限，也就是需要在命令前加sudo比较麻烦，为了避免这个麻烦可以把建立docker组并把当前用户加入docker用户组， 12$ sudo groupadd docker$ sudo usermod -aG docker $USER 启动、退出、重启docker 123$ systemctl start docker$ systemctl stop docker$ systemctl restart docker 也可以使用， 123$ service docker start$ service docker stop$ service docker restart Dockerfile理解docker中一些基本概念，并完成docker安装下一步就是学习docker的使用。对于大多数开发人员来说，docker使用过程中最为核心的部分就是Dockerfile。 Dockerfile是一个文本文件，它包含了一些指令，docker镜像的构建就是通过Dockerfile中的这一条一条的指令完成的。也就是说，要构建一个镜像，就需要一个Dockerfile，然后根据自己的需求配置一些指令集合，下面就看一下Dockerfile中使用的一些指令。 FROM：指定基础镜像 定制我们的镜像，是需要以一个镜像为基础的，就是基础镜像，例如Ubuntu、 nginx、postgres、mysql等，例如，FROM Ubuntu:16.04，如果本地有Ubuntu基础镜像则使用本地基础镜像，如果没有则会到官方镜像仓库拉取，16.04是镜像版本号，如果不指定则会拉取lastest。 RUN：执行命令 RUN指定我们在构建镜像时需要执行的命令，比如apt-get install安装某个软件，pip install安装Python依赖包，配置软件源，配置时区等， 例如，RUN apt-get install python3。 ADD和COPY：文件操作 ADD和COPY是两个功能类似的指令，一般优先使用COPY，它比ADD更透明，它的功能是将本地文件拷贝到容器中，例如，COPY ./ /home/jackpop/test。 WORKDIR：指定工作路径 指定镜像的运行时的工作路径，例如，WORKDIR /home/jackpop/test 。 ENTRYPOINT：设置镜像主命令 指定镜像运行是运行的命令，例如, ENTRYPOINT [“python”, “-m”, “main”]。 LABEL：添加标签 可以为镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。 CMD：执行目标镜像中包含的软件 如果创建镜像的目的是为了部署某个服务，可能会执行某种形式的命令，可以包含参数。 EXPOSE：指定监听端口 给外部访问指定访问端口。 ENV：环境变量 为了方面程序运行，有时需要更新环境变量。 VOLUME：暴露数据库存储文件 USER：指定当前用户 其中常用的命令就是FROM、COPY、WORKDIR、RUN、ENTRYPOINT。 常用命令了解了Dockerfile的常用指令，我们该怎么对镜像和容器进行操作呢？下面就来学习一下docker常用的一些命令， 备注：由于我已经把当前用户加入到docker用户组，所以下面命令没有加sudo，如果没有加用户组需要使用sudo docker。 查看本地镜像 123$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 ****** 10 days ago 119MB 查看容器 123$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES*** *** *** *** *** *** *** *** 启动、停止、重启容器 123$ docker start $container_id$ docker stop $container_id$ docker restart $container_id 退出和进入镜像 12$ exit$ docker exec $container_id /bin/bash 启动镜像 1$ docker run $image_id 可以用—p和—dns指定端口和dns来配置网络。 container_id是容器ID，image_id是镜像ID。 拉取镜像 1$ docker image pull ubuntu 从Dockerfile创建镜像 1$ docker build 从一个修改的容器创建镜像 1$ docker commit 容器与本地之间复制文件 1$ docker cp 推送镜像 1$ docker push 为镜像打标签 1$ docker tag 重命名容器 1$ docker rename 删除容器 1$ docker rm 删除镜像 1$ docker rmi 搜索镜像 1$ docker search docker常用命令概括： 实践创建项目 123Test/├── Dockerfile└── main.py 写一个简单的测试程序 1234567891011121314151617181920# main.pyimport loggingfrom time import sleepimport numpy as nplogging.basicConfig(level=logging.DEBUG, format="'%(asctime)s - " "%(filename)s[line:%(lineno)d] - " "%(levelname)s: %(message)s")def main(): for i in range(10): logging.debug(np.random.randint(0, 5)) sleep(0.1)if __name__ == '__main__': main() Dockerfile 这是构建镜像中的重点部分， 1234567891011FROM ubuntu:16.04COPY ./ /home/Test_dockerWORKDIR /home/Test_dockerRUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip \&amp;&amp; ln -s pip3 /usr/bin/pip \&amp;&amp; ln -sf /usr/bin/python3 /usr/bin/python \&amp;&amp; rm -rf ls /var/cache/apt/* \ENTRYPOINT ["python3", "-m", "main"] 进入项目根目录 1$ cd Test 开始创建 1$ docker build test:v1.0 . test是指定构建镜像的名称，v1.0指定镜像标签，如果不指定，镜像名称和标签会显示为。 运行镜像 1234567891011$ docker run $image_id'2019-06-29 12:26:38,298 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,399 - main.py[line:13] - DEBUG: 2'2019-06-29 12:26:38,499 - main.py[line:13] - DEBUG: 1'2019-06-29 12:26:38,599 - main.py[line:13] - DEBUG: 3'2019-06-29 12:26:38,699 - main.py[line:13] - DEBUG: 0'2019-06-29 12:26:38,799 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:38,900 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,000 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,100 - main.py[line:13] - DEBUG: 4'2019-06-29 12:26:39,200 - main.py[line:13] - DEBUG: 2 当然也可以在基础镜像的基础上进行修改来创建我们的镜像，例如，我们拉取一个Ubuntu基础镜像，可以启动镜像后安装我们需要的软件和环境，然后利用docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]来创建一个新镜像。 延伸阅读除了基础的docker之外，还有一些高级的docker开源工具，比较知名的有如下3项， docker compose docker machine docker swarm 其中docker compose是官方编排项目之一，用于快速在集群中部署分布式应用。docker machine同样是官方编排项目之一，负责在多种平台上快速安装docker环境。docker swarm提供docker容器集群服务，是docker官方对容器云生态进行支持的核心方案。 除此之外，还有一些比较知名的集群管理系统，例如， Mesos Kubernetes 其中Mesos是来自UC Berkeley的集群资源管理开源项目，它可以让用户很容易实现分布式应用的自动化调度。Kubernetes是由Google团队发起并维护的给予docker的开源容器集群管理系统，应用比较广泛，它不仅支持场景的云平台，而且支持内部数据中心。 学习资源上述所讲的常用命令、指令含义等对于日常开发使用已经够用了，如果对Docker更深入的内容，例如，数据管理、安全、底层实现、容器与云计算等感兴趣可以选取其他的学习资料。在这里我推荐一份我认为不错的学习资料。就是yeasy大神在github开源的一份详细的docker教程—docker_practice，目前docker_practice项目在github已经13.7k个star，想深入学习的可以查看github项目， 也可以查看gitbooks， 或者关注公众号【平凡而诗意】回复关键字”dk”获取pdf和epub版教程， 更多内容请关注公众号【平凡而诗意】]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVPR2019最佳论文解读]]></title>
    <url>%2F2019%2F06%2F28%2FCVPR2019%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[前言 CVPR，全称IEEE Conference on Computer Vision and Pattern Recognition，与ECCV(Europeon Conference on Computer Vision)，ICCV( IEEE International Conference on Computer Vision)并称为计算机视觉领域三大会议，均为计算机视觉领域的顶级会议。由于近几年计算机视觉的异常火热，CVPR也就成为很多计算机视觉领域研究者趋之若鹜的盛宴，它的受关注程度更是今非昔比。CVPR2019于2019年6月16日在美国召开，此次会议共收到来自全球14104位研究者提交的5160篇文章，同比2018年增长56%，一举打破记录，受欢迎程度可见一斑。 CVPR2019最终共接收1294篇文章，尽管CVPR被计算机视觉领域视为顶尖，我个人认为，其中不乏质量平平的水文，真正令人印象深刻，几年之后依然被人所熟知且实用，并在算法思想方面取得跨越的却寥寥无几。闲话说完，回到本文的重点CVPR2019最佳论文，该荣誉最终由卡耐基梅隆大学、多伦多大学、伦敦大学学院的多位研究者斩获，论文名称为A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction，接下来，我详细解读一下这篇文章。 数学符号含义$s$ 光源上的点$v$ 可见场景内的点$x$ 不可见场景内的点$d$ 检测器上的点$\tau_{\mathcal{F}}$ 费马路径长度$I(\tau ; \boldsymbol{v})$ 瞬态 概念解释瞬态(transients):一种测量值，用于重建隐藏形状信息的大多数方法采用快速调制光源已经传感器来记录光子强度和旅行时间的测量值。费马路径(Fermat paths):首先返回的光子路径的超集合。费马路径长度(Fermat pathlengths):顾名思义，就是通过光速等计算出来的离散路径长度。 算法详解 目前大多数计算机视觉领域的研究都是围绕着视觉可见范围内的研究，但是理解视野范围之外的场景在很多领域却有着非常重要的应用，因此，这使得这项研究更加具有价值。被动方式通过分析隐藏场景所投射的阴影来粗略估计物体的运动和结构，或者利用光的相干性来定位隐藏对象。这些方法没有足够的信息来精确计算位置隐藏场景的三维形状。主动方式提取隐藏场景的附加信息时可能的。大多数重建隐藏形状信息的方法都是用调制光源和时间分辨传感器、超快光电二极管等，这些传感器不仅记录入射光子的强度，还在时间分辨率范围内记录它们到达的时间，这种测量称为瞬态。 大多数主动技术都是通过测量一个已知可见场景的不同位置的瞬态，然后根据已经获取的辐射成像逆向来进行三维重建，例如椭圆反投影、正则化线性系统、光锥变换等。这些方法主要有两个缺点： 它们依赖于辐射测量信息 为了简化反演问题，所有现有的重建技术都依赖于非视线场景的Lambertian 反射假设 在这篇文章中，作者提出一种使用视线以外场景的瞬态测量得到的几何信息的方法，克服了上述的限制。简言之，它主要使用视线内和视线外场景之间的一种称之为费马路径的几何路径星系，通过观察发现这些路径遵循镜面或者物体边界特点的反射定理。作者证明，费马路径对应于瞬态测量中的不连续性，不连续点的时间位置仅是视线外场景对象的形状而不是其反射率。利用上述理论，推导出一种精确重建视线外物体形状的算法，称之为费马流(Fermat Flow)。作者证明，费马路径长度的空间导数提供了一个简单的约束，它唯一地决定了隐藏场景点的深度和法线。这个导数是通过将光滑的路径函数拟合到一组稀疏的测量值上而得到，然后结合深度和法线信息来计算平滑网网格。概括一下，本文在隐藏物体重建方面主要包含以下3个步骤： 瞬态测量 求解费马流方程 表面拟合 测量瞬态 假设已经校准了从光源到可见点，和从可见点到检测器的距离 \mathcal{\tau\mathcal{V}}(\boldsymbol{v}) \triangleq\|s-v\|+\|d-v\|，那么可以通过光速等计算在非可见场景的路径长度， I(\tau ; \boldsymbol{v})=\int_{\mathcal{X}} f(\boldsymbol{x} ; \boldsymbol{v}) \delta(\tau-\tau(\boldsymbol{x} ; \boldsymbol{v})) \mathrm{d} A(p, q)其中 $\tau(\boldsymbol{x} ; \boldsymbol{v}) \triangleq 2 \cdot|\boldsymbol{x}-\boldsymbol{v}|,(p, q) \in[0,1]^{2} $是非可见物体表面的参数化表示。 费马流方程 给定测量的瞬态$I(\tau ; \boldsymbol{v})$ ，可以把它的离散性定义为对费马路径长度的贡献，每个路径长度约束了球面上的点的法线和曲率。这是本文的核心所在，给定一组费马路径长度，就可以得到隐藏物体表面点集的位置和法线。首先定义费马路径函数， \tau_{\mathcal{F}}(\boldsymbol{v})=\{\tau : I(\tau ; \boldsymbol{v}) \text { is discontinuous }\}在每个瞬态可以有多个不连续的路径长度，因此费马路径函数是一个多值函数 \boldsymbol{x}_{\mathcal{F}}=\boldsymbol{v}-\left(\tau_{\mathcal{F}}(\boldsymbol{v}) / 4\right) \nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})其中 $\boldsymbol{x}_{\mathcal{F}} $是隐藏物体球面上的点，因此，物体可以唯一的被可见点\boldsymbol{v}、路径长度、梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 重建，得到隐藏物体表面的点，然后通过一些简单的集合操作即可。但是就算路径长度的导数是一件非常难的事情，它和选取的可视面的形状、位置有密切的关系，为了简化，文中采用选取平面作为可视区域，得到的导数为， \begin{array}{l}{\nabla_{\boldsymbol{v}^{\tau} \mathcal{F}}(\boldsymbol{v})=} \\ {\left.\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}, \frac{\partial \tau_{\mathcal{F}}}{\partial y}, \sqrt{4-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial x}\right)^{2}-\left(\frac{\partial \tau_{\mathcal{F}}}{\partial y}\right)^{2}}\right)\right|_{\boldsymbol{v}}}\end{array}表面拟合上述的步骤生成了一系列的有向点云，它的密度相当于在可视区域 \mathcal{V} 上的测量密度，然后，可以使用算法，利用正常信息，以更高的精度将曲面表示(如三角形网格)匹配到点云，给定这样一个初始的表面重建，在补充中，我们描述了一个基于高光路径扰动理论的优化过程，该过程对拟合表面进行了细化，以考虑由于梯度 $\nabla_{\boldsymbol{v}} \tau_{\mathcal{F}}(\boldsymbol{v})$ 估计不准确而可能产生的误差。 实验结果 如图中所示，分别从两个视图中重建了一个有方向的点云，点按它们的法线着色。最后，我们将一个表面与点云相匹配，显示在右边的两个视图下。 扫描的对象跨越各种形状(凸，凹)和反射(半透明，光泽，镜面)。对于每一个物体，我们展示了环境光下的照片，以及它表面重建的两个视图。 更多我的作品Jackpop：【动手学计算机视觉】第一讲：图像预处理之图像去噪 Jackpop：【动手学计算机视觉】第二讲：图像预处理之图像增强 Jackpop：【动手学计算机视觉】第三讲：图像预处理之图像分割 Jackpop：【动手学计算机视觉】第四讲：图像预处理之图像增广 Jackpop：【动手学计算机视觉】第五讲：传统目标检测之特征工程 Jackpop：【动手学计算机视觉】第六讲：传统目标检测之Harris角点检测 Jackpop：【动手学计算机视觉】第七讲：传统目标检测之SIFT特征]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>AI</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
